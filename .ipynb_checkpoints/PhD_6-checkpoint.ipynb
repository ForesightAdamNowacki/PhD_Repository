{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4252aad-9a93-4148-8b9d-7414dd7a8439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# LAB\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage.morphology as smo\n",
    "from skimage.io import imread\n",
    "import itertools\n",
    "\n",
    "from skimage import io, color\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please ensure you have installed TensorFlow correctly')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3db75a-8041-43bc-977d-d5496f1d37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_add_border(image, x , y, val, rel = False):\n",
    "\n",
    "    \"\"\"\n",
    "    Adds a border to the input image\n",
    "    rel = True - x,y - size of the added border\n",
    "    rel = False - x,y - size of the image with added border\n",
    "    val - pixel value \n",
    "    \"\"\"\n",
    "    \n",
    "    (sx_org, sy_org) = image.shape\n",
    "    if rel:\n",
    "        sx = sx_org + 2*x\n",
    "        sy = sy_org + 2*y\n",
    "    else:\n",
    "        sx = x\n",
    "        sy = y\n",
    "    img = np.ones([sx, sy]) * val\n",
    "    [cx, cy] = ((np.array([sx, sy]) - np.array([sx_org, sy_org]))/2).astype('int')\n",
    "    img[cx:(cx + sx_org), cy:(cy + sy_org)] = image\n",
    "    return img\n",
    "\n",
    "# ---------- #\n",
    "# Use example:\n",
    "# obraz = imread(\"camel-19.gif\")\n",
    "# if len(obraz.shape) == 3:\n",
    "#     obraz = obraz[:,:,1]\n",
    "# print(obraz.shape)\n",
    "# obraz_ = image_add_border(obraz, x = 100, y = 100, val = 1, rel = True)\n",
    "# print(obraz_.shape)\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(obraz)\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(obraz_)\n",
    "# plt.show()\n",
    "# ---------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c77922-b9b0-4d7c-bb63-f36ebd12db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structuring_elements(n, type = 'disk', initsize = 1, step = 1):\n",
    "    \n",
    "    \"\"\"\n",
    "    generate a list of n structuring elements\n",
    "    type = 'disk', 'square', 'diamond'\n",
    "    \"\"\"\n",
    "    \n",
    "    selist = []\n",
    "    sesize = initsize\n",
    "    \n",
    "    for i in range(n):\n",
    "        if (type == 'disk'):\n",
    "            se = smo.disk(sesize)\n",
    "        if (type == 'square'):\n",
    "            se = smo.square(2 * sesize + 1)\n",
    "        if (type == 'diamond'):\n",
    "            se = smo.diamond(sesize)       \n",
    "        \n",
    "        selist.append(se)\n",
    "        sesize += step\n",
    "        \n",
    "    return selist\n",
    "\n",
    "# ---------- #\n",
    "# Use examples:\n",
    "# get_structuring_elements(3, type = \"square\")\n",
    "# get_structuring_elements(3, type = \"disk\")\n",
    "# get_structuring_elements(3, type = \"diamond\")\n",
    "# ---------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "261583e5-eac7-4863-a3a9-e4d168b9ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image_size, channels, start_neurons, dense_neurons, classes, model_name = \"model_1\"):\n",
    "     \n",
    "    input_tensor = tf.keras.layers.Input(shape = [image_size, image_size, channels])\n",
    "\n",
    "    conv_1 = tf.keras.layers.Conv2D(filters = start_neurons * 1, \n",
    "                                    kernel_size = (3, 3),\n",
    "                                    strides = (1, 1), \n",
    "                                    activation = tf.keras.activations.relu,\n",
    "                                    padding = \"same\")(input_tensor)\n",
    "    conv_2 = tf.keras.layers.Conv2D(filters = start_neurons * 1, \n",
    "                                    kernel_size = (3, 3),\n",
    "                                    strides = (1, 1), \n",
    "                                    activation = tf.keras.activations.relu,\n",
    "                                    padding = \"same\")(conv_1)\n",
    "    conv_3 = tf.keras.layers.Conv2D(filters = start_neurons * 1, \n",
    "                                    kernel_size = (3, 3),\n",
    "                                    strides = (1, 1), \n",
    "                                    activation = tf.keras.activations.relu,\n",
    "                                    padding = \"same\")(conv_2)\n",
    "    pool_1 = tf.keras.layers.MaxPool2D(pool_size = (2, 2),\n",
    "                                       strides = (2, 2))(conv_3)\n",
    "\n",
    "    flatten = tf.keras.layers.Flatten()(pool_1)\n",
    "    dense = tf.keras.layers.Dense(units = dense_neurons, activation = tf.keras.activations.relu)(flatten)\n",
    "    output_tensor = tf.keras.layers.Dense(units = classes, activation = tf.keras.activations.softmax)(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = input_tensor, \n",
    "                                  outputs = output_tensor, \n",
    "                                  name = model_name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39637d2c-1b05-41a2-87de-6116bd7a1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphological_stack(input_image,\n",
    "                        structuring_elements_depth,\n",
    "                        transormation_type = 'cv_oc',\n",
    "                        structuring_elements_type = 'disk',\n",
    "                        structuring_elements_initsize = 1,\n",
    "                        structuring_elements_step = 1,\n",
    "                        addborder = True):\n",
    "    \"\"\"\n",
    "    produce a stack of results of the morphological dual operators\n",
    "    input_image - imput image (binary or graylevel 2D image)\n",
    "    structuring_elements_depth - list of two values - numers of up-stack and down-stack images\n",
    "    transormation_type - type of operations erosion/dilation <-> opening/closing; skimage binary <-> skimage graytone <-> opencv\n",
    "    structuring_elements_type = structuring element type ('disk', 'square', 'diamond')\n",
    "    structuring_elements_initsize = initial size of the structuring element \n",
    "    structuring_elements_step = increment of the structuring element size\n",
    "    addborder = True if the external boundary is added, = False otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    max_up = structuring_elements_depth[0] # number of up-stack images (higher indeces, dilation/opening)\n",
    "    max_down = structuring_elements_depth[1] # number of down-stack images (kower indeces, erosion/closing)\n",
    "    max_updown = max(max_up, max_down)\n",
    "    \n",
    "    structuring_elements_list = get_structuring_elements(n = max_updown,\n",
    "                                                         type = structuring_elements_type, \n",
    "                                                         initsize = structuring_elements_initsize,\n",
    "                                                         step = structuring_elements_step)\n",
    "    if addborder:\n",
    "        image = image_add_border(image = input_image,\n",
    "                                 x = max_updown,\n",
    "                                 y = max_updown, \n",
    "                                 val = 0, \n",
    "                                 rel = True)\n",
    "    else:\n",
    "        image = input_image\n",
    "    \n",
    "    image_out = np.zeros([image.shape[0], image.shape[1], max_up + max_down + 1])    \n",
    "    count = 0\n",
    "\n",
    "    if transormation_type == 'b_ed': # binary erosion/dilation - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.binary_erosion\n",
    "        operator_up = smo.binary_dilation\n",
    "    elif transormation_type == 'b_oc': # binary opening/closing - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.binary_opening\n",
    "        operator_up = smo.binary_closing      \n",
    "    elif transormation_type == 'ed': # erosion/dilation - scikit.image     \n",
    "        opencv = False\n",
    "        operator_down = smo.erosion\n",
    "        operator_up = smo.dilation\n",
    "    elif transormation_type == 'oc': # opening/closing - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.opening\n",
    "        operator_up = smo.closing      \n",
    "    elif transormation_type == 'cv_ed': # erosion/dilation - openCV \n",
    "        opencv = True\n",
    "        operator_down = cv2.MORPH_ERODE\n",
    "        operator_up = cv2.MORPH_DILATE\n",
    "    else: # transormation_type == 'cv_oc': # opening/closing - openCV \n",
    "        opencv = True\n",
    "        operator_down = cv2.MORPH_OPEN\n",
    "        operator_up = cv2.MORPH_CLOSE     \n",
    "    \n",
    "    if opencv:  # opencv version \n",
    "        for i in range(max_down):\n",
    "            image_out[:,:,count] = cv2.morphologyEx(image,\n",
    "                                                    operator_down,\n",
    "                                                    structuring_elements_list[max_down - i - 1]); count += 1\n",
    "        image_out[:,:,count] = image; count += 1\n",
    "        for i in range(max_up):\n",
    "            image_out[:,:,count] = cv2.morphologyEx(image,\n",
    "                                                    operator_up, \n",
    "                                                    structuring_elements_list[i]); count += 1\n",
    "        \n",
    "    else:   # scikit image version\n",
    "        for i in range(max_down):\n",
    "            operator_down(image,\n",
    "                          selem = structuring_elements_list[max_down - i - 1],\n",
    "                          out = image_out[:,:,count]); count += 1\n",
    "        image_out[:,:,count] = image; count += 1\n",
    "        for i in range(max_up):\n",
    "            operator_up(image,\n",
    "                        selem = structuring_elements_list[i], \n",
    "                        out = image_out[:,:,count]); count += 1   \n",
    "        \n",
    "    return image_out\n",
    "\n",
    "# ---------- #\n",
    "# Use examples:\n",
    "# obraz = imread(\"camel-19.gif\")\n",
    "# if len(obraz.shape) == 3:\n",
    "#     obraz = obraz[:,:,1]\n",
    "# obraz_ = morphological_stack(input_image = obraz,\n",
    "#                              structuring_elements_depth = [10, 10])\n",
    "# print(obraz_.shape)\n",
    "# plt.imshow(obraz_[:,:,20])\n",
    "# ---------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59cb7623-2ae7-4da2-9b5c-7015fadcabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphological_test_LAB_cifar_10(results_directory_ = \"Results_6\",\n",
    "                                    model_name_ = \"model\",\n",
    "                                    structuring_elements_depth_ = [2, 2],\n",
    "                                    transormation_type_ = \"cv_ed\",\n",
    "                                    structuring_elements_type_ = \"disk\",\n",
    "                                    structuring_elements_initsize_ = 1,\n",
    "                                    structuring_elements_step_ = 1,\n",
    "                                    addborder_ = True,\n",
    "                                    morphological_transformation_mode_ = True,\n",
    "                                    start_neurons_ = 16,\n",
    "                                    dense_neurons_ = 256,\n",
    "                                    epochs_ = 10,\n",
    "                                    batch_size_ = 32,\n",
    "                                    augmentation_ = True):\n",
    "\n",
    "    results_directory = os.path.join(\"D:/GitHub/PhD_Repository\", results_directory_)\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "    if morphological_transformation_mode_ == True:\n",
    "\n",
    "        print(\"1.train. Convert RGB to LAB\")\n",
    "        x_train = [i for i in color.rgb2lab(x_train)]\n",
    "\n",
    "        x_train_channel_1st = [img[:, :, 0] for img in x_train]\n",
    "        x_train_channel_2nd = [img[:, :, 1] for img in x_train]\n",
    "        x_train_channel_3rd = [img[:, :, 2] for img in x_train]\n",
    "\n",
    "        x_train_channel_2nd = [np.expand_dims(i, -1) for i in x_train_channel_2nd]\n",
    "        x_train_channel_2nd = np.array(x_train_channel_2nd)\n",
    "\n",
    "        x_train_channel_3rd = [np.expand_dims(i, -1) for i in x_train_channel_3rd]\n",
    "        x_train_channel_3rd = np.array(x_train_channel_3rd)\n",
    "\n",
    "        print(\"2.train. Morphological operations\")\n",
    "        x_train_2 = [morphological_stack(input_image = i,\n",
    "                                                   structuring_elements_depth = structuring_elements_depth_,\n",
    "                                                   transormation_type = transormation_type_,\n",
    "                                                   structuring_elements_type = structuring_elements_type_,\n",
    "                                                   structuring_elements_initsize = structuring_elements_initsize_,\n",
    "                                                   structuring_elements_step = structuring_elements_step_,\n",
    "                                                   addborder = addborder_) for i in x_train_channel_1st]\n",
    "\n",
    "        print(\"3.train. Expand first dim\")\n",
    "        x_train_3 = [np.expand_dims(i, 0) for i in x_train_2]\n",
    "        del x_train_2\n",
    "\n",
    "        print(\"4.train. Crop images\")\n",
    "        shp = x_train_3[0].shape[1]\n",
    "        sed_max = np.max(structuring_elements_depth_)\n",
    "        x_train_4 = [i[:, sed_max:shp - sed_max, sed_max:shp - sed_max] for i in x_train_3]\n",
    "        del x_train_3\n",
    "\n",
    "        print(\"5.train. Convert list to numpy array\")\n",
    "        x_train_5 = np.concatenate(np.array(x_train_4), axis = 0)\n",
    "        del x_train_4\n",
    "\n",
    "        print(\"6.train. Stack L, A & B\")\n",
    "        x_train_6 = np.concatenate([x_train_5, x_train_channel_2nd, x_train_channel_3rd], axis = -1)\n",
    "        del x_train_5\n",
    "        \n",
    "        x_train_ = x_train_6\n",
    "        y_train_ = y_train\n",
    "\n",
    "        print(\"1.test. Convert RGB to LAB\")\n",
    "        x_test = [i for i in color.rgb2lab(x_test)]\n",
    "\n",
    "        x_test_channel_1st = [img[:, :, 0] for img in x_test]\n",
    "        x_test_channel_2nd = [img[:, :, 1] for img in x_test]\n",
    "        x_test_channel_3rd = [img[:, :, 2] for img in x_test]\n",
    "\n",
    "        x_test_channel_2nd = [np.expand_dims(i, -1) for i in x_test_channel_2nd]\n",
    "        x_test_channel_2nd = np.array(x_test_channel_2nd)\n",
    "\n",
    "        x_test_channel_3rd = [np.expand_dims(i, -1) for i in x_test_channel_3rd]\n",
    "        x_test_channel_3rd = np.array(x_test_channel_3rd)\n",
    "\n",
    "        print(\"2.test. Morphological operations\")\n",
    "        x_test_2 = [morphological_stack(input_image = i,\n",
    "                                                   structuring_elements_depth = structuring_elements_depth_,\n",
    "                                                   transormation_type = transormation_type_,\n",
    "                                                   structuring_elements_type = structuring_elements_type_,\n",
    "                                                   structuring_elements_initsize = structuring_elements_initsize_,\n",
    "                                                   structuring_elements_step = structuring_elements_step_,\n",
    "                                                   addborder = addborder_) for i in x_test_channel_1st]\n",
    "\n",
    "        print(\"3.test. Expand first dim\")\n",
    "        x_test_3 = [np.expand_dims(i, 0) for i in x_test_2]\n",
    "        del x_test_2\n",
    "\n",
    "        print(\"4.test. Crop images\")\n",
    "        shp = x_test_3[0].shape[1]\n",
    "        sed_max = np.max(structuring_elements_depth_)\n",
    "        x_test_4 = [i[:, sed_max:shp - sed_max, sed_max:shp - sed_max] for i in x_test_3]\n",
    "        del x_test_3\n",
    "\n",
    "        print(\"5.test. Convert list to numpy array\")\n",
    "        x_test_5 = np.concatenate(np.array(x_test_4), axis = 0)\n",
    "        del x_test_4\n",
    "\n",
    "        print(\"6.train. Stack L, A & B\")\n",
    "        x_test_6 = np.concatenate([x_test_5, x_test_channel_2nd, x_test_channel_3rd], axis = -1)\n",
    "        del x_test_5\n",
    "        \n",
    "        x_test_ = x_test_6\n",
    "        y_test_ = y_test\n",
    "        \n",
    "    else:\n",
    "\n",
    "        print(\"1.train. Normal\")\n",
    "        x_train_ = x_train\n",
    "        y_train_ = y_train\n",
    "\n",
    "        print(\"1.test. Normal\")\n",
    "        x_test_ = x_test\n",
    "        y_test_ = y_test\n",
    "\n",
    "        print(\"Split: train, validation and test\")\n",
    "\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    X = np.arange(x_train_.shape[0])\n",
    "    y = np.arange(x_train_.shape[0])\n",
    "\n",
    "    classes = len(np.unique(y_train_))\n",
    "\n",
    "    x_train_id, x_validation_id, y_train_id, y_validation_id = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    x_train__ = x_train_[x_train_id, :, :, :]\n",
    "    y_train__ = y_train_[y_train_id]\n",
    "\n",
    "    x_valid__ = x_train_[x_validation_id, :, :, :]\n",
    "    y_valid__ = y_train_[y_validation_id]\n",
    "\n",
    "    x_test__ = x_test_\n",
    "    y_test__ = y_test_\n",
    "\n",
    "    y_train__ = tf.keras.utils.to_categorical(y_train__, classes)\n",
    "    y_valid__ = tf.keras.utils.to_categorical(y_valid__, classes)\n",
    "    y_test__ = tf.keras.utils.to_categorical(y_test__, classes)\n",
    "\n",
    "    print(x_train__.shape)\n",
    "    print(y_train__.shape)\n",
    "    print(x_valid__.shape)\n",
    "    print(y_valid__.shape)\n",
    "    print(x_test__.shape)\n",
    "    print(y_test__.shape)\n",
    "\n",
    "    image_size = x_train__.shape[1]\n",
    "    channels = x_train__.shape[3]\n",
    "    early_stopping = int(epochs_ * 0.1)\n",
    "\n",
    "    print(\"Build data generators\")\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range = 90,\n",
    "            width_shift_range = np.ceil(0.1 * image_size), \n",
    "            height_shift_range = np.ceil(0.1 * image_size),\n",
    "            horizontal_flip = True, \n",
    "            vertical_flip = True,\n",
    "            fill_mode = 'nearest')\n",
    "\n",
    "    test_validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range = 0,\n",
    "            width_shift_range = 0, \n",
    "            height_shift_range = 0,\n",
    "            horizontal_flip = False, \n",
    "            vertical_flip = False,\n",
    "            fill_mode = 'nearest')\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(patience = early_stopping, monitor = 'val_accuracy', verbose = 1),\n",
    "                 tf.keras.callbacks.ModelCheckpoint(filepath = os.path.join(results_directory, \"weights.h5\"),\n",
    "                                                    save_weights_only=True,\n",
    "                                                    monitor='val_accuracy',\n",
    "                                                    mode='max',\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "    model = build_model(image_size = image_size,\n",
    "                        channels = channels, \n",
    "                        start_neurons = start_neurons_,\n",
    "                        dense_neurons = dense_neurons_, \n",
    "                        classes = classes,\n",
    "                        model_name = model_name_)\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                      loss = tf.keras.losses.categorical_crossentropy,\n",
    "                      metrics = [\"accuracy\"])\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    if augmentation_ == True:\n",
    "        print(\"Augmentation mode on\")\n",
    "        train_generator = train_datagen.flow(x_train__, y_train__, batch_size = batch_size_)\n",
    "    else:\n",
    "        print(\"Augmentation mode off\")\n",
    "        train_generator = test_validation_datagen.flow(x_train__, y_train__, batch_size = batch_size_)\n",
    "\n",
    "    validation_generator = test_validation_datagen.flow(x_valid__, y_valid__, batch_size = batch_size_)\n",
    "\n",
    "    model_results = model.fit(train_generator,\n",
    "                              validation_data = validation_generator,\n",
    "                              steps_per_epoch = np.ceil(train_generator.n / batch_size_),\n",
    "                              validation_steps = np.ceil(validation_generator.n / batch_size_),\n",
    "                              epochs = epochs_,\n",
    "                              shuffle = True,\n",
    "                              callbacks = callbacks)\n",
    "\n",
    "    model = build_model(image_size = image_size,\n",
    "                        channels = channels, \n",
    "                        start_neurons = start_neurons_,\n",
    "                        dense_neurons = dense_neurons_, \n",
    "                        classes = classes,\n",
    "                        model_name = model_name_)\n",
    "\n",
    "    model.load_weights(os.path.join(results_directory, \"weights.h5\"))\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                      loss = tf.keras.losses.categorical_crossentropy,\n",
    "                      metrics = [\"accuracy\"])\n",
    "\n",
    "    model_results_pd = pd.DataFrame(model_results.history)\n",
    "    model_results_pd[\"model\"] = model_name_\n",
    "    model_results_pd[\"epoch\"] = np.array(model_results.epoch) + 1\n",
    "    model_results_pd[\"structuring_elements_depth\"] = str(structuring_elements_depth_)\n",
    "    model_results_pd[\"transormation_type\"] = transormation_type_\n",
    "    model_results_pd[\"structuring_elements_type\"] = structuring_elements_type_\n",
    "    model_results_pd[\"structuring_elements_initsize\"] = structuring_elements_initsize_\n",
    "    model_results_pd[\"structuring_elements_step\"] = structuring_elements_step_\n",
    "    model_results_pd[\"morphological_transformation_mode\"] = morphological_transformation_mode_\n",
    "    model_results_pd[\"start_neurons\"] = start_neurons_\n",
    "    model_results_pd[\"dense_neurons\"] = dense_neurons_\n",
    "    model_results_pd[\"epochs\"] = epochs_\n",
    "    model_results_pd[\"batch_size\"] = batch_size_\n",
    "    model_results_pd[\"augmentation\"] = augmentation_\n",
    "    model_results_pd.to_csv(os.path.join(results_directory,  model_name_ + \"_history.csv\"))\n",
    "\n",
    "    model_train_accuracy = model.evaluate(x_train__, y_train__)[1]\n",
    "    model_validation_accuracy = model.evaluate(x_valid__, y_valid__)[1]\n",
    "    model_test_accuracy = model.evaluate(x_test__, y_test__)[1]\n",
    "\n",
    "    print(\"Train accuracy:\", model_train_accuracy)\n",
    "    print(\"Validation accuracy:\", model_validation_accuracy)\n",
    "    print(\"Test accuracy:\", model_test_accuracy)\n",
    "\n",
    "    evaluation_results = pd.DataFrame({\"Dataset\" : [\"train\", \"validation\", \"test\"],\n",
    "                                       \"Accuracy\" : [model_train_accuracy, model_validation_accuracy, model_test_accuracy],\n",
    "                                       \"Model_Name\" : [model_name_] * 3})\n",
    "    evaluation_results[\"epochs\"] = model_results_pd.shape[0]\n",
    "    evaluation_results[\"structuring_elements_depth\"] = str(structuring_elements_depth_)\n",
    "    evaluation_results[\"transormation_type\"] = transormation_type_\n",
    "    evaluation_results[\"structuring_elements_type\"] = structuring_elements_type_\n",
    "    evaluation_results[\"structuring_elements_initsize\"] = structuring_elements_initsize_\n",
    "    evaluation_results[\"structuring_elements_step\"] = structuring_elements_step_\n",
    "    evaluation_results[\"morphological_transformation_mode\"] = morphological_transformation_mode_\n",
    "    evaluation_results[\"start_neurons\"] = start_neurons_\n",
    "    evaluation_results[\"dense_neurons\"] = dense_neurons_\n",
    "    evaluation_results[\"epochs\"] = epochs_\n",
    "    evaluation_results[\"batch_size\"] = batch_size_\n",
    "    evaluation_results[\"augmentation\"] = augmentation_\n",
    "    evaluation_results.to_csv(os.path.join(results_directory,  model_name_ + \"_evaluation.csv\"))\n",
    "\n",
    "    del model\n",
    "    del model_results_pd\n",
    "    del evaluation_results\n",
    "    os.remove(os.path.join(results_directory, \"weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ba9f20-4ac6-45fe-bb18-5320a28a5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandgrid(*itrs):\n",
    "    product = list(itertools.product(*itrs))\n",
    "    return {'Var{}'.format(i+1):[x[i] for x in product] for i in range(len(itrs))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4104539-941e-4f08-8ee1-fc451e67cc06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structuring_elements_depth_hp</th>\n",
       "      <th>transormation_type_hp</th>\n",
       "      <th>structuring_elements_type_hp</th>\n",
       "      <th>structuring_elements_step_hp</th>\n",
       "      <th>start_neurons_hp</th>\n",
       "      <th>dense_neurons_hp</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   structuring_elements_depth_hp transormation_type_hp  \\\n",
       "0                         [1, 1]                 cv_ed   \n",
       "1                         [1, 1]                 cv_ed   \n",
       "2                         [1, 1]                 cv_ed   \n",
       "3                         [1, 1]                 cv_ed   \n",
       "4                         [1, 1]                 cv_oc   \n",
       "5                         [1, 1]                 cv_oc   \n",
       "6                         [1, 1]                 cv_oc   \n",
       "7                         [1, 1]                 cv_oc   \n",
       "8                         [2, 2]                 cv_ed   \n",
       "9                         [2, 2]                 cv_ed   \n",
       "10                        [2, 2]                 cv_ed   \n",
       "11                        [2, 2]                 cv_ed   \n",
       "12                        [2, 2]                 cv_oc   \n",
       "13                        [2, 2]                 cv_oc   \n",
       "14                        [2, 2]                 cv_oc   \n",
       "15                        [2, 2]                 cv_oc   \n",
       "16                        [3, 3]                 cv_ed   \n",
       "17                        [3, 3]                 cv_ed   \n",
       "18                        [3, 3]                 cv_ed   \n",
       "19                        [3, 3]                 cv_ed   \n",
       "20                        [3, 3]                 cv_oc   \n",
       "21                        [3, 3]                 cv_oc   \n",
       "22                        [3, 3]                 cv_oc   \n",
       "23                        [3, 3]                 cv_oc   \n",
       "24                        [4, 4]                 cv_ed   \n",
       "25                        [4, 4]                 cv_ed   \n",
       "26                        [4, 4]                 cv_ed   \n",
       "27                        [4, 4]                 cv_ed   \n",
       "28                        [4, 4]                 cv_oc   \n",
       "29                        [4, 4]                 cv_oc   \n",
       "30                        [4, 4]                 cv_oc   \n",
       "31                        [4, 4]                 cv_oc   \n",
       "32                        [5, 5]                 cv_ed   \n",
       "33                        [5, 5]                 cv_ed   \n",
       "34                        [5, 5]                 cv_ed   \n",
       "35                        [5, 5]                 cv_ed   \n",
       "36                        [5, 5]                 cv_oc   \n",
       "37                        [5, 5]                 cv_oc   \n",
       "38                        [5, 5]                 cv_oc   \n",
       "39                        [5, 5]                 cv_oc   \n",
       "\n",
       "   structuring_elements_type_hp  structuring_elements_step_hp  \\\n",
       "0                          disk                             1   \n",
       "1                          disk                             1   \n",
       "2                          disk                             1   \n",
       "3                          disk                             1   \n",
       "4                          disk                             1   \n",
       "5                          disk                             1   \n",
       "6                          disk                             1   \n",
       "7                          disk                             1   \n",
       "8                          disk                             1   \n",
       "9                          disk                             1   \n",
       "10                         disk                             1   \n",
       "11                         disk                             1   \n",
       "12                         disk                             1   \n",
       "13                         disk                             1   \n",
       "14                         disk                             1   \n",
       "15                         disk                             1   \n",
       "16                         disk                             1   \n",
       "17                         disk                             1   \n",
       "18                         disk                             1   \n",
       "19                         disk                             1   \n",
       "20                         disk                             1   \n",
       "21                         disk                             1   \n",
       "22                         disk                             1   \n",
       "23                         disk                             1   \n",
       "24                         disk                             1   \n",
       "25                         disk                             1   \n",
       "26                         disk                             1   \n",
       "27                         disk                             1   \n",
       "28                         disk                             1   \n",
       "29                         disk                             1   \n",
       "30                         disk                             1   \n",
       "31                         disk                             1   \n",
       "32                         disk                             1   \n",
       "33                         disk                             1   \n",
       "34                         disk                             1   \n",
       "35                         disk                             1   \n",
       "36                         disk                             1   \n",
       "37                         disk                             1   \n",
       "38                         disk                             1   \n",
       "39                         disk                             1   \n",
       "\n",
       "    start_neurons_hp  dense_neurons_hp  id  \n",
       "0                 16               128   0  \n",
       "1                 16               256   1  \n",
       "2                 32               128   2  \n",
       "3                 32               256   3  \n",
       "4                 16               128   4  \n",
       "5                 16               256   5  \n",
       "6                 32               128   6  \n",
       "7                 32               256   7  \n",
       "8                 16               128   8  \n",
       "9                 16               256   9  \n",
       "10                32               128  10  \n",
       "11                32               256  11  \n",
       "12                16               128  12  \n",
       "13                16               256  13  \n",
       "14                32               128  14  \n",
       "15                32               256  15  \n",
       "16                16               128  16  \n",
       "17                16               256  17  \n",
       "18                32               128  18  \n",
       "19                32               256  19  \n",
       "20                16               128  20  \n",
       "21                16               256  21  \n",
       "22                32               128  22  \n",
       "23                32               256  23  \n",
       "24                16               128  24  \n",
       "25                16               256  25  \n",
       "26                32               128  26  \n",
       "27                32               256  27  \n",
       "28                16               128  28  \n",
       "29                16               256  29  \n",
       "30                32               128  30  \n",
       "31                32               256  31  \n",
       "32                16               128  32  \n",
       "33                16               256  33  \n",
       "34                32               128  34  \n",
       "35                32               256  35  \n",
       "36                16               128  36  \n",
       "37                16               256  37  \n",
       "38                32               128  38  \n",
       "39                32               256  39  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structuring_elements_depth_hp = [[1, 1], [2, 2], [3, 3], [4, 4], [5, 5]]\n",
    "transormation_type_hp = [\"cv_ed\", \"cv_oc\"]\n",
    "structuring_elements_type_hp = [\"disk\"]\n",
    "structuring_elements_step_hp = [1]\n",
    "start_neurons_hp = [16, 32]\n",
    "dense_neurons_hp = [128, 256]\n",
    "\n",
    "grid_big = pd.DataFrame(expandgrid(structuring_elements_depth_hp,\n",
    "                               transormation_type_hp,\n",
    "                               structuring_elements_type_hp,\n",
    "                               structuring_elements_step_hp,\n",
    "                               start_neurons_hp,\n",
    "                               dense_neurons_hp))\n",
    "grid_big[\"id\"] = list(np.arange(grid_big.shape[0]))\n",
    "grid_big.columns = [\"structuring_elements_depth_hp\", \n",
    "                \"transormation_type_hp\", \n",
    "                \"structuring_elements_type_hp\",\n",
    "                \"structuring_elements_step_hp\", \n",
    "                \"start_neurons_hp\", \n",
    "                \"dense_neurons_hp\",\n",
    "                \"id\"]\n",
    "grid_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba492d9-3802-4c10-bb46-7fd7aad1785a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_neurons_hp</th>\n",
       "      <th>dense_neurons_hp</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_neurons_hp  dense_neurons_hp  id\n",
       "0                16               128   0\n",
       "1                16               256   1\n",
       "2                32               128   2\n",
       "3                32               256   3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_neurons_hp = [16, 32]\n",
    "dense_neurons_hp = [128, 256]\n",
    "\n",
    "grid_small = pd.DataFrame(expandgrid(start_neurons_hp,\n",
    "                                     dense_neurons_hp))\n",
    "grid_small[\"id\"] = list(np.arange(grid_small.shape[0]))\n",
    "grid_small.columns = [\"start_neurons_hp\", \n",
    "                \"dense_neurons_hp\",\n",
    "                \"id\"]\n",
    "grid_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a77911-d0cb-46f2-bbe4-a990f4edc119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in np.arange(0, grid_small.shape[0]):\n",
    "    \n",
    "#     model_name_ = \"small_grid_model_\" + str(i)\n",
    "#     print(model_name_)\n",
    "    \n",
    "#     morphological_test_LAB_cifar_10(results_directory_ = \"Results_6\",\n",
    "#                                     model_name_ = model_name_,\n",
    "#                                     structuring_elements_depth_ = [0, 0],\n",
    "#                                     transormation_type_ = None,\n",
    "#                                     structuring_elements_type_ = None,\n",
    "#                                     structuring_elements_initsize_ = None,\n",
    "#                                     structuring_elements_step_ = None,\n",
    "#                                     addborder_ = None,\n",
    "#                                     morphological_transformation_mode_ = False,\n",
    "#                                     start_neurons_ = grid_small[\"start_neurons_hp\"][i],\n",
    "#                                     dense_neurons_ = grid_small[\"dense_neurons_hp\"][i],\n",
    "#                                     epochs_ = 100,\n",
    "#                                     batch_size_ = 512,\n",
    "#                                     augmentation_ = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "703bb8b5-4d68-47d7-a1df-3d2179118f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(30, grid_big.shape[0]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b7c740c-10a7-45a6-a17e-4e500e8e0d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big_grid_model_30\n",
      "1.train. Convert RGB to LAB\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "6.train. Stack L, A & B\n",
      "1.test. Convert RGB to LAB\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.test. Convert list to numpy array\n",
      "6.train. Stack L, A & B\n",
      "(40000, 32, 32, 11)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 11)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        3200      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,071,690\n",
      "Trainable params: 1,071,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (40000, 32, 32, 11) (11 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n",
      "C:\\Users\\admin\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (10000, 32, 32, 11) (11 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node big_grid_model_30/conv2d/Relu (defined at <ipython-input-6-4d1102631edd>:206) ]] [Op:__inference_train_function_901]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8febbe3ceb9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                     \u001b[0mepochs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                                     \u001b[0mbatch_size_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                                     augmentation_ = True)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-4d1102631edd>\u001b[0m in \u001b[0;36mmorphological_test_LAB_cifar_10\u001b[1;34m(results_directory_, model_name_, structuring_elements_depth_, transormation_type_, structuring_elements_type_, structuring_elements_initsize_, structuring_elements_step_, addborder_, morphological_transformation_mode_, start_neurons_, dense_neurons_, epochs_, batch_size_, augmentation_)\u001b[0m\n\u001b[0;32m    204\u001b[0m                               \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                               \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                               callbacks = callbacks)\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     model = build_model(image_size = image_size,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node big_grid_model_30/conv2d/Relu (defined at <ipython-input-6-4d1102631edd>:206) ]] [Op:__inference_train_function_901]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(30, grid_big.shape[0]):\n",
    "    \n",
    "    model_name_ = \"big_grid_model_\" + str(i)\n",
    "    print(model_name_)\n",
    "    \n",
    "    morphological_test_LAB_cifar_10(results_directory_ = \"Results_6\",\n",
    "                                    model_name_ = model_name_,\n",
    "                                    structuring_elements_depth_ = grid_big[\"structuring_elements_depth_hp\"][i],\n",
    "                                    transormation_type_ = grid_big[\"transormation_type_hp\"][i],\n",
    "                                    structuring_elements_type_ = grid_big[\"structuring_elements_type_hp\"][i],\n",
    "                                    structuring_elements_initsize_ = 1,\n",
    "                                    structuring_elements_step_ = grid_big[\"structuring_elements_step_hp\"][i],\n",
    "                                    addborder_ = True,\n",
    "                                    morphological_transformation_mode_ = True,\n",
    "                                    start_neurons_ = grid_big[\"start_neurons_hp\"][i],\n",
    "                                    dense_neurons_ = grid_big[\"dense_neurons_hp\"][i],\n",
    "                                    epochs_ = 100,\n",
    "                                    batch_size_ = 512,\n",
    "                                    augmentation_ = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab343f9-a1e2-4c72-9020-e0aa30a54343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# morphological_test_LAB_cifar_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f31c1-227f-4d02-8b07-8d286d945aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_ML_TF",
   "language": "python",
   "name": "gpu_ml_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
