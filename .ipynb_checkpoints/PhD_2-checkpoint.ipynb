{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:19.482052Z",
     "start_time": "2021-01-04T16:30:15.893647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import skimage.morphology as smo\n",
    "import time\n",
    "from random import randrange\n",
    "import itertools\n",
    "\n",
    "import glob \n",
    "\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numba import cuda \n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please ensure you have installed TensorFlow correctly')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:19.488036Z",
     "start_time": "2021-01-04T16:30:19.483049Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow_cv2(image, tytul = '', osie = False, opencv = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plot image\n",
    "    \"\"\"\n",
    "    \n",
    "    if not(osie):\n",
    "        plt.axis(\"off\") \n",
    "    if image.ndim == 2:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "    else:\n",
    "        if opencv:\n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            plt.imshow(image)\n",
    "    plt.title(tytul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:19.500004Z",
     "start_time": "2021-01-04T16:30:19.489033Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_add_border(image, x , y, val, rel = False):\n",
    "\n",
    "    \"\"\"\n",
    "    Adds a border to the input image\n",
    "    rel = True - x,y - size of the added border\n",
    "    rel = False - x,y - size of the image with added border\n",
    "    val - pixel value \n",
    "    \"\"\"\n",
    "    \n",
    "    (sx_org, sy_org) = image.shape\n",
    "    if rel:\n",
    "        sx = sx_org + 2*x\n",
    "        sy = sy_org + 2*y\n",
    "    else:\n",
    "        sx = x\n",
    "        sy = y\n",
    "    img = np.ones([sx, sy]) * val\n",
    "    [cx, cy] = ((np.array([sx, sy]) - np.array([sx_org, sy_org]))/2).astype('int')\n",
    "    img[cx:(cx + sx_org), cy:(cy + sy_org)] = image\n",
    "    return img\n",
    "\n",
    "# ---------- #\n",
    "# Use example:\n",
    "# obraz = imread(\"camel-19.gif\")\n",
    "# if len(obraz.shape) == 3:\n",
    "#     obraz = obraz[:,:,1]\n",
    "# print(obraz.shape)\n",
    "# obraz_ = image_add_border(obraz, x = 100, y = 100, val = 1, rel = True)\n",
    "# print(obraz_.shape)\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(obraz)\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(obraz_)\n",
    "# plt.show()\n",
    "# ---------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:19.511972Z",
     "start_time": "2021-01-04T16:30:19.501001Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_structuring_elements(n, type = 'disk', initsize = 1, step = 1):\n",
    "    \n",
    "    \"\"\"\n",
    "    generate a list of n structuring elements\n",
    "    type = 'disk', 'square', 'diamond'\n",
    "    \"\"\"\n",
    "    \n",
    "    selist = []\n",
    "    sesize = initsize\n",
    "    \n",
    "    for i in range(n):\n",
    "        if (type == 'disk'):\n",
    "            se = smo.disk(sesize)\n",
    "        if (type == 'square'):\n",
    "            se = smo.square(2 * sesize + 1)\n",
    "        if (type == 'diamond'):\n",
    "            se = smo.diamond(sesize)       \n",
    "        \n",
    "        selist.append(se)\n",
    "        sesize += step\n",
    "        \n",
    "    return selist\n",
    "\n",
    "# ---------- #\n",
    "# Use examples:\n",
    "# get_structuring_elements(3, type = \"square\")\n",
    "# get_structuring_elements(3, type = \"disk\")\n",
    "# get_structuring_elements(3, type = \"diamond\")\n",
    "# ---------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:19.528927Z",
     "start_time": "2021-01-04T16:30:19.512970Z"
    }
   },
   "outputs": [],
   "source": [
    "def morphological_stack(input_image,\n",
    "                        structuring_elements_depth,\n",
    "                        transormation_type = 'cv_oc',\n",
    "                        structuring_elements_type = 'disk',\n",
    "                        structuring_elements_initsize = 1,\n",
    "                        structuring_elements_step = 1,\n",
    "                        addborder = True):\n",
    "    \"\"\"\n",
    "    produce a stack of results of the morphological dual operators\n",
    "    input_image - imput image (binary or graylevel 2D image)\n",
    "    structuring_elements_depth - list of two values - numers of up-stack and down-stack images\n",
    "    transormation_type - type of operations erosion/dilation <-> opening/closing; skimage binary <-> skimage graytone <-> opencv\n",
    "    structuring_elements_type = structuring element type ('disk', 'square', 'diamond')\n",
    "    structuring_elements_initsize = initial size of the structuring element \n",
    "    structuring_elements_step = increment of the structuring element size\n",
    "    addborder = True if the external boundary is added, = False otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    max_up = structuring_elements_depth[0] # number of up-stack images (higher indeces, dilation/opening)\n",
    "    max_down = structuring_elements_depth[1] # number of down-stack images (kower indeces, erosion/closing)\n",
    "    max_updown = max(max_up, max_down)\n",
    "    \n",
    "    structuring_elements_list = get_structuring_elements(n = max_updown,\n",
    "                                                         type = structuring_elements_type, \n",
    "                                                         initsize = structuring_elements_initsize,\n",
    "                                                         step = structuring_elements_step)\n",
    "    if addborder:\n",
    "        image = image_add_border(image = input_image,\n",
    "                                 x = max_updown,\n",
    "                                 y = max_updown, \n",
    "                                 val = 0, \n",
    "                                 rel = True)\n",
    "    else:\n",
    "        image = input_image\n",
    "    \n",
    "    image_out = np.zeros([image.shape[0], image.shape[1], max_up + max_down + 1])    \n",
    "    count = 0\n",
    "\n",
    "    if transormation_type == 'b_ed': # binary erosion/dilation - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.binary_erosion\n",
    "        operator_up = smo.binary_dilation\n",
    "    elif transormation_type == 'b_oc': # binary opening/closing - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.binary_opening\n",
    "        operator_up = smo.binary_closing      \n",
    "    elif transormation_type == 'ed': # erosion/dilation - scikit.image     \n",
    "        opencv = False\n",
    "        operator_down = smo.erosion\n",
    "        operator_up = smo.dilation\n",
    "    elif transormation_type == 'oc': # opening/closing - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.opening\n",
    "        operator_up = smo.closing      \n",
    "    elif transormation_type == 'cv_ed': # erosion/dilation - openCV \n",
    "        opencv = True\n",
    "        operator_down = cv2.MORPH_ERODE\n",
    "        operator_up = cv2.MORPH_DILATE\n",
    "    else: # transormation_type == 'cv_oc': # opening/closing - openCV \n",
    "        opencv = True\n",
    "        operator_down = cv2.MORPH_OPEN\n",
    "        operator_up = cv2.MORPH_CLOSE     \n",
    "    \n",
    "    if opencv:  # opencv version \n",
    "        for i in range(max_down):\n",
    "            image_out[:,:,count] = cv2.morphologyEx(image,\n",
    "                                                    operator_down,\n",
    "                                                    structuring_elements_list[max_down - i - 1]); count += 1\n",
    "        image_out[:,:,count] = image; count += 1\n",
    "        for i in range(max_up):\n",
    "            image_out[:,:,count] = cv2.morphologyEx(image,\n",
    "                                                    operator_up, \n",
    "                                                    structuring_elements_list[i]); count += 1\n",
    "        \n",
    "    else:   # scikit image version\n",
    "        for i in range(max_down):\n",
    "            operator_down(image,\n",
    "                          selem = structuring_elements_list[max_down - i - 1],\n",
    "                          out = image_out[:,:,count]); count += 1\n",
    "        image_out[:,:,count] = image; count += 1\n",
    "        for i in range(max_up):\n",
    "            operator_up(image,\n",
    "                        selem = structuring_elements_list[i], \n",
    "                        out = image_out[:,:,count]); count += 1   \n",
    "        \n",
    "    return image_out\n",
    "\n",
    "# ---------- #\n",
    "# Use examples:\n",
    "# obraz = imread(\"camel-19.gif\")\n",
    "# if len(obraz.shape) == 3:\n",
    "#     obraz = obraz[:,:,1]\n",
    "# obraz_ = morphological_stack(input_image = obraz,\n",
    "#                              structuring_elements_depth = [2, 2])\n",
    "# obraz_.shape\n",
    "# ---------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:19.540895Z",
     "start_time": "2021-01-04T16:30:19.529924Z"
    }
   },
   "outputs": [],
   "source": [
    "def flat_morphological_stack(input_stack, normalize = True):\n",
    "\n",
    "    \"\"\"\n",
    "    flat morphological stack\n",
    "    normalize - convert result for pixel values between 0-1\n",
    "    \"\"\"\n",
    "    \n",
    "    max_up_down = input_stack.shape[2]\n",
    "    max_value = input_stack.max()\n",
    "    image_out = np.sum(input_stack/max_value, axis = 2)\n",
    "    if normalize:\n",
    "            image_out /= max_up_down\n",
    "    \n",
    "    return image_out\n",
    "\n",
    "# ---------- #\n",
    "# Use examples:\n",
    "# obraz = imread(\"camel-19.gif\")\n",
    "# if len(obraz.shape) == 3:\n",
    "#     obraz = obraz[:,:,1]\n",
    "# obraz_ = morphological_stack(input_image = obraz,\n",
    "#                              structuring_elements_depth = [25, 25],\n",
    "#                             transormation_type = \"cv_ed\")\n",
    "# obraz__ = flat_morphological_stack(input_stack = obraz_)\n",
    "# plt.imshow(obraz__)\n",
    "# ---------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:19.553860Z",
     "start_time": "2021-01-04T16:30:19.541892Z"
    }
   },
   "outputs": [],
   "source": [
    "def morphological_stack_with_flat(input_image,\n",
    "                                  structuring_elements_depth,\n",
    "                                  transormation_type = 'cv_oc',\n",
    "                                  structuring_elements_type = 'disk',\n",
    "                                  structuring_elements_initsize = 1,\n",
    "                                  structuring_elements_step = 1,\n",
    "                                  addborder = True,\n",
    "                                  normalize_flat = True):\n",
    "    \"\"\"\n",
    "    produce a stack of results of the morphological dual operators\n",
    "    input_image - imput image (binary or graylevel 2D image)\n",
    "    structuring_elements_depth - list of two values - numers of up-stack and down-stack images\n",
    "    transormation_type - type of operations erosion/dilation <-> opening/closing; skimage binary <-> skimage graytone <-> opencv\n",
    "    structuring_elements_type = structuring element type ('disk', 'square', 'diamond')\n",
    "    structuring_elements_initsize = initial size of the structuring element \n",
    "    structuring_elements_step = increment of the structuring element size\n",
    "    addborder = True if the external boundary is added, = False otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    max_up = structuring_elements_depth[0] # number of up-stack images (higher indeces, dilation/opening)\n",
    "    max_down = structuring_elements_depth[1] # number of down-stack images (kower indeces, erosion/closing)\n",
    "    max_updown = max(max_up, max_down)\n",
    "    \n",
    "    structuring_elements_list = get_structuring_elements(n = max_updown,\n",
    "                                                         type = structuring_elements_type, \n",
    "                                                         initsize = structuring_elements_initsize,\n",
    "                                                         step = structuring_elements_step)\n",
    "    if addborder:\n",
    "        image = image_add_border(image = input_image,\n",
    "                                 x = max_updown,\n",
    "                                 y = max_updown, \n",
    "                                 val = 0, \n",
    "                                 rel = True)\n",
    "    else:\n",
    "        image = input_image\n",
    "    \n",
    "    image_out = np.zeros([image.shape[0], image.shape[1], max_up + max_down + 1])    \n",
    "    count = 0\n",
    "\n",
    "    if transormation_type == 'b_ed': # binary erosion/dilation - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.binary_erosion\n",
    "        operator_up = smo.binary_dilation\n",
    "    elif transormation_type == 'b_oc': # binary opening/closing - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.binary_opening\n",
    "        operator_up = smo.binary_closing      \n",
    "    elif transormation_type == 'ed': # erosion/dilation - scikit.image     \n",
    "        opencv = False\n",
    "        operator_down = smo.erosion\n",
    "        operator_up = smo.dilation\n",
    "    elif transormation_type == 'oc': # opening/closing - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.opening\n",
    "        operator_up = smo.closing      \n",
    "    elif transormation_type == 'cv_ed': # erosion/dilation - openCV \n",
    "        opencv = True\n",
    "        operator_down = cv2.MORPH_ERODE\n",
    "        operator_up = cv2.MORPH_DILATE\n",
    "    else: # transormation_type == 'cv_oc': # opening/closing - openCV \n",
    "        opencv = True\n",
    "        operator_down = cv2.MORPH_OPEN\n",
    "        operator_up = cv2.MORPH_CLOSE     \n",
    "    \n",
    "    if opencv:  # opencv version \n",
    "        for i in range(max_down):\n",
    "            image_out[:,:,count] = cv2.morphologyEx(image,\n",
    "                                                    operator_down,\n",
    "                                                    structuring_elements_list[max_down - i - 1]); count += 1\n",
    "        image_out[:,:,count] = image; count += 1\n",
    "        for i in range(max_up):\n",
    "            image_out[:,:,count] = cv2.morphologyEx(image,\n",
    "                                                    operator_up, \n",
    "                                                    structuring_elements_list[i]); count += 1\n",
    "        \n",
    "    else:   # scikit image version\n",
    "        for i in range(max_down):\n",
    "            operator_down(image,\n",
    "                          selem = structuring_elements_list[max_down - i - 1],\n",
    "                          out = image_out[:,:,count]); count += 1\n",
    "        image_out[:,:,count] = image; count += 1\n",
    "        for i in range(max_up):\n",
    "            operator_up(image,\n",
    "                        selem = structuring_elements_list[i], \n",
    "                        out = image_out[:,:,count]); count += 1   \n",
    "            \n",
    "    image_out = flat_morphological_stack(input_stack = image_out, normalize = normalize_flat)\n",
    "        \n",
    "    return image_out\n",
    "\n",
    "# ---------- #\n",
    "# Use examples:\n",
    "# obraz = imread(\"camel-19.gif\")\n",
    "# if len(obraz.shape) == 3:\n",
    "#     obraz = obraz[:,:,1]\n",
    "# obraz_ = morphological_stack_with_flat(input_image = obraz,\n",
    "#                                        structuring_elements_depth = [10, 10])\n",
    "# obraz_.shape\n",
    "# ---------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T21:17:08.163582Z",
     "start_time": "2021-02-22T21:17:08.141612Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(image_size, channels, start_neurons, dense_neurons, classes, model_name = \"model_1\"):\n",
    "     \n",
    "    input_tensor = tf.keras.layers.Input(shape = [image_size, image_size, channels])\n",
    "\n",
    "    conv_1 = tf.keras.layers.Conv2D(filters = start_neurons * 1, \n",
    "                                    kernel_size = (3, 3),\n",
    "                                    strides = (1, 1), \n",
    "                                    activation = tf.keras.activations.relu,\n",
    "                                    padding = \"same\")(input_tensor)\n",
    "    conv_2 = tf.keras.layers.Conv2D(filters = start_neurons * 1, \n",
    "                                    kernel_size = (3, 3),\n",
    "                                    strides = (1, 1), \n",
    "                                    activation = tf.keras.activations.relu,\n",
    "                                    padding = \"same\")(conv_1)\n",
    "    conv_3 = tf.keras.layers.Conv2D(filters = start_neurons * 1, \n",
    "                                    kernel_size = (3, 3),\n",
    "                                    strides = (1, 1), \n",
    "                                    activation = tf.keras.activations.relu,\n",
    "                                    padding = \"same\")(conv_2)\n",
    "    pool_1 = tf.keras.layers.MaxPool2D(pool_size = (2, 2),\n",
    "                                       strides = (2, 2))(conv_3)\n",
    "\n",
    "    flatten = tf.keras.layers.Flatten()(pool_1)\n",
    "    dense = tf.keras.layers.Dense(units = dense_neurons, activation = tf.keras.activations.relu)(flatten)\n",
    "    output_tensor = tf.keras.layers.Dense(units = classes, activation = tf.keras.activations.softmax)(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = input_tensor, \n",
    "                                  outputs = output_tensor, \n",
    "                                  name = model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T21:17:11.550278Z",
     "start_time": "2021-02-22T21:17:11.536343Z"
    }
   },
   "outputs": [],
   "source": [
    "def expandgrid(*itrs):\n",
    "    product = list(itertools.product(*itrs))\n",
    "    return {'Var{}'.format(i+1):[x[i] for x in product] for i in range(len(itrs))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:19.675534Z",
     "start_time": "2021-01-04T16:30:19.579791Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def morphological_transformation_pipe(results_directory = \"D:/GitHub/PhD_Repository/Results/\",\n",
    "                                      model_name = \"model\",\n",
    "                                      data_directory = \"D:/GitHub/PhD_Repository/Datasets/MPEG7_CE-Shape-1_Part_B\",\n",
    "                                      image_size_ = 128,\n",
    "                                      morphological_transformation_mode = 0,\n",
    "                                      structuring_elements_depth_ = [5, 5],\n",
    "                                      transormation_type_ = \"cv_ed\",\n",
    "                                      structuring_elements_type_ = \"disk\",\n",
    "                                      structuring_elements_initsize_ = 1,\n",
    "                                      structuring_elements_step_ = 1,\n",
    "                                      addborder_ = True,\n",
    "                                      train_flip_augmentation = False,\n",
    "                                      validation_flip_augmentation = False,\n",
    "                                      test_flip_augmentation = False,\n",
    "                                      channels_ = 1,\n",
    "                                      start_neurons_ = 16,\n",
    "                                      dense_neurons_ = 512,\n",
    "                                      batch_size = 64,\n",
    "                                      epochs = 100,\n",
    "                                      early_stopping = 10,\n",
    "                                      shuffle = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    results_directory - directory where results are saved\n",
    "    model_name - string model name\n",
    "    data_directory - directory with input data\n",
    "    image_size_ - size of input (width, height) to CNN model\n",
    "    morphological_transformation_mode - 0 - without any morphological transformations\n",
    "                                      - 1 - with morphological transformations and stack of mola is stored in memory - require a lot od RAM for bigger stacks - memory insufficient method\n",
    "                                      - 2 - with morphological transformations and stack is normalized and flattened immediately - memory efficient method\n",
    "    structuring_elements_depth_ - MoLa stack size\n",
    "    transormation_type_ - e.g. erosion/dillataion or opening/closing\n",
    "    structuring_elements_type_ - e.g. disk, square, diamond\n",
    "    structuring_elements_initsize - structuring_elements_initsize_\n",
    "    structuring_elements_step_ - structuring_elements_step_\n",
    "    addborder_ - addborder\n",
    "    train_flip_augmentation - data generation/augmentation using flips: 90, 180, 270 degrees on train data\n",
    "    validation_flip_augmentation - data generation/augmentation using flips: 90, 180, 270 degrees on validation data\n",
    "    test_flip_augmentation - data generation/augmentation using flips: 90, 180, 270 degrees on test data\n",
    "    channels_ - depth in CNN model - greyscale images -> 1, RGB -> 3\n",
    "    start_neurons_ - filters in Conv layers\n",
    "    dense_neurons_ - neurond in dense layer between flattening and output layer\n",
    "    batch_size - number of images in one batch\n",
    "    epochs - epochs\n",
    "    early_stopping - early stopping\n",
    "    shuffle - randomly shuffle data during training \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    os.chdir(data_directory)\n",
    "\n",
    "    data = pd.DataFrame({\"Path\" : [os.path.join(os.getcwd(), i) for i in os.listdir()],\n",
    "                         \"Filename\" : [i for i in os.listdir()],\n",
    "                         \"Label\" : [i[0:i.find(\"-\")] for i in os.listdir()]}); data\n",
    "    data = data.merge(pd.DataFrame({\"Label\" : data[\"Label\"].unique().tolist(),\n",
    "                                    \"Numeric_Label\" : np.arange(len(data[\"Label\"].unique()))}), \n",
    "                      how = \"left\",\n",
    "                      on = \"Label\")\n",
    "\n",
    "    classes = len(data[\"Label\"].unique())\n",
    "\n",
    "    if morphological_transformation_mode == 1:\n",
    "\n",
    "        print(\"1. Step images_1:\")\n",
    "        images_1 = [imread(i) for i in data[\"Path\"].tolist()]\n",
    "        print(\"2. Step images_2:\")\n",
    "        images_2 = [i[:,:,0] if len(i.shape) == 3 else i for i in images_1]\n",
    "        del images_1\n",
    "        print(\"3. Step images_3:\")\n",
    "        images_3 = [morphological_stack(input_image = i,\n",
    "                                      structuring_elements_depth = structuring_elements_depth_,\n",
    "                                      transormation_type = transormation_type_,\n",
    "                                      structuring_elements_type = structuring_elements_type_,\n",
    "                                      structuring_elements_initsize = structuring_elements_initsize_,\n",
    "                                      structuring_elements_step = structuring_elements_step_,\n",
    "                                      addborder = addborder_) for i in images_2]\n",
    "        del images_2\n",
    "        print(\"4. Step images_4:\")\n",
    "        images_4 = [flat_morphological_stack(i) for i in images_3]\n",
    "        del images_3\n",
    "        print(\"5. Step images_5:\")\n",
    "        images_5 = [cv2.resize(i, (image_size_, image_size_)) for i in images_4]\n",
    "        del images_4\n",
    "        print(\"6. Step images_6:\")\n",
    "        images_6 = [np.expand_dims(i, -1) for i in images_5]\n",
    "        del images_5\n",
    "        print(\"7. Step images_7:\")\n",
    "        images_7 = [np.expand_dims(i, 0) for i in images_6]\n",
    "        del images_6\n",
    "        print(\"8. Step images_8:\")\n",
    "        images_8 = np.concatenate(np.array(images_7), axis = 0)\n",
    "        del images_7\n",
    "\n",
    "    elif morphological_transformation_mode == 2:\n",
    "        \n",
    "        print(\"1. Step images_1:\")\n",
    "        images_1 = [imread(i) for i in data[\"Path\"].tolist()]\n",
    "        print(\"2. Step images_2:\")\n",
    "        images_2 = [i[:,:,0] if len(i.shape) == 3 else i for i in images_1]\n",
    "        del images_1\n",
    "        print(\"3. Step images_3:\")\n",
    "        images_3 = [morphological_stack_with_flat(input_image = i,\n",
    "                                                  structuring_elements_depth = structuring_elements_depth_,\n",
    "                                                  transormation_type = transormation_type_,\n",
    "                                                  structuring_elements_type = structuring_elements_type_,\n",
    "                                                  structuring_elements_initsize = structuring_elements_initsize_,\n",
    "                                                  structuring_elements_step = structuring_elements_step_,\n",
    "                                                  addborder = addborder_) for i in images_2]\n",
    "        del images_2\n",
    "        print(\"4. Step images_4:\")\n",
    "        images_4 = images_3\n",
    "        del images_3\n",
    "        print(\"5. Step images_5:\")\n",
    "        images_5 = [cv2.resize(i, (image_size_, image_size_)) for i in images_4]\n",
    "        del images_4\n",
    "        print(\"6. Step images_6:\")\n",
    "        images_6 = [np.expand_dims(i, -1) for i in images_5]\n",
    "        del images_5\n",
    "        print(\"7. Step images_7:\")\n",
    "        images_7 = [np.expand_dims(i, 0) for i in images_6]\n",
    "        del images_6\n",
    "        print(\"8. Step images_8:\")\n",
    "        images_8 = np.concatenate(np.array(images_7), axis = 0)\n",
    "        del images_7\n",
    "        \n",
    "    else: # morphological_transformation_mode == 0:\n",
    "\n",
    "        print(\"1. Step images_1:\")\n",
    "        images_1 = [imread(i) for i in data[\"Path\"].tolist()]\n",
    "        print(\"2. Step images_2:\")\n",
    "        images_2 = [i[:,:,0] if len(i.shape) == 3 else i for i in images_1]\n",
    "        del images_1\n",
    "        print(\"3. Step images_3:\")\n",
    "        images_3 = images_2\n",
    "        del images_2\n",
    "        print(\"4. Step images_4:\")\n",
    "        images_4 = images_3\n",
    "        del images_3\n",
    "        print(\"5. Step images_5:\")\n",
    "        images_5 = [cv2.resize(i, (image_size_, image_size_)) for i in images_4]\n",
    "        del images_4\n",
    "        print(\"6. Step images_6:\")\n",
    "        images_6 = [np.expand_dims(i, -1) for i in images_5]\n",
    "        del images_5\n",
    "        print(\"7. Step images_7:\")\n",
    "        images_7 = [np.expand_dims(i, 0) for i in images_6]\n",
    "        del images_6\n",
    "        print(\"8. Step images_8:\")\n",
    "        images_8 = np.concatenate(np.array(images_7), axis = 0)\n",
    "        del images_7\n",
    "\n",
    "    print(np.array(images_8).shape)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    X = np.arange(1400)\n",
    "    y = np.arange(1400)\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size = 0.25, random_state = 42)\n",
    "\n",
    "    X_train_ = images_8[X_train,:,:,:]\n",
    "    y_train_ = np.array(data[\"Numeric_Label\"])[y_train]\n",
    "    X_valid_ = images_8[X_valid,:,:,:]\n",
    "    y_valid_ = np.array(data[\"Numeric_Label\"])[y_valid]\n",
    "    X_test_ = images_8[X_test,:,:,:]\n",
    "    y_test_ = np.array(data[\"Numeric_Label\"])[y_test]\n",
    "\n",
    "    if train_flip_augmentation:\n",
    "        X_train_0 = [np.flip(i, axis = 0) for i in X_train_]\n",
    "        X_train_1 = [np.flip(i, axis = 1) for i in X_train_]\n",
    "        X_train_2 = [np.flip(np.flip(i, axis = 0), axis = 1) for i in X_train_]\n",
    "        X_train_ = np.concatenate((X_train_, X_train_0, X_train_1, X_train_2), axis = 0)\n",
    "        y_train_ = np.concatenate((y_train_, y_train_, y_train_, y_train_), axis = 0)\n",
    "\n",
    "    if validation_flip_augmentation:\n",
    "        X_valid_0 = [np.flip(i, axis = 0) for i in X_valid_]\n",
    "        X_valid_1 = [np.flip(i, axis = 1) for i in X_valid_]\n",
    "        X_valid_2 = [np.flip(np.flip(i, axis = 0), axis = 1) for i in X_valid_]\n",
    "        X_valid_ = np.concatenate((X_valid_, X_valid_0, X_valid_1, X_valid_2), axis = 0)\n",
    "        y_valid_ = np.concatenate((y_valid_, y_valid_, y_valid_, y_valid_), axis = 0)\n",
    "\n",
    "    if test_flip_augmentation:\n",
    "        X_test_0 = [np.flip(i, axis = 0) for i in X_test_]\n",
    "        X_test_1 = [np.flip(i, axis = 1) for i in X_test_]\n",
    "        X_test_2 = [np.flip(np.flip(i, axis = 0), axis = 1) for i in X_test_]\n",
    "        X_test_ = np.concatenate((X_test_, X_test_0, X_test_1, X_test_2), axis = 0)\n",
    "        y_test_ = np.concatenate((y_test_, y_test_, y_test_, y_test_), axis = 0)\n",
    "\n",
    "    y_train_ = tf.keras.utils.to_categorical(y_train_, classes)\n",
    "    y_valid_ = tf.keras.utils.to_categorical(y_valid_, classes)\n",
    "    y_test_ = tf.keras.utils.to_categorical(y_test_, classes)\n",
    "\n",
    "    print(X_train_.shape)\n",
    "    print(y_train_.shape)\n",
    "    print(X_valid_.shape)\n",
    "    print(y_valid_.shape)\n",
    "    print(X_test_.shape)\n",
    "    print(y_test_.shape)\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(patience = early_stopping, monitor = 'val_loss')]\n",
    "\n",
    "    model = build_model(image_size = image_size_,\n",
    "                        channels = channels_, \n",
    "                        start_neurons = start_neurons_,\n",
    "                        dense_neurons = dense_neurons_, \n",
    "                        classes = classes)\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                    loss = tf.keras.losses.categorical_crossentropy,\n",
    "                    metrics = [\"accuracy\"])\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model_results = model.fit(X_train_,\n",
    "                                  y_train_, \n",
    "                                  batch_size = batch_size, \n",
    "                                  epochs = epochs, \n",
    "                                  shuffle = shuffle,\n",
    "                                  callbacks = callbacks,\n",
    "                                  validation_data = (X_valid_, y_valid_))\n",
    "\n",
    "    model_results_pd = pd.DataFrame(model_results.history)\n",
    "    model_results_pd[\"model\"] = model_name\n",
    "    model_results_pd[\"epoch\"] = np.array(model_results.epoch) + 1\n",
    "    model_results_pd.to_csv(results_directory + model_name + \"_history.csv\")\n",
    "    print(model_results_pd)\n",
    "\n",
    "    model_train_accuracy = model.evaluate(X_train_, y_train_)[1]\n",
    "    model_validation_accuracy = model.evaluate(X_valid_, y_valid_)[1]\n",
    "    model_test_accuracy = model.evaluate(X_test_, y_test_)[1]\n",
    "    del model\n",
    "\n",
    "    print(\"Train accuracy:\", model_train_accuracy)\n",
    "    print(\"Validation accuracy:\", model_validation_accuracy)\n",
    "    print(\"Test accuracy:\", model_test_accuracy)\n",
    "\n",
    "    evaluation_results = pd.DataFrame({\"Dataset\" : [\"train\", \"validation\", \"test\"],\n",
    "                                       \"Accuracy\" : [model_train_accuracy, model_validation_accuracy, model_test_accuracy],\n",
    "                                       \"Model_Name\" : [model_name] * 3})\n",
    "    evaluation_results.to_csv(results_directory + model_name + \"_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:19.688500Z",
     "start_time": "2021-01-04T16:30:19.676532Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reference models - without morphological transformations:\n",
    "# sizes = [64, 128, 256]\n",
    "\n",
    "# for i in np.arange(len(sizes)):\n",
    "#     morphological_transformation_pipe(\n",
    "#         model_name = \"reference_model_\" + str(sizes[i]),\n",
    "#         data_directory = \"D:/GitHub/PhD_Repository/Datasets/MPEG7_CE-Shape-1_Part_B\",\n",
    "#         image_size_ = sizes[i],\n",
    "#         train_flip_augmentation = True,\n",
    "#         validation_flip_augmentation = True,\n",
    "#         test_flip_augmentation = True)\n",
    "#     tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:19.700468Z",
     "start_time": "2021-01-04T16:30:19.689498Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dillatation - erosion morphological transformations\n",
    "# sizes_hp = [64, 128, 256]\n",
    "# structuring_elements_depth_hp = [[2, 2], [5, 5]]\n",
    "# transormation_type_hp = [\"cv_ed\"]\n",
    "# structuring_elements_type_hp = [\"disk\", \"square\", \"diamond\"]\n",
    "# structuring_elements_step_hp = [1, 2]\n",
    "\n",
    "# grid = pd.DataFrame(expandgrid(sizes_hp,\n",
    "#                                structuring_elements_depth_hp,\n",
    "#                                transormation_type_hp,\n",
    "#                                structuring_elements_type_hp,\n",
    "#                                structuring_elements_step_hp))\n",
    "\n",
    "# for i in np.arange(34, grid.shape[0]):\n",
    "#     model_name_ = \"dillatation_erosion_\" + str(grid[\"Var1\"][i]) + \"_\" + str(grid[\"Var2\"][i]) + \"_\" + str(grid[\"Var3\"][i]) + \"_\" + str(grid[\"Var4\"][i]) + \"_\" + str(grid[\"Var5\"][i])\n",
    "#     morphological_transformation_pipe(\n",
    "#         morphological_transformation_mode = 2,\n",
    "#         model_name = model_name_,\n",
    "#         data_directory = \"D:/GitHub/PhD_Repository/Datasets/MPEG7_CE-Shape-1_Part_B\",\n",
    "#         image_size_ = grid[\"Var1\"][i],\n",
    "#         structuring_elements_depth_ = grid[\"Var2\"][i],\n",
    "#         transormation_type_ = grid[\"Var3\"][i],\n",
    "#         structuring_elements_type_ = grid[\"Var4\"][i],    \n",
    "#         structuring_elements_step_ = grid[\"Var5\"][i],\n",
    "#         train_flip_augmentation = True,\n",
    "#         validation_flip_augmentation = True,\n",
    "#         test_flip_augmentation = True)\n",
    "#     tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:19.712436Z",
     "start_time": "2021-01-04T16:30:19.701465Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # opening - closing morphological transformations\n",
    "# sizes_hp = [64, 128, 256]\n",
    "# structuring_elements_depth_hp = [[2, 2], [5, 5]]\n",
    "# transormation_type_hp = [\"cv_oc\"]\n",
    "# structuring_elements_type_hp = [\"disk\", \"square\", \"diamond\"]\n",
    "# structuring_elements_step_hp = [1, 2]\n",
    "\n",
    "# grid = pd.DataFrame(expandgrid(sizes_hp,\n",
    "#                                structuring_elements_depth_hp,\n",
    "#                                transormation_type_hp,\n",
    "#                                structuring_elements_type_hp,\n",
    "#                                structuring_elements_step_hp))\n",
    "\n",
    "# for i in np.arange(34, grid.shape[0]):\n",
    "#     model_name_ = \"opening_closing_\" + str(grid[\"Var1\"][i]) + \"_\" + str(grid[\"Var2\"][i]) + \"_\" + str(grid[\"Var3\"][i]) + \"_\" + str(grid[\"Var4\"][i]) + \"_\" + str(grid[\"Var5\"][i])\n",
    "#     morphological_transformation_pipe(\n",
    "#         morphological_transformation_mode = 2,\n",
    "#         model_name = model_name_,\n",
    "#         data_directory = \"D:/GitHub/PhD_Repository/Datasets/MPEG7_CE-Shape-1_Part_B\",\n",
    "#         image_size_ = grid[\"Var1\"][i],\n",
    "#         structuring_elements_depth_ = grid[\"Var2\"][i],\n",
    "#         transormation_type_ = grid[\"Var3\"][i],\n",
    "#         structuring_elements_type_ = grid[\"Var4\"][i],    \n",
    "#         structuring_elements_step_ = grid[\"Var5\"][i],\n",
    "#         train_flip_augmentation = True,\n",
    "#         validation_flip_augmentation = True,\n",
    "#         test_flip_augmentation = True)\n",
    "#     tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:20.099402Z",
     "start_time": "2021-01-04T16:30:19.713433Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MoLa_Type</th>\n",
       "      <th>Dataset</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dillatation_erosion</td>\n",
       "      <td>test</td>\n",
       "      <td>0.797321</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.830605</td>\n",
       "      <td>0.834375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>opening_closing</td>\n",
       "      <td>test</td>\n",
       "      <td>0.791964</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.815030</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reference_model</td>\n",
       "      <td>test</td>\n",
       "      <td>0.698214</td>\n",
       "      <td>0.782143</td>\n",
       "      <td>0.745238</td>\n",
       "      <td>0.755357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dillatation_erosion</td>\n",
       "      <td>train</td>\n",
       "      <td>0.990774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999694</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>opening_closing</td>\n",
       "      <td>train</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reference_model</td>\n",
       "      <td>train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dillatation_erosion</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.837029</td>\n",
       "      <td>0.838839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>opening_closing</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.786607</td>\n",
       "      <td>0.845536</td>\n",
       "      <td>0.818576</td>\n",
       "      <td>0.823214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reference_model</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.697321</td>\n",
       "      <td>0.797321</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MoLa_Type     Dataset  Accuracy                              \n",
       "                                         min       max      mean    median\n",
       "0  dillatation_erosion        test  0.797321  0.861607  0.830605  0.834375\n",
       "3      opening_closing        test  0.791964  0.843750  0.815030  0.814286\n",
       "6      reference_model        test  0.698214  0.782143  0.745238  0.755357\n",
       "1  dillatation_erosion       train  0.990774  1.000000  0.999694  1.000000\n",
       "4      opening_closing       train  0.997917  1.000000  0.999884  1.000000\n",
       "7      reference_model       train  1.000000  1.000000  1.000000  1.000000\n",
       "2  dillatation_erosion  validation  0.807143  0.861607  0.837029  0.838839\n",
       "5      opening_closing  validation  0.786607  0.845536  0.818576  0.823214\n",
       "8      reference_model  validation  0.697321  0.797321  0.752381  0.762500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wniosek 1. - wykorzystanie stosu warstw morfologicznych, ich znormalizowanie i spłaszczenie i użycie jako \n",
      "input do modelu CNN pozwala osiągnąć wyższe wyniki dokładności, niż bez ich wykorzystania. Stosowanie połęczenia \n",
      "operacji dylatacji i erozji pozwala osiągać lepsze wyniki, niż operacji otwarć i zamknięć.\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Dataset</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>064</td>\n",
       "      <td>test</td>\n",
       "      <td>0.798214</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.833743</td>\n",
       "      <td>0.836607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>test</td>\n",
       "      <td>0.801786</td>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.826153</td>\n",
       "      <td>0.826339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>test</td>\n",
       "      <td>0.791964</td>\n",
       "      <td>0.834821</td>\n",
       "      <td>0.808557</td>\n",
       "      <td>0.804018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>064</td>\n",
       "      <td>train</td>\n",
       "      <td>0.990774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>064</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.838951</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.813393</td>\n",
       "      <td>0.858036</td>\n",
       "      <td>0.833110</td>\n",
       "      <td>0.832589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.786607</td>\n",
       "      <td>0.851786</td>\n",
       "      <td>0.811347</td>\n",
       "      <td>0.807143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Size     Dataset  Accuracy                              \n",
       "                         min       max      mean    median\n",
       "0  064        test  0.798214  0.861607  0.833743  0.836607\n",
       "3  128        test  0.801786  0.846429  0.826153  0.826339\n",
       "6  256        test  0.791964  0.834821  0.808557  0.804018\n",
       "1  064       train  0.990774  1.000000  0.999368  1.000000\n",
       "4  128       train  1.000000  1.000000  1.000000  1.000000\n",
       "7  256       train  1.000000  1.000000  1.000000  1.000000\n",
       "2  064  validation  0.817857  0.861607  0.838951  0.837500\n",
       "5  128  validation  0.813393  0.858036  0.833110  0.832589\n",
       "8  256  validation  0.786607  0.851786  0.811347  0.807143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wniosek 2. - Dla modeli CNN bazujących na zdjeciach przekształconych przy użyciu operacji morfologicznych\n",
      "lepsze wyniki osiągano, gdy zdjecia miały mniejsze rozmiary inputu (skalowanie zdjęć odbywało się po zastosowaniu\n",
      "transformacji morfologicznych, a nie przed nimi)\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Stack_dimension</th>\n",
       "      <th>Dataset</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>test</td>\n",
       "      <td>0.791964</td>\n",
       "      <td>0.845536</td>\n",
       "      <td>0.819196</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>test</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.826438</td>\n",
       "      <td>0.829464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>train</td>\n",
       "      <td>0.990774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999719</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>train</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999859</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.786607</td>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.821776</td>\n",
       "      <td>0.826339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.833829</td>\n",
       "      <td>0.837054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stack_dimension     Dataset  Accuracy                              \n",
       "                                    min       max      mean    median\n",
       "0          [2, 2]        test  0.791964  0.845536  0.819196  0.825000\n",
       "3          [5, 5]        test  0.793750  0.861607  0.826438  0.829464\n",
       "1          [2, 2]       train  0.990774  1.000000  0.999719  1.000000\n",
       "4          [5, 5]       train  0.997917  1.000000  0.999859  1.000000\n",
       "2          [2, 2]  validation  0.786607  0.846429  0.821776  0.826339\n",
       "5          [5, 5]  validation  0.794643  0.861607  0.833829  0.837054"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wniosek 3. - Dla modeli CNN bazujących na zdjęciach przekształconych przy użyciu operacji morfologicznych\n",
      "lepsze wyniki osiągano, gdy tworzono głębszy stos przekształceń morfologicznych)\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Structuring_Element</th>\n",
       "      <th>Dataset</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diamond</td>\n",
       "      <td>test</td>\n",
       "      <td>0.791964</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.822545</td>\n",
       "      <td>0.827679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disk</td>\n",
       "      <td>test</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.823847</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>square</td>\n",
       "      <td>test</td>\n",
       "      <td>0.795536</td>\n",
       "      <td>0.849107</td>\n",
       "      <td>0.822061</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diamond</td>\n",
       "      <td>train</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disk</td>\n",
       "      <td>train</td>\n",
       "      <td>0.999702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>square</td>\n",
       "      <td>train</td>\n",
       "      <td>0.990774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diamond</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.828720</td>\n",
       "      <td>0.833482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>disk</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.786607</td>\n",
       "      <td>0.858036</td>\n",
       "      <td>0.827790</td>\n",
       "      <td>0.834375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>square</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.854464</td>\n",
       "      <td>0.826897</td>\n",
       "      <td>0.830357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Structuring_Element     Dataset  Accuracy                              \n",
       "                                        min       max      mean    median\n",
       "0             diamond        test  0.791964  0.861607  0.822545  0.827679\n",
       "3                disk        test  0.794643  0.846429  0.823847  0.828125\n",
       "6              square        test  0.795536  0.849107  0.822061  0.825000\n",
       "1             diamond       train  0.997917  1.000000  0.999888  1.000000\n",
       "4                disk       train  0.999702  1.000000  0.999988  1.000000\n",
       "7              square       train  0.990774  1.000000  0.999492  1.000000\n",
       "2             diamond  validation  0.794643  0.861607  0.828720  0.833482\n",
       "5                disk  validation  0.786607  0.858036  0.827790  0.834375\n",
       "8              square  validation  0.787500  0.854464  0.826897  0.830357"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wniosek 4. - Dla modeli CNN bazujących na zdjęciach przekształconych przy użyciu operacji morfologicznych wyniki\n",
      "są porównywalne dla zastosowanych 3 rodzajów kerneli/elementów strukturyzujących  tj. dysk, square, diamond)\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Structuring_Element_Step</th>\n",
       "      <th>Dataset</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>0.791964</td>\n",
       "      <td>0.849107</td>\n",
       "      <td>0.822768</td>\n",
       "      <td>0.827679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.822867</td>\n",
       "      <td>0.826339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.998512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>0.990774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999636</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.791071</td>\n",
       "      <td>0.854464</td>\n",
       "      <td>0.826959</td>\n",
       "      <td>0.832589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.786607</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.828646</td>\n",
       "      <td>0.832589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Structuring_Element_Step     Dataset  Accuracy                              \n",
       "                                             min       max      mean    median\n",
       "0                        1        test  0.791964  0.849107  0.822768  0.827679\n",
       "3                        2        test  0.792857  0.861607  0.822867  0.826339\n",
       "1                        1       train  0.998512  1.000000  0.999942  1.000000\n",
       "4                        2       train  0.990774  1.000000  0.999636  1.000000\n",
       "2                        1  validation  0.791071  0.854464  0.826959  0.832589\n",
       "5                        2  validation  0.786607  0.861607  0.828646  0.832589"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wniosek 5. - Dla modeli CNN bazujących na zdjęciach przekształconych przy użyciu operacji morfologicznych wyniki\n",
      "są porównywalne dla zastosowanego stepu w tworzeniu stosu warstw morfologicznych\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"D:/GitHub/PhD_Repository/Results\")\n",
    "\n",
    "\n",
    "# Suffixes\n",
    "evaluation_suffix = 'evaluation.csv'\n",
    "history_suffix = 'history.csv'\n",
    "\n",
    "# Reference model:\n",
    "reference_evaluation = glob.glob('./reference*')\n",
    "reference_evaluation = [k for k in reference_evaluation if evaluation_suffix in k]\n",
    "reference_evaluation = [pd.read_csv(i) for i in reference_evaluation]\n",
    "reference_evaluation = pd.concat(reference_evaluation)\n",
    "\n",
    "reference_history = glob.glob('./reference*')\n",
    "reference_history = [k for k in reference_history if history_suffix in k]\n",
    "reference_history = [pd.read_csv(i) for i in reference_history]\n",
    "reference_history = pd.concat(reference_history)\n",
    "\n",
    "# Dillatation-Erosion model:\n",
    "de_evaluation = glob.glob('./dillatation_erosion*')\n",
    "de_evaluation = [k for k in de_evaluation if evaluation_suffix in k]\n",
    "de_evaluation = [pd.read_csv(i) for i in de_evaluation]\n",
    "de_evaluation = pd.concat(de_evaluation)\n",
    "\n",
    "de_history = glob.glob('./dillatation_erosion*')\n",
    "de_history = [k for k in de_history if history_suffix in k]\n",
    "de_history = [pd.read_csv(i) for i in de_history]\n",
    "de_history = pd.concat(de_history)\n",
    "\n",
    "# Opening-Closing model:\n",
    "oc_evaluation = glob.glob('./opening_closing*')\n",
    "oc_evaluation = [k for k in oc_evaluation if evaluation_suffix in k]\n",
    "oc_evaluation = [pd.read_csv(i) for i in oc_evaluation]\n",
    "oc_evaluation = pd.concat(oc_evaluation)\n",
    "\n",
    "oc_history = glob.glob('./opening_closing*')\n",
    "oc_history = [k for k in oc_history if history_suffix in k]\n",
    "oc_history = [pd.read_csv(i) for i in oc_history]\n",
    "oc_history = pd.concat(oc_history)\n",
    "\n",
    "evaluation_all = pd.concat([reference_evaluation, de_evaluation, oc_evaluation])\n",
    "evaluation_all = evaluation_all[[\"Model_Name\", \"Dataset\", \"Accuracy\"]]\n",
    "evaluation_all = evaluation_all.reset_index(drop = True)\n",
    "evaluation_all\n",
    "\n",
    "evaluation_all[\"MoLa_Type\"] = np.where(evaluation_all[\"Model_Name\"].str.contains(\"reference_model\"), \"reference_model\", \n",
    "                                 np.where(evaluation_all[\"Model_Name\"].str.contains(\"opening_closing\"), \"opening_closing\",\n",
    "                                          \"dillatation_erosion\"))\n",
    "evaluation_all[\"Size\"] = np.where(evaluation_all[\"Model_Name\"].str.contains(\"_64\"), \"064\", \n",
    "                                 np.where(evaluation_all[\"Model_Name\"].str.contains(\"_128\"), \"128\",\n",
    "                                          \"256\"))\n",
    "\n",
    "evaluation_all[\"Stack_dimension\"] = np.where(evaluation_all[\"Model_Name\"].str.contains(\"5, 5\"), \"[5, 5]\", \n",
    "                                 np.where(evaluation_all[\"Model_Name\"].str.contains(\"2, 2\"), \"[2, 2]\",\n",
    "                                          \"[0, 0]\"))\n",
    "\n",
    "evaluation_all[\"Structuring_Element\"] = np.where(evaluation_all[\"Model_Name\"].str.contains(\"disk\"), \"disk\", \n",
    "                                 np.where(evaluation_all[\"Model_Name\"].str.contains(\"diamond\"), \"diamond\",\n",
    "                                          \"square\"))\n",
    "\n",
    "evaluation_all[\"Structuring_Element_Step\"] = np.where(evaluation_all[\"Model_Name\"].str.endswith(\"_1\"), \"1\", \n",
    "                                 np.where(evaluation_all[\"Model_Name\"].str.endswith(\"_2\"), \"2\",\n",
    "                                          \"0\"))\n",
    "\n",
    "evaluation_all_1 = evaluation_all[[\"MoLa_Type\", \"Dataset\", \"Accuracy\"]].groupby([\"MoLa_Type\", \"Dataset\"]).agg([min, max, np.mean, np.median])\n",
    "evaluation_all_1 = evaluation_all_1.reset_index()\n",
    "evaluation_all_1 = evaluation_all_1.sort_values([\"Dataset\", \"MoLa_Type\"])\n",
    "print(\"-------------------------------------------------\")\n",
    "display(evaluation_all_1)\n",
    "print(\"\"\"Wniosek 1. - wykorzystanie stosu warstw morfologicznych, ich znormalizowanie i spłaszczenie i użycie jako \n",
    "input do modelu CNN pozwala osiągnąć wyższe wyniki dokładności, niż bez ich wykorzystania. Stosowanie połęczenia \n",
    "operacji dylatacji i erozji pozwala osiągać lepsze wyniki, niż operacji otwarć i zamknięć.\"\"\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "evaluation_all_2 = evaluation_all[[\"MoLa_Type\", \"Size\", \"Dataset\", \"Accuracy\"]]\n",
    "evaluation_all_2 = evaluation_all_2[evaluation_all_2[\"MoLa_Type\"].isin([\"opening_closing\", \"dillatation_erosion\"])]\n",
    "evaluation_all_2 = evaluation_all_2.groupby([\"Size\", \"Dataset\"]).agg([min, max, np.mean, np.median])\n",
    "evaluation_all_2 = evaluation_all_2.reset_index()\n",
    "evaluation_all_2 = evaluation_all_2.sort_values([\"Dataset\", \"Size\"])\n",
    "display(evaluation_all_2)\n",
    "print(\"\"\"Wniosek 2. - Dla modeli CNN bazujących na zdjeciach przekształconych przy użyciu operacji morfologicznych\n",
    "lepsze wyniki osiągano, gdy zdjecia miały mniejsze rozmiary inputu (skalowanie zdjęć odbywało się po zastosowaniu\n",
    "transformacji morfologicznych, a nie przed nimi)\"\"\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "evaluation_all_3 = evaluation_all[[\"MoLa_Type\", \"Stack_dimension\", \"Dataset\", \"Accuracy\"]]\n",
    "evaluation_all_3 = evaluation_all_3[evaluation_all_3[\"MoLa_Type\"].isin([\"opening_closing\", \"dillatation_erosion\"])]\n",
    "evaluation_all_3 = evaluation_all_3.groupby([\"Stack_dimension\", \"Dataset\"]).agg([min, max, np.mean, np.median])\n",
    "evaluation_all_3 = evaluation_all_3.reset_index()\n",
    "evaluation_all_3 = evaluation_all_3.sort_values([\"Dataset\", \"Stack_dimension\"])\n",
    "display(evaluation_all_3)\n",
    "print(\"\"\"Wniosek 3. - Dla modeli CNN bazujących na zdjęciach przekształconych przy użyciu operacji morfologicznych\n",
    "lepsze wyniki osiągano, gdy tworzono głębszy stos przekształceń morfologicznych)\"\"\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "evaluation_all_4 = evaluation_all[[\"MoLa_Type\", \"Structuring_Element\", \"Dataset\", \"Accuracy\"]]\n",
    "evaluation_all_4 = evaluation_all_4[evaluation_all_4[\"MoLa_Type\"].isin([\"opening_closing\", \"dillatation_erosion\"])]\n",
    "evaluation_all_4 = evaluation_all_4.groupby([\"Structuring_Element\", \"Dataset\"]).agg([min, max, np.mean, np.median])\n",
    "evaluation_all_4 = evaluation_all_4.reset_index()\n",
    "evaluation_all_4 = evaluation_all_4.sort_values([\"Dataset\", \"Structuring_Element\"])\n",
    "display(evaluation_all_4)\n",
    "print(\"\"\"Wniosek 4. - Dla modeli CNN bazujących na zdjęciach przekształconych przy użyciu operacji morfologicznych wyniki\n",
    "są porównywalne dla zastosowanych 3 rodzajów kerneli/elementów strukturyzujących  tj. dysk, square, diamond)\"\"\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "evaluation_all_5 = evaluation_all[[\"MoLa_Type\", \"Structuring_Element_Step\", \"Dataset\", \"Accuracy\"]]\n",
    "evaluation_all_5 = evaluation_all_5[evaluation_all_5[\"MoLa_Type\"].isin([\"opening_closing\", \"dillatation_erosion\"])]\n",
    "evaluation_all_5 = evaluation_all_5.groupby([\"Structuring_Element_Step\", \"Dataset\"]).agg([min, max, np.mean, np.median])\n",
    "evaluation_all_5 = evaluation_all_5.reset_index()\n",
    "evaluation_all_5 = evaluation_all_5.sort_values([\"Dataset\", \"Structuring_Element_Step\"])\n",
    "display(evaluation_all_5)\n",
    "print(\"\"\"Wniosek 5. - Dla modeli CNN bazujących na zdjęciach przekształconych przy użyciu operacji morfologicznych wyniki\n",
    "są porównywalne dla zastosowanego stepu w tworzeniu stosu warstw morfologicznych\"\"\")\n",
    "print(\"-------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:20.175199Z",
     "start_time": "2021-01-04T16:30:20.100399Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MoLa_Type</th>\n",
       "      <th colspan=\"2\" halign=\"left\">epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dillatation_erosion</td>\n",
       "      <td>6.784580</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>opening_closing</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reference_model</td>\n",
       "      <td>6.675676</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MoLa_Type     epoch       \n",
       "                            mean median\n",
       "0  dillatation_erosion  6.784580      7\n",
       "1      opening_closing  6.000000      6\n",
       "2      reference_model  6.675676      7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wniosek 6. - W przypadku stosowania przekształceń morfologicznych otwarć i zamknięć dostrzeżono krótszy czas \n",
      "uczenia (mniejsza ilość epok trenowania/aktywacji kryterium wczesnego zatrzymania)\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Stack_dimension</th>\n",
       "      <th colspan=\"2\" halign=\"left\">epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>6.447368</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>6.379475</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stack_dimension     epoch       \n",
       "                       mean median\n",
       "0          [2, 2]  6.447368      6\n",
       "1          [5, 5]  6.379475      6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wniosek 7. - W przypadku stosowania przekształceń morfologicznych otwarć i zamknięć oraz dylatacji i erozji \n",
      "z większą ilością elementów strukturyzujących/większym stosem przeksztaceń morfologicznych dostrzeżono krótszy czas \n",
      "uczenia (mniejsza ilość epok trenowania/aktywacji kryterium wczesnego zatrzymania)\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\">epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>064</td>\n",
       "      <td>6.494624</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>6.597222</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Size     epoch       \n",
       "            mean median\n",
       "0  064  6.494624    6.0\n",
       "1  128  6.133333    6.0\n",
       "2  256  6.597222    6.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wniosek 8. - Niezależnie od stosowanych wymiarów zdjęć jako inputu do modelu sieci konwolucyjnej \n",
      "nie dostrzeżono prostej zależności czasowej (ilość epok trenowania/aktywacji kryterium wczesnego zatrzymania)\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Structuring_Element</th>\n",
       "      <th colspan=\"2\" halign=\"left\">epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diamond</td>\n",
       "      <td>6.293478</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disk</td>\n",
       "      <td>6.765517</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>square</td>\n",
       "      <td>6.158672</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Structuring_Element     epoch       \n",
       "                           mean median\n",
       "0             diamond  6.293478      6\n",
       "1                disk  6.765517      7\n",
       "2              square  6.158672      6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wniosek 9. - W przypadku stosowania przekształceń morfologicznych z wykorzystaniem kerneli 'diamond' i 'square'\n",
      "dostrzeżono krótszy czas uczenia (mniejsza ilość epok trenowania/aktywacji kryterium wczesnego zatrzymania), niż gdy\n",
      "stosowano kernel 'disk'\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Structuring_Element_Step</th>\n",
       "      <th colspan=\"2\" halign=\"left\">epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.558962</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.263923</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Structuring_Element_Step     epoch       \n",
       "                                mean median\n",
       "0                        1  6.558962      6\n",
       "1                        2  6.263923      6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wniosek 10. - W przypadku stosowania przekształceń morfologicznych z wykorzystaniem większego stepu\n",
      "dostrzeżono krótszy czas uczenia (mniejsza ilość epok trenowania/aktywacji kryterium wczesnego zatrzymania), niż gdy\n",
      "stosowano mniejszy step\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "history_all = pd.concat([reference_history, de_history, oc_history])\n",
    "history_all = history_all[[\"model\", \"epoch\"]]\n",
    "history_all = history_all.reset_index(drop = True)\n",
    "\n",
    "history_all[\"MoLa_Type\"] = np.where(history_all[\"model\"].str.contains(\"reference_model\"), \"reference_model\", \n",
    "                                 np.where(history_all[\"model\"].str.contains(\"opening_closing\"), \"opening_closing\",\n",
    "                                          \"dillatation_erosion\"))\n",
    "\n",
    "history_all[\"Stack_dimension\"] = np.where(history_all[\"model\"].str.contains(\"5, 5\"), \"[5, 5]\", \n",
    "                                 np.where(history_all[\"model\"].str.contains(\"2, 2\"), \"[2, 2]\",\n",
    "                                          \"[0, 0]\"))\n",
    "\n",
    "history_all[\"Size\"] = np.where(history_all[\"model\"].str.contains(\"_64\"), \"064\", \n",
    "                                 np.where(history_all[\"model\"].str.contains(\"_128\"), \"128\",\n",
    "                                          \"256\"))\n",
    "\n",
    "history_all[\"Structuring_Element\"] = np.where(history_all[\"model\"].str.contains(\"disk\"), \"disk\", \n",
    "                                 np.where(history_all[\"model\"].str.contains(\"diamond\"), \"diamond\",\n",
    "                                          \"square\"))\n",
    "\n",
    "history_all[\"Structuring_Element_Step\"] = np.where(history_all[\"model\"].str.endswith(\"_1\"), \"1\", \n",
    "                                 np.where(history_all[\"model\"].str.endswith(\"_2\"), \"2\",\n",
    "                                          \"0\"))\n",
    "\n",
    "history_all_1 = history_all[[\"MoLa_Type\", \"epoch\"]].groupby([\"MoLa_Type\"]).agg([np.mean, np.median])\n",
    "history_all_1 = history_all_1.reset_index()\n",
    "history_all_1 = history_all_1.sort_values([\"MoLa_Type\"])\n",
    "display(history_all_1)\n",
    "print(\"\"\"Wniosek 6. - W przypadku stosowania przekształceń morfologicznych otwarć i zamknięć dostrzeżono krótszy czas \n",
    "uczenia (mniejsza ilość epok trenowania/aktywacji kryterium wczesnego zatrzymania)\"\"\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "history_all = history_all[history_all[\"MoLa_Type\"].isin([\"opening_closing\", \"dillatation_erosion\"])]\n",
    "history_all_2 = history_all[[\"Stack_dimension\", \"epoch\"]].groupby([\"Stack_dimension\"]).agg([np.mean, np.median])\n",
    "history_all_2 = history_all_2.reset_index()\n",
    "history_all_2 = history_all_2.sort_values([\"Stack_dimension\"])\n",
    "display(history_all_2)\n",
    "print(\"\"\"Wniosek 7. - W przypadku stosowania przekształceń morfologicznych otwarć i zamknięć oraz dylatacji i erozji \n",
    "z większą ilością elementów strukturyzujących/większym stosem przeksztaceń morfologicznych dostrzeżono krótszy czas \n",
    "uczenia (mniejsza ilość epok trenowania/aktywacji kryterium wczesnego zatrzymania)\"\"\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "history_all_3 = history_all[[\"Size\", \"epoch\"]].groupby([\"Size\"]).agg([np.mean, np.median])\n",
    "history_all_3 = history_all_3.reset_index()\n",
    "history_all_3 = history_all_3.sort_values([\"Size\"])\n",
    "display(history_all_3)\n",
    "print(\"\"\"Wniosek 8. - Niezależnie od stosowanych wymiarów zdjęć jako inputu do modelu sieci konwolucyjnej \n",
    "nie dostrzeżono prostej zależności czasowej (ilość epok trenowania/aktywacji kryterium wczesnego zatrzymania)\"\"\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "history_all_4 = history_all[[\"Structuring_Element\", \"epoch\"]].groupby([\"Structuring_Element\"]).agg([np.mean, np.median])\n",
    "history_all_4 = history_all_4.reset_index()\n",
    "history_all_4 = history_all_4.sort_values([\"Structuring_Element\"])\n",
    "display(history_all_4)\n",
    "print(\"\"\"Wniosek 9. - W przypadku stosowania przekształceń morfologicznych z wykorzystaniem kerneli 'diamond' i 'square'\n",
    "dostrzeżono krótszy czas uczenia (mniejsza ilość epok trenowania/aktywacji kryterium wczesnego zatrzymania), niż gdy\n",
    "stosowano kernel 'disk'\"\"\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "history_all_5 = history_all[[\"Structuring_Element_Step\", \"epoch\"]].groupby([\"Structuring_Element_Step\"]).agg([np.mean, np.median])\n",
    "history_all_5 = history_all_5.reset_index()\n",
    "history_all_5 = history_all_5.sort_values([\"Structuring_Element_Step\"])\n",
    "display(history_all_5)\n",
    "print(\"\"\"Wniosek 10. - W przypadku stosowania przekształceń morfologicznych z wykorzystaniem większego stepu\n",
    "dostrzeżono krótszy czas uczenia (mniejsza ilość epok trenowania/aktywacji kryterium wczesnego zatrzymania), niż gdy\n",
    "stosowano mniejszy step\"\"\")\n",
    "print(\"-------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:20.180186Z",
     "start_time": "2021-01-04T16:30:20.176197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wniosek 11. - Nie przetestowano pomysłu z wykorzystaniem inputu do sieci konwolucyjnej w postaci stosu warstw\n",
      "przekształceń morfologicznych, ponieważ obciąża to bardzo RAM - miewałem problemy przy 32Gb żeby się zmieścić. Dlatego\n",
      "zacząłem stosować kasowanie zbędnych obiektów z pamięci co trochę pomogło. Później stworzyłem dodatkowo funkcję\n",
      "morphological_stack_with_flat(), która tworzy stos i od razu go spłaszcza co jest bardziej efektywno pamięciowo,\n",
      "niż sekwencyjne najpierw stworzenie stosów dla wszystkich obrazów a potem dla wszystkich obrazów spłaszczenie.\n",
      "-------------------------------------------------\n",
      "Wniosek 12. - Na pewno stosowanie przekształceń morfologicznych wydłuża proces przygotowania danych pod względem\n",
      "czasu, natomiast wydaje się to być rekompensowane późniejszymi lepszymi wynikami w klasyfikacji\n",
      "-------------------------------------------------\n",
      "Wniosek 13. Zbiór danych jest dość mały i się przetrenowuje na danych uczących. W tym celu stosowałem operację\n",
      "dogenerowania danych/augmentacji poprzez obrózenie obraców o 90, 180, 270 stopni. To pozwoliło zmniejszyć do pewnego\n",
      "stopnia różnicę miedzy wynikami na zbiorze uczącym/treningowym a walidacyjnym i testowym. Na testowym również\n",
      "dogenerowałem dane żeby oceniać modele na trochę większej ilości danych tj. zamiast na 280 to na 1120.\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Inne wnioski:\n",
    "print(\"\"\"Wniosek 11. - Nie przetestowano pomysłu z wykorzystaniem inputu do sieci konwolucyjnej w postaci stosu warstw\n",
    "przekształceń morfologicznych, ponieważ obciąża to bardzo RAM - miewałem problemy przy 32Gb żeby się zmieścić. Dlatego\n",
    "zacząłem stosować kasowanie zbędnych obiektów z pamięci co trochę pomogło. Później stworzyłem dodatkowo funkcję\n",
    "morphological_stack_with_flat(), która tworzy stos i od razu go spłaszcza co jest bardziej efektywno pamięciowo,\n",
    "niż sekwencyjne najpierw stworzenie stosów dla wszystkich obrazów a potem dla wszystkich obrazów spłaszczenie.\"\"\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "print(\"\"\"Wniosek 12. - Na pewno stosowanie przekształceń morfologicznych wydłuża proces przygotowania danych pod względem\n",
    "czasu, natomiast wydaje się to być rekompensowane późniejszymi lepszymi wynikami w klasyfikacji\"\"\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "print(\"\"\"Wniosek 13. Zbiór danych jest dość mały i się przetrenowuje na danych uczących. W tym celu stosowałem operację\n",
    "dogenerowania danych/augmentacji poprzez obrózenie obraców o 90, 180, 270 stopni. To pozwoliło zmniejszyć do pewnego\n",
    "stopnia różnicę miedzy wynikami na zbiorze uczącym/treningowym a walidacyjnym i testowym. Na testowym również\n",
    "dogenerowałem dane żeby oceniać modele na trochę większej ilości danych tj. zamiast na 280 to na 1120.\"\"\")\n",
    "print(\"-------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_ML_2",
   "language": "python",
   "name": "gpu_ml_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
