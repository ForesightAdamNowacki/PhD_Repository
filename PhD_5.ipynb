{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handed-buyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# bez splaszczenia szare obrazy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage.morphology as smo\n",
    "from skimage.io import imread\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please ensure you have installed TensorFlow correctly')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "located-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_add_border(image, x , y, val, rel = False):\n",
    "\n",
    "    \"\"\"\n",
    "    Adds a border to the input image\n",
    "    rel = True - x,y - size of the added border\n",
    "    rel = False - x,y - size of the image with added border\n",
    "    val - pixel value \n",
    "    \"\"\"\n",
    "    \n",
    "    (sx_org, sy_org) = image.shape\n",
    "    if rel:\n",
    "        sx = sx_org + 2*x\n",
    "        sy = sy_org + 2*y\n",
    "    else:\n",
    "        sx = x\n",
    "        sy = y\n",
    "    img = np.ones([sx, sy]) * val\n",
    "    [cx, cy] = ((np.array([sx, sy]) - np.array([sx_org, sy_org]))/2).astype('int')\n",
    "    img[cx:(cx + sx_org), cy:(cy + sy_org)] = image\n",
    "    return img\n",
    "\n",
    "# ---------- #\n",
    "# Use example:\n",
    "# obraz = imread(\"camel-19.gif\")\n",
    "# if len(obraz.shape) == 3:\n",
    "#     obraz = obraz[:,:,1]\n",
    "# print(obraz.shape)\n",
    "# obraz_ = image_add_border(obraz, x = 100, y = 100, val = 1, rel = True)\n",
    "# print(obraz_.shape)\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(obraz)\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(obraz_)\n",
    "# plt.show()\n",
    "# ---------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alleged-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structuring_elements(n, type = 'disk', initsize = 1, step = 1):\n",
    "    \n",
    "    \"\"\"\n",
    "    generate a list of n structuring elements\n",
    "    type = 'disk', 'square', 'diamond'\n",
    "    \"\"\"\n",
    "    \n",
    "    selist = []\n",
    "    sesize = initsize\n",
    "    \n",
    "    for i in range(n):\n",
    "        if (type == 'disk'):\n",
    "            se = smo.disk(sesize)\n",
    "        if (type == 'square'):\n",
    "            se = smo.square(2 * sesize + 1)\n",
    "        if (type == 'diamond'):\n",
    "            se = smo.diamond(sesize)       \n",
    "        \n",
    "        selist.append(se)\n",
    "        sesize += step\n",
    "        \n",
    "    return selist\n",
    "\n",
    "# ---------- #\n",
    "# Use examples:\n",
    "# get_structuring_elements(3, type = \"square\")\n",
    "# get_structuring_elements(3, type = \"disk\")\n",
    "# get_structuring_elements(3, type = \"diamond\")\n",
    "# ---------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1033fb62-ec07-4d5c-9fd7-1282c15d159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image_size, channels, start_neurons, dense_neurons, classes, model_name = \"model_1\"):\n",
    "     \n",
    "    input_tensor = tf.keras.layers.Input(shape = [image_size, image_size, channels])\n",
    "\n",
    "    conv_1 = tf.keras.layers.Conv2D(filters = start_neurons * 1, \n",
    "                                    kernel_size = (3, 3),\n",
    "                                    strides = (1, 1), \n",
    "                                    activation = tf.keras.activations.relu,\n",
    "                                    padding = \"same\")(input_tensor)\n",
    "    conv_2 = tf.keras.layers.Conv2D(filters = start_neurons * 1, \n",
    "                                    kernel_size = (3, 3),\n",
    "                                    strides = (1, 1), \n",
    "                                    activation = tf.keras.activations.relu,\n",
    "                                    padding = \"same\")(conv_1)\n",
    "    conv_3 = tf.keras.layers.Conv2D(filters = start_neurons * 1, \n",
    "                                    kernel_size = (3, 3),\n",
    "                                    strides = (1, 1), \n",
    "                                    activation = tf.keras.activations.relu,\n",
    "                                    padding = \"same\")(conv_2)\n",
    "    pool_1 = tf.keras.layers.MaxPool2D(pool_size = (2, 2),\n",
    "                                       strides = (2, 2))(conv_3)\n",
    "\n",
    "    flatten = tf.keras.layers.Flatten()(pool_1)\n",
    "    dense = tf.keras.layers.Dense(units = dense_neurons, activation = tf.keras.activations.relu)(flatten)\n",
    "    output_tensor = tf.keras.layers.Dense(units = classes, activation = tf.keras.activations.softmax)(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = input_tensor, \n",
    "                                  outputs = output_tensor, \n",
    "                                  name = model_name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stretch-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphological_stack(input_image,\n",
    "                        structuring_elements_depth,\n",
    "                        transormation_type = 'cv_oc',\n",
    "                        structuring_elements_type = 'disk',\n",
    "                        structuring_elements_initsize = 1,\n",
    "                        structuring_elements_step = 1,\n",
    "                        addborder = True):\n",
    "    \"\"\"\n",
    "    produce a stack of results of the morphological dual operators\n",
    "    input_image - imput image (binary or graylevel 2D image)\n",
    "    structuring_elements_depth - list of two values - numers of up-stack and down-stack images\n",
    "    transormation_type - type of operations erosion/dilation <-> opening/closing; skimage binary <-> skimage graytone <-> opencv\n",
    "    structuring_elements_type = structuring element type ('disk', 'square', 'diamond')\n",
    "    structuring_elements_initsize = initial size of the structuring element \n",
    "    structuring_elements_step = increment of the structuring element size\n",
    "    addborder = True if the external boundary is added, = False otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    max_up = structuring_elements_depth[0] # number of up-stack images (higher indeces, dilation/opening)\n",
    "    max_down = structuring_elements_depth[1] # number of down-stack images (kower indeces, erosion/closing)\n",
    "    max_updown = max(max_up, max_down)\n",
    "    \n",
    "    structuring_elements_list = get_structuring_elements(n = max_updown,\n",
    "                                                         type = structuring_elements_type, \n",
    "                                                         initsize = structuring_elements_initsize,\n",
    "                                                         step = structuring_elements_step)\n",
    "    if addborder:\n",
    "        image = image_add_border(image = input_image,\n",
    "                                 x = max_updown,\n",
    "                                 y = max_updown, \n",
    "                                 val = 0, \n",
    "                                 rel = True)\n",
    "    else:\n",
    "        image = input_image\n",
    "    \n",
    "    image_out = np.zeros([image.shape[0], image.shape[1], max_up + max_down + 1])    \n",
    "    count = 0\n",
    "\n",
    "    if transormation_type == 'b_ed': # binary erosion/dilation - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.binary_erosion\n",
    "        operator_up = smo.binary_dilation\n",
    "    elif transormation_type == 'b_oc': # binary opening/closing - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.binary_opening\n",
    "        operator_up = smo.binary_closing      \n",
    "    elif transormation_type == 'ed': # erosion/dilation - scikit.image     \n",
    "        opencv = False\n",
    "        operator_down = smo.erosion\n",
    "        operator_up = smo.dilation\n",
    "    elif transormation_type == 'oc': # opening/closing - scikit.image\n",
    "        opencv = False\n",
    "        operator_down = smo.opening\n",
    "        operator_up = smo.closing      \n",
    "    elif transormation_type == 'cv_ed': # erosion/dilation - openCV \n",
    "        opencv = True\n",
    "        operator_down = cv2.MORPH_ERODE\n",
    "        operator_up = cv2.MORPH_DILATE\n",
    "    else: # transormation_type == 'cv_oc': # opening/closing - openCV \n",
    "        opencv = True\n",
    "        operator_down = cv2.MORPH_OPEN\n",
    "        operator_up = cv2.MORPH_CLOSE     \n",
    "    \n",
    "    if opencv:  # opencv version \n",
    "        for i in range(max_down):\n",
    "            image_out[:,:,count] = cv2.morphologyEx(image,\n",
    "                                                    operator_down,\n",
    "                                                    structuring_elements_list[max_down - i - 1]); count += 1\n",
    "        image_out[:,:,count] = image; count += 1\n",
    "        for i in range(max_up):\n",
    "            image_out[:,:,count] = cv2.morphologyEx(image,\n",
    "                                                    operator_up, \n",
    "                                                    structuring_elements_list[i]); count += 1\n",
    "        \n",
    "    else:   # scikit image version\n",
    "        for i in range(max_down):\n",
    "            operator_down(image,\n",
    "                          selem = structuring_elements_list[max_down - i - 1],\n",
    "                          out = image_out[:,:,count]); count += 1\n",
    "        image_out[:,:,count] = image; count += 1\n",
    "        for i in range(max_up):\n",
    "            operator_up(image,\n",
    "                        selem = structuring_elements_list[i], \n",
    "                        out = image_out[:,:,count]); count += 1   \n",
    "        \n",
    "    return image_out\n",
    "\n",
    "# ---------- #\n",
    "# Use examples:\n",
    "# obraz = imread(\"camel-19.gif\")\n",
    "# if len(obraz.shape) == 3:\n",
    "#     obraz = obraz[:,:,1]\n",
    "# obraz_ = morphological_stack(input_image = obraz,\n",
    "#                              structuring_elements_depth = [10, 10])\n",
    "# print(obraz_.shape)\n",
    "# plt.imshow(obraz_[:,:,20])\n",
    "# ---------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "covered-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphological_test_cifar_10(results_directory_ = \"Results_5_\",\n",
    "                                model_name_ = \"model\",\n",
    "                                structuring_elements_depth_ = [2, 2],\n",
    "                                transormation_type_ = \"cv_ed\",\n",
    "                                structuring_elements_type_ = \"disk\",\n",
    "                                structuring_elements_initsize_ = 1,\n",
    "                                structuring_elements_step_ = 1,\n",
    "                                addborder_ = True,\n",
    "                                morphological_transformation_mode_ = True,\n",
    "                                start_neurons_ = 16,\n",
    "                                dense_neurons_ = 256,\n",
    "                                epochs_ = 10,\n",
    "                                batch_size_ = 32,\n",
    "                                augmentation_ = True):\n",
    "\n",
    "    results_directory = os.path.join(\"D:/GitHub/PhD_Repository\", results_directory_)\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "    if morphological_transformation_mode_ == True:\n",
    "\n",
    "        print(\"1.train. Convert RGB to greyscale\")\n",
    "        x_train_1 = [img[:, :, 0] * 0.3 + img[:, :, 1] * 0.6 + img[:, :, 2] * 0.1 for img in x_train]\n",
    "\n",
    "        print(\"2.train. Morphological operations\")\n",
    "        x_train_2 = [morphological_stack(input_image = i,\n",
    "                                                   structuring_elements_depth = structuring_elements_depth_,\n",
    "                                                   transormation_type = transormation_type_,\n",
    "                                                   structuring_elements_type = structuring_elements_type_,\n",
    "                                                   structuring_elements_initsize = structuring_elements_initsize_,\n",
    "                                                   structuring_elements_step = structuring_elements_step_,\n",
    "                                                   addborder = addborder_) for i in x_train_1]\n",
    "        del x_train_1\n",
    "\n",
    "        print(\"3.train. Expand first dim\")\n",
    "        x_train_3 = [np.expand_dims(i, 0) for i in x_train_2]\n",
    "        del x_train_2\n",
    "\n",
    "        print(\"4.train. Crop images\")\n",
    "        shp = x_train_3[0].shape[1]\n",
    "        sed_max = np.max(structuring_elements_depth_)\n",
    "        x_train_4 = [i[:, sed_max:shp - sed_max, sed_max:shp - sed_max] for i in x_train_3]\n",
    "        del x_train_3\n",
    "\n",
    "        print(\"5.train. Convert list to numpy array\")\n",
    "        x_train_5 = np.concatenate(np.array(x_train_4), axis = 0)\n",
    "        del x_train_4\n",
    "\n",
    "        x_train_ = x_train_5\n",
    "        y_train_ = y_train\n",
    "\n",
    "        print(\"1.test. Convert RGB to greyscale\")\n",
    "        x_test_1 = [img[:, :, 0] * 0.3 + img[:, :, 1] * 0.6 + img[:, :, 2] * 0.1 for img in x_test]\n",
    "\n",
    "        print(\"2.test. Morphological operations\")\n",
    "        x_test_2 = [morphological_stack(input_image = i,\n",
    "                                                   structuring_elements_depth = structuring_elements_depth_,\n",
    "                                                   transormation_type = transormation_type_,\n",
    "                                                   structuring_elements_type = structuring_elements_type_,\n",
    "                                                   structuring_elements_initsize = structuring_elements_initsize_,\n",
    "                                                   structuring_elements_step = structuring_elements_step_,\n",
    "                                                   addborder = addborder_) for i in x_test_1]\n",
    "        del x_test_1\n",
    "\n",
    "        print(\"3.test. Expand first dim\")\n",
    "        x_test_3 = [np.expand_dims(i, 0) for i in x_test_2]\n",
    "        del x_test_2\n",
    "\n",
    "        print(\"4.test. Crop images\")\n",
    "        shp = x_test_3[0].shape[1]\n",
    "        sed_max = np.max(structuring_elements_depth_)\n",
    "        x_test_4 = [i[:, sed_max:shp - sed_max, sed_max:shp - sed_max] for i in x_test_3]\n",
    "        del x_test_3\n",
    "\n",
    "        print(\"5.train. Convert list to numpy array\")\n",
    "        x_test_5 = np.concatenate(np.array(x_test_4), axis = 0)\n",
    "        del x_test_4\n",
    "\n",
    "        x_test_ = x_test_5\n",
    "        y_test_ = y_test\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"1.train. Normal\")\n",
    "        x_train_ = x_train\n",
    "        y_train_ = y_train\n",
    "\n",
    "        print(\"1.test. Normal\")\n",
    "        x_test_ = x_test\n",
    "        y_test_ = y_test\n",
    "\n",
    "        print(\"Split: train, validation and test\")\n",
    "\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    X = np.arange(x_train_.shape[0])\n",
    "    y = np.arange(x_train_.shape[0])\n",
    "\n",
    "    classes = len(np.unique(y_train_))\n",
    "\n",
    "    x_train_id, x_validation_id, y_train_id, y_validation_id = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    x_train__ = x_train_[x_train_id, :, :, :]\n",
    "    y_train__ = y_train_[y_train_id]\n",
    "\n",
    "    x_valid__ = x_train_[x_validation_id, :, :, :]\n",
    "    y_valid__ = y_train_[y_validation_id]\n",
    "\n",
    "    x_test__ = x_test_\n",
    "    y_test__ = y_test_\n",
    "\n",
    "    y_train__ = tf.keras.utils.to_categorical(y_train__, classes)\n",
    "    y_valid__ = tf.keras.utils.to_categorical(y_valid__, classes)\n",
    "    y_test__ = tf.keras.utils.to_categorical(y_test__, classes)\n",
    "\n",
    "    print(x_train__.shape)\n",
    "    print(y_train__.shape)\n",
    "    print(x_valid__.shape)\n",
    "    print(y_valid__.shape)\n",
    "    print(x_test__.shape)\n",
    "    print(y_test__.shape)\n",
    "\n",
    "    image_size = x_train__.shape[1]\n",
    "    channels = x_train__.shape[3]\n",
    "    early_stopping = int(epochs_ * 0.1)\n",
    "\n",
    "    print(\"Build data generators\")\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range = 90,\n",
    "            width_shift_range = np.ceil(0.1 * image_size), \n",
    "            height_shift_range = np.ceil(0.1 * image_size),\n",
    "            horizontal_flip = True, \n",
    "            vertical_flip = True,\n",
    "            fill_mode = 'nearest')\n",
    "\n",
    "    test_validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range = 0,\n",
    "            width_shift_range = 0, \n",
    "            height_shift_range = 0,\n",
    "            horizontal_flip = False, \n",
    "            vertical_flip = False,\n",
    "            fill_mode = 'nearest')\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(patience = early_stopping, monitor = 'val_accuracy', verbose = 1),\n",
    "                 tf.keras.callbacks.ModelCheckpoint(filepath = os.path.join(results_directory, \"weights.h5\"),\n",
    "                                                    save_weights_only=True,\n",
    "                                                    monitor='val_accuracy',\n",
    "                                                    mode='max',\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "    model = build_model(image_size = image_size,\n",
    "                        channels = channels, \n",
    "                        start_neurons = start_neurons_,\n",
    "                        dense_neurons = dense_neurons_, \n",
    "                        classes = classes,\n",
    "                        model_name = model_name_)\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                      loss = tf.keras.losses.categorical_crossentropy,\n",
    "                      metrics = [\"accuracy\"])\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    if augmentation_ == True:\n",
    "        print(\"Augmentation mode on\")\n",
    "        train_generator = train_datagen.flow(x_train__, y_train__, batch_size = batch_size_)\n",
    "    else:\n",
    "        print(\"Augmentation mode off\")\n",
    "        train_generator = test_validation_datagen.flow(x_train__, y_train__, batch_size = batch_size_)\n",
    "\n",
    "    validation_generator = test_validation_datagen.flow(x_valid__, y_valid__, batch_size = batch_size_)\n",
    "\n",
    "    model_results = model.fit(train_generator,\n",
    "                              validation_data = validation_generator,\n",
    "                              steps_per_epoch = np.ceil(train_generator.n / batch_size_),\n",
    "                              validation_steps = np.ceil(validation_generator.n / batch_size_),\n",
    "                              epochs = epochs_,\n",
    "                              shuffle = True,\n",
    "                              callbacks = callbacks)\n",
    "\n",
    "    model = build_model(image_size = image_size,\n",
    "                        channels = channels, \n",
    "                        start_neurons = start_neurons_,\n",
    "                        dense_neurons = dense_neurons_, \n",
    "                        classes = classes,\n",
    "                        model_name = model_name_)\n",
    "\n",
    "    model.load_weights(os.path.join(results_directory, \"weights.h5\"))\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                      loss = tf.keras.losses.categorical_crossentropy,\n",
    "                      metrics = [\"accuracy\"])\n",
    "\n",
    "    model_results_pd = pd.DataFrame(model_results.history)\n",
    "    model_results_pd[\"model\"] = model_name_\n",
    "    model_results_pd[\"epoch\"] = np.array(model_results.epoch) + 1\n",
    "    model_results_pd[\"structuring_elements_depth\"] = str(structuring_elements_depth_)\n",
    "    model_results_pd[\"transormation_type\"] = transormation_type_\n",
    "    model_results_pd[\"structuring_elements_type\"] = structuring_elements_type_\n",
    "    model_results_pd[\"structuring_elements_initsize\"] = structuring_elements_initsize_\n",
    "    model_results_pd[\"structuring_elements_step\"] = structuring_elements_step_\n",
    "    model_results_pd[\"morphological_transformation_mode\"] = morphological_transformation_mode_\n",
    "    model_results_pd[\"start_neurons\"] = start_neurons_\n",
    "    model_results_pd[\"dense_neurons\"] = dense_neurons_\n",
    "    model_results_pd[\"epochs\"] = epochs_\n",
    "    model_results_pd[\"batch_size\"] = batch_size_\n",
    "    model_results_pd[\"augmentation\"] = augmentation_\n",
    "    model_results_pd.to_csv(os.path.join(results_directory,  model_name_ + \"_history.csv\"))\n",
    "\n",
    "    model_train_accuracy = model.evaluate(x_train__, y_train__)[1]\n",
    "    model_validation_accuracy = model.evaluate(x_valid__, y_valid__)[1]\n",
    "    model_test_accuracy = model.evaluate(x_test__, y_test__)[1]\n",
    "\n",
    "    print(\"Train accuracy:\", model_train_accuracy)\n",
    "    print(\"Validation accuracy:\", model_validation_accuracy)\n",
    "    print(\"Test accuracy:\", model_test_accuracy)\n",
    "\n",
    "    evaluation_results = pd.DataFrame({\"Dataset\" : [\"train\", \"validation\", \"test\"],\n",
    "                                       \"Accuracy\" : [model_train_accuracy, model_validation_accuracy, model_test_accuracy],\n",
    "                                       \"Model_Name\" : [model_name_] * 3})\n",
    "    evaluation_results[\"epochs\"] = model_results_pd.shape[0]\n",
    "    evaluation_results[\"structuring_elements_depth\"] = str(structuring_elements_depth_)\n",
    "    evaluation_results[\"transormation_type\"] = transormation_type_\n",
    "    evaluation_results[\"structuring_elements_type\"] = structuring_elements_type_\n",
    "    evaluation_results[\"structuring_elements_initsize\"] = structuring_elements_initsize_\n",
    "    evaluation_results[\"structuring_elements_step\"] = structuring_elements_step_\n",
    "    evaluation_results[\"morphological_transformation_mode\"] = morphological_transformation_mode_\n",
    "    evaluation_results[\"start_neurons\"] = start_neurons_\n",
    "    evaluation_results[\"dense_neurons\"] = dense_neurons_\n",
    "    evaluation_results[\"epochs\"] = epochs_\n",
    "    evaluation_results[\"batch_size\"] = batch_size_\n",
    "    evaluation_results[\"augmentation\"] = augmentation_\n",
    "    evaluation_results.to_csv(os.path.join(results_directory,  model_name_ + \"_evaluation.csv\"))\n",
    "\n",
    "    del model\n",
    "    del model_results_pd\n",
    "    del evaluation_results\n",
    "    os.remove(os.path.join(results_directory, \"weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "authorized-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandgrid(*itrs):\n",
    "    product = list(itertools.product(*itrs))\n",
    "    return {'Var{}'.format(i+1):[x[i] for x in product] for i in range(len(itrs))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0e7f06-61f4-4e30-9b24-f3a9c0485ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structuring_elements_depth_hp</th>\n",
       "      <th>transormation_type_hp</th>\n",
       "      <th>structuring_elements_type_hp</th>\n",
       "      <th>structuring_elements_step_hp</th>\n",
       "      <th>start_neurons_hp</th>\n",
       "      <th>dense_neurons_hp</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>cv_ed</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>cv_oc</td>\n",
       "      <td>disk</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   structuring_elements_depth_hp transormation_type_hp  \\\n",
       "0                         [1, 1]                 cv_ed   \n",
       "1                         [1, 1]                 cv_ed   \n",
       "2                         [1, 1]                 cv_ed   \n",
       "3                         [1, 1]                 cv_ed   \n",
       "4                         [1, 1]                 cv_oc   \n",
       "5                         [1, 1]                 cv_oc   \n",
       "6                         [1, 1]                 cv_oc   \n",
       "7                         [1, 1]                 cv_oc   \n",
       "8                         [2, 2]                 cv_ed   \n",
       "9                         [2, 2]                 cv_ed   \n",
       "10                        [2, 2]                 cv_ed   \n",
       "11                        [2, 2]                 cv_ed   \n",
       "12                        [2, 2]                 cv_oc   \n",
       "13                        [2, 2]                 cv_oc   \n",
       "14                        [2, 2]                 cv_oc   \n",
       "15                        [2, 2]                 cv_oc   \n",
       "16                        [3, 3]                 cv_ed   \n",
       "17                        [3, 3]                 cv_ed   \n",
       "18                        [3, 3]                 cv_ed   \n",
       "19                        [3, 3]                 cv_ed   \n",
       "20                        [3, 3]                 cv_oc   \n",
       "21                        [3, 3]                 cv_oc   \n",
       "22                        [3, 3]                 cv_oc   \n",
       "23                        [3, 3]                 cv_oc   \n",
       "24                        [4, 4]                 cv_ed   \n",
       "25                        [4, 4]                 cv_ed   \n",
       "26                        [4, 4]                 cv_ed   \n",
       "27                        [4, 4]                 cv_ed   \n",
       "28                        [4, 4]                 cv_oc   \n",
       "29                        [4, 4]                 cv_oc   \n",
       "30                        [4, 4]                 cv_oc   \n",
       "31                        [4, 4]                 cv_oc   \n",
       "32                        [5, 5]                 cv_ed   \n",
       "33                        [5, 5]                 cv_ed   \n",
       "34                        [5, 5]                 cv_ed   \n",
       "35                        [5, 5]                 cv_ed   \n",
       "36                        [5, 5]                 cv_oc   \n",
       "37                        [5, 5]                 cv_oc   \n",
       "38                        [5, 5]                 cv_oc   \n",
       "39                        [5, 5]                 cv_oc   \n",
       "40                        [6, 6]                 cv_ed   \n",
       "41                        [6, 6]                 cv_ed   \n",
       "42                        [6, 6]                 cv_ed   \n",
       "43                        [6, 6]                 cv_ed   \n",
       "44                        [6, 6]                 cv_oc   \n",
       "45                        [6, 6]                 cv_oc   \n",
       "46                        [6, 6]                 cv_oc   \n",
       "47                        [6, 6]                 cv_oc   \n",
       "\n",
       "   structuring_elements_type_hp  structuring_elements_step_hp  \\\n",
       "0                          disk                             1   \n",
       "1                          disk                             1   \n",
       "2                          disk                             1   \n",
       "3                          disk                             1   \n",
       "4                          disk                             1   \n",
       "5                          disk                             1   \n",
       "6                          disk                             1   \n",
       "7                          disk                             1   \n",
       "8                          disk                             1   \n",
       "9                          disk                             1   \n",
       "10                         disk                             1   \n",
       "11                         disk                             1   \n",
       "12                         disk                             1   \n",
       "13                         disk                             1   \n",
       "14                         disk                             1   \n",
       "15                         disk                             1   \n",
       "16                         disk                             1   \n",
       "17                         disk                             1   \n",
       "18                         disk                             1   \n",
       "19                         disk                             1   \n",
       "20                         disk                             1   \n",
       "21                         disk                             1   \n",
       "22                         disk                             1   \n",
       "23                         disk                             1   \n",
       "24                         disk                             1   \n",
       "25                         disk                             1   \n",
       "26                         disk                             1   \n",
       "27                         disk                             1   \n",
       "28                         disk                             1   \n",
       "29                         disk                             1   \n",
       "30                         disk                             1   \n",
       "31                         disk                             1   \n",
       "32                         disk                             1   \n",
       "33                         disk                             1   \n",
       "34                         disk                             1   \n",
       "35                         disk                             1   \n",
       "36                         disk                             1   \n",
       "37                         disk                             1   \n",
       "38                         disk                             1   \n",
       "39                         disk                             1   \n",
       "40                         disk                             1   \n",
       "41                         disk                             1   \n",
       "42                         disk                             1   \n",
       "43                         disk                             1   \n",
       "44                         disk                             1   \n",
       "45                         disk                             1   \n",
       "46                         disk                             1   \n",
       "47                         disk                             1   \n",
       "\n",
       "    start_neurons_hp  dense_neurons_hp  id  \n",
       "0                 16               128   0  \n",
       "1                 16               256   1  \n",
       "2                 32               128   2  \n",
       "3                 32               256   3  \n",
       "4                 16               128   4  \n",
       "5                 16               256   5  \n",
       "6                 32               128   6  \n",
       "7                 32               256   7  \n",
       "8                 16               128   8  \n",
       "9                 16               256   9  \n",
       "10                32               128  10  \n",
       "11                32               256  11  \n",
       "12                16               128  12  \n",
       "13                16               256  13  \n",
       "14                32               128  14  \n",
       "15                32               256  15  \n",
       "16                16               128  16  \n",
       "17                16               256  17  \n",
       "18                32               128  18  \n",
       "19                32               256  19  \n",
       "20                16               128  20  \n",
       "21                16               256  21  \n",
       "22                32               128  22  \n",
       "23                32               256  23  \n",
       "24                16               128  24  \n",
       "25                16               256  25  \n",
       "26                32               128  26  \n",
       "27                32               256  27  \n",
       "28                16               128  28  \n",
       "29                16               256  29  \n",
       "30                32               128  30  \n",
       "31                32               256  31  \n",
       "32                16               128  32  \n",
       "33                16               256  33  \n",
       "34                32               128  34  \n",
       "35                32               256  35  \n",
       "36                16               128  36  \n",
       "37                16               256  37  \n",
       "38                32               128  38  \n",
       "39                32               256  39  \n",
       "40                16               128  40  \n",
       "41                16               256  41  \n",
       "42                32               128  42  \n",
       "43                32               256  43  \n",
       "44                16               128  44  \n",
       "45                16               256  45  \n",
       "46                32               128  46  \n",
       "47                32               256  47  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structuring_elements_depth_hp = [[1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6]]\n",
    "transormation_type_hp = [\"cv_ed\", \"cv_oc\"]\n",
    "structuring_elements_type_hp = [\"disk\"]\n",
    "structuring_elements_step_hp = [1]\n",
    "start_neurons_hp = [16, 32]\n",
    "dense_neurons_hp = [128, 256]\n",
    "\n",
    "grid_big = pd.DataFrame(expandgrid(structuring_elements_depth_hp,\n",
    "                               transormation_type_hp,\n",
    "                               structuring_elements_type_hp,\n",
    "                               structuring_elements_step_hp,\n",
    "                               start_neurons_hp,\n",
    "                               dense_neurons_hp))\n",
    "grid_big[\"id\"] = list(np.arange(grid_big.shape[0]))\n",
    "grid_big.columns = [\"structuring_elements_depth_hp\", \n",
    "                \"transormation_type_hp\", \n",
    "                \"structuring_elements_type_hp\",\n",
    "                \"structuring_elements_step_hp\", \n",
    "                \"start_neurons_hp\", \n",
    "                \"dense_neurons_hp\",\n",
    "                \"id\"]\n",
    "grid_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3233534-aa54-4444-9a4d-2c9f3e5033e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_neurons_hp</th>\n",
       "      <th>dense_neurons_hp</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_neurons_hp  dense_neurons_hp  id\n",
       "0                16               128   0\n",
       "1                16               256   1\n",
       "2                32               128   2\n",
       "3                32               256   3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_neurons_hp = [16, 32]\n",
    "dense_neurons_hp = [128, 256]\n",
    "\n",
    "grid_small = pd.DataFrame(expandgrid(start_neurons_hp,\n",
    "                                     dense_neurons_hp))\n",
    "grid_small[\"id\"] = list(np.arange(grid_small.shape[0]))\n",
    "grid_small.columns = [\"start_neurons_hp\", \n",
    "                \"dense_neurons_hp\",\n",
    "                \"id\"]\n",
    "grid_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a19aa5d-642b-45ef-a24f-00bdf313b8e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_grid_model_0\n",
      "1.train. Normal\n",
      "1.test. Normal\n",
      "Split: train, validation and test\n",
      "(40000, 32, 32, 3)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"small_grid_model_0\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 530,794\n",
      "Trainable params: 530,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      " 1/79 [..............................] - ETA: 0s - loss: 49.4603 - accuracy: 0.1172WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0109s). Check your callbacks.\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 5.2461 - accuracy: 0.1508 - val_loss: 2.2016 - val_accuracy: 0.1935\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 2.0885 - accuracy: 0.2243 - val_loss: 2.0661 - val_accuracy: 0.2599\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 2.0074 - accuracy: 0.2635 - val_loss: 1.9814 - val_accuracy: 0.2792\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.9556 - accuracy: 0.2880 - val_loss: 1.9475 - val_accuracy: 0.3028\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.9150 - accuracy: 0.3024 - val_loss: 1.9046 - val_accuracy: 0.3203\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.8947 - accuracy: 0.3099 - val_loss: 1.8883 - val_accuracy: 0.3136\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 13s 162ms/step - loss: 1.8636 - accuracy: 0.3229 - val_loss: 1.8674 - val_accuracy: 0.3364\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.8470 - accuracy: 0.3364 - val_loss: 1.8264 - val_accuracy: 0.3467\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.8272 - accuracy: 0.3399 - val_loss: 1.8017 - val_accuracy: 0.3564\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.8163 - accuracy: 0.3440 - val_loss: 1.7901 - val_accuracy: 0.3561\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.8082 - accuracy: 0.3446 - val_loss: 1.7945 - val_accuracy: 0.3595\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.7864 - accuracy: 0.3560 - val_loss: 1.7753 - val_accuracy: 0.3579\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.7744 - accuracy: 0.3575 - val_loss: 1.8084 - val_accuracy: 0.3506\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.7608 - accuracy: 0.3680 - val_loss: 1.8245 - val_accuracy: 0.3456\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.7633 - accuracy: 0.3600 - val_loss: 1.7463 - val_accuracy: 0.3709\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.7415 - accuracy: 0.3712 - val_loss: 1.7578 - val_accuracy: 0.3719\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.7349 - accuracy: 0.3721 - val_loss: 1.7634 - val_accuracy: 0.3746\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.7256 - accuracy: 0.3776 - val_loss: 1.7274 - val_accuracy: 0.3876\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.7106 - accuracy: 0.3814 - val_loss: 1.7268 - val_accuracy: 0.3872\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.6989 - accuracy: 0.3902 - val_loss: 1.8285 - val_accuracy: 0.3573\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6997 - accuracy: 0.3868 - val_loss: 1.6827 - val_accuracy: 0.3947\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.6847 - accuracy: 0.3912 - val_loss: 1.6778 - val_accuracy: 0.4025\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6705 - accuracy: 0.3960 - val_loss: 1.7350 - val_accuracy: 0.3912\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6631 - accuracy: 0.3982 - val_loss: 1.7237 - val_accuracy: 0.3903\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.6597 - accuracy: 0.4030 - val_loss: 1.7029 - val_accuracy: 0.3921\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.6530 - accuracy: 0.4042 - val_loss: 1.6869 - val_accuracy: 0.4087\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6449 - accuracy: 0.4079 - val_loss: 1.7945 - val_accuracy: 0.3809\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.6332 - accuracy: 0.4123 - val_loss: 1.6891 - val_accuracy: 0.4076\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6222 - accuracy: 0.4178 - val_loss: 1.6489 - val_accuracy: 0.4176\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.6243 - accuracy: 0.4200 - val_loss: 1.6691 - val_accuracy: 0.4115\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.6122 - accuracy: 0.4191 - val_loss: 1.6755 - val_accuracy: 0.4140\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.5953 - accuracy: 0.4246 - val_loss: 1.7060 - val_accuracy: 0.4075\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.5785 - accuracy: 0.4332 - val_loss: 1.7146 - val_accuracy: 0.4058\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.5745 - accuracy: 0.4367 - val_loss: 1.6702 - val_accuracy: 0.4163\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.5546 - accuracy: 0.4383 - val_loss: 1.6422 - val_accuracy: 0.4218\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.5549 - accuracy: 0.4400 - val_loss: 1.6021 - val_accuracy: 0.4345\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.5422 - accuracy: 0.4446 - val_loss: 1.6686 - val_accuracy: 0.4259\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.5308 - accuracy: 0.4525 - val_loss: 1.6485 - val_accuracy: 0.4229\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.5263 - accuracy: 0.4510 - val_loss: 1.6893 - val_accuracy: 0.4216\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.5193 - accuracy: 0.4549 - val_loss: 1.6353 - val_accuracy: 0.4235\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.5137 - accuracy: 0.4576 - val_loss: 1.6456 - val_accuracy: 0.4343\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.5057 - accuracy: 0.4611 - val_loss: 1.6103 - val_accuracy: 0.4391\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 12s 158ms/step - loss: 1.4980 - accuracy: 0.4582 - val_loss: 1.6669 - val_accuracy: 0.4277\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4901 - accuracy: 0.4649 - val_loss: 1.6873 - val_accuracy: 0.4230\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4745 - accuracy: 0.4681 - val_loss: 1.6455 - val_accuracy: 0.4409\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4761 - accuracy: 0.4708 - val_loss: 1.6797 - val_accuracy: 0.4303\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4696 - accuracy: 0.4734 - val_loss: 1.6473 - val_accuracy: 0.4366\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.4730 - accuracy: 0.4697 - val_loss: 1.7159 - val_accuracy: 0.4284\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.4616 - accuracy: 0.4740 - val_loss: 1.5361 - val_accuracy: 0.4687\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4534 - accuracy: 0.4791 - val_loss: 1.5741 - val_accuracy: 0.4537\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4433 - accuracy: 0.4821 - val_loss: 1.5761 - val_accuracy: 0.4555\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4406 - accuracy: 0.4833 - val_loss: 1.7199 - val_accuracy: 0.4285\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4435 - accuracy: 0.4817 - val_loss: 1.6115 - val_accuracy: 0.4497\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.4263 - accuracy: 0.4906 - val_loss: 1.5783 - val_accuracy: 0.4582\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4200 - accuracy: 0.4922 - val_loss: 1.5651 - val_accuracy: 0.4647\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.4235 - accuracy: 0.4901 - val_loss: 1.6151 - val_accuracy: 0.4463\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4154 - accuracy: 0.4906 - val_loss: 1.6526 - val_accuracy: 0.4499\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4123 - accuracy: 0.4915 - val_loss: 1.5224 - val_accuracy: 0.4706\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.4071 - accuracy: 0.4945 - val_loss: 1.6231 - val_accuracy: 0.4603\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.4017 - accuracy: 0.5006 - val_loss: 1.6025 - val_accuracy: 0.4557\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.3881 - accuracy: 0.5049 - val_loss: 1.5930 - val_accuracy: 0.4630\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3893 - accuracy: 0.5000 - val_loss: 1.5481 - val_accuracy: 0.4675\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3794 - accuracy: 0.5090 - val_loss: 1.4572 - val_accuracy: 0.4992\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3859 - accuracy: 0.5029 - val_loss: 1.5514 - val_accuracy: 0.4685\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3823 - accuracy: 0.5047 - val_loss: 1.5395 - val_accuracy: 0.4806\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3706 - accuracy: 0.5059 - val_loss: 1.5206 - val_accuracy: 0.4818\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3704 - accuracy: 0.5075 - val_loss: 1.5678 - val_accuracy: 0.4608\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3770 - accuracy: 0.5070 - val_loss: 1.5504 - val_accuracy: 0.4812\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3614 - accuracy: 0.5112 - val_loss: 1.5023 - val_accuracy: 0.4899\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3597 - accuracy: 0.5117 - val_loss: 1.5536 - val_accuracy: 0.4741\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3465 - accuracy: 0.5198 - val_loss: 1.5298 - val_accuracy: 0.4865\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.3520 - accuracy: 0.5159 - val_loss: 1.4533 - val_accuracy: 0.5039\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3450 - accuracy: 0.5190 - val_loss: 1.4708 - val_accuracy: 0.5028\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.3521 - accuracy: 0.5168 - val_loss: 1.4564 - val_accuracy: 0.5047\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.3417 - accuracy: 0.5201 - val_loss: 1.6076 - val_accuracy: 0.4812\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 13s 159ms/step - loss: 1.3316 - accuracy: 0.5225 - val_loss: 1.6401 - val_accuracy: 0.4629\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.3383 - accuracy: 0.5166 - val_loss: 1.4760 - val_accuracy: 0.5027\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.3289 - accuracy: 0.5252 - val_loss: 1.5294 - val_accuracy: 0.4900\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 12s 158ms/step - loss: 1.3348 - accuracy: 0.5223 - val_loss: 1.4658 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.3281 - accuracy: 0.5239 - val_loss: 1.5510 - val_accuracy: 0.4820\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.3228 - accuracy: 0.5272 - val_loss: 1.4343 - val_accuracy: 0.5095\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.3183 - accuracy: 0.5266 - val_loss: 1.4896 - val_accuracy: 0.5001\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.3124 - accuracy: 0.5330 - val_loss: 1.4684 - val_accuracy: 0.5006\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.3153 - accuracy: 0.5281 - val_loss: 1.4755 - val_accuracy: 0.4962\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.3128 - accuracy: 0.5305 - val_loss: 1.4667 - val_accuracy: 0.5021\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.3067 - accuracy: 0.5322 - val_loss: 1.4970 - val_accuracy: 0.4977\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.3009 - accuracy: 0.5321 - val_loss: 1.5055 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.3015 - accuracy: 0.5389 - val_loss: 1.4911 - val_accuracy: 0.5016\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.2997 - accuracy: 0.5355 - val_loss: 1.4670 - val_accuracy: 0.5086\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.3016 - accuracy: 0.5357 - val_loss: 1.3934 - val_accuracy: 0.5224\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.2885 - accuracy: 0.5407 - val_loss: 1.4829 - val_accuracy: 0.5065\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.2942 - accuracy: 0.5369 - val_loss: 1.4696 - val_accuracy: 0.5035\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.2796 - accuracy: 0.5440 - val_loss: 1.4072 - val_accuracy: 0.5216\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.2815 - accuracy: 0.5425 - val_loss: 1.3896 - val_accuracy: 0.5202\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.2760 - accuracy: 0.5440 - val_loss: 1.4555 - val_accuracy: 0.5151\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.2843 - accuracy: 0.5418 - val_loss: 1.4468 - val_accuracy: 0.5140\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.2913 - accuracy: 0.5386 - val_loss: 1.4796 - val_accuracy: 0.5050\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.2683 - accuracy: 0.5459 - val_loss: 1.3608 - val_accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.2691 - accuracy: 0.5459 - val_loss: 1.3816 - val_accuracy: 0.5260\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.2606 - accuracy: 0.5508 - val_loss: 1.4945 - val_accuracy: 0.5023\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.3082 - accuracy: 0.5487\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3608 - accuracy: 0.5333\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3377 - accuracy: 0.5442\n",
      "Train accuracy: 0.548675000667572\n",
      "Validation accuracy: 0.53329998254776\n",
      "Test accuracy: 0.5442000031471252\n",
      "small_grid_model_1\n",
      "1.train. Normal\n",
      "1.test. Normal\n",
      "Split: train, validation and test\n",
      "(40000, 32, 32, 3)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"small_grid_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,056,490\n",
      "Trainable params: 1,056,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 6.2118 - accuracy: 0.1458 - val_loss: 2.2026 - val_accuracy: 0.1925\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 12s 158ms/step - loss: 2.0986 - accuracy: 0.2217 - val_loss: 2.0719 - val_accuracy: 0.2544\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 13s 162ms/step - loss: 2.0182 - accuracy: 0.2607 - val_loss: 1.9419 - val_accuracy: 0.2999\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.9509 - accuracy: 0.2875 - val_loss: 1.8950 - val_accuracy: 0.3159\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.9083 - accuracy: 0.3051 - val_loss: 1.8391 - val_accuracy: 0.3303\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.8727 - accuracy: 0.3159 - val_loss: 1.8754 - val_accuracy: 0.3243\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.8543 - accuracy: 0.3229 - val_loss: 1.7902 - val_accuracy: 0.3496\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.8320 - accuracy: 0.3343 - val_loss: 1.8128 - val_accuracy: 0.3452\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.8188 - accuracy: 0.3433 - val_loss: 1.7723 - val_accuracy: 0.3635\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.8050 - accuracy: 0.3462 - val_loss: 1.7625 - val_accuracy: 0.3678\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.7846 - accuracy: 0.3566 - val_loss: 1.7693 - val_accuracy: 0.3662\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.7729 - accuracy: 0.3559 - val_loss: 1.7546 - val_accuracy: 0.3700\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.7698 - accuracy: 0.3624 - val_loss: 1.7323 - val_accuracy: 0.3847\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 12s 158ms/step - loss: 1.7515 - accuracy: 0.3668 - val_loss: 1.7222 - val_accuracy: 0.3889\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.7407 - accuracy: 0.3758 - val_loss: 1.7351 - val_accuracy: 0.3840\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.7330 - accuracy: 0.3741 - val_loss: 1.7363 - val_accuracy: 0.3824\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.7265 - accuracy: 0.3795 - val_loss: 1.8047 - val_accuracy: 0.3619\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.7071 - accuracy: 0.3869 - val_loss: 1.7260 - val_accuracy: 0.3823\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6991 - accuracy: 0.3886 - val_loss: 1.7570 - val_accuracy: 0.3808\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.6894 - accuracy: 0.3909 - val_loss: 1.7877 - val_accuracy: 0.3701\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.6755 - accuracy: 0.3977 - val_loss: 1.6962 - val_accuracy: 0.4005\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.6746 - accuracy: 0.3960 - val_loss: 1.7599 - val_accuracy: 0.3833\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.6597 - accuracy: 0.4042 - val_loss: 1.7082 - val_accuracy: 0.3953\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6601 - accuracy: 0.4040 - val_loss: 1.7554 - val_accuracy: 0.3803\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.6491 - accuracy: 0.4049 - val_loss: 1.6776 - val_accuracy: 0.4090\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6412 - accuracy: 0.4108 - val_loss: 1.6330 - val_accuracy: 0.4107\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.6288 - accuracy: 0.4150 - val_loss: 1.6697 - val_accuracy: 0.4167\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.6127 - accuracy: 0.4205 - val_loss: 1.6301 - val_accuracy: 0.4228\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6079 - accuracy: 0.4230 - val_loss: 1.6843 - val_accuracy: 0.4086\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6037 - accuracy: 0.4247 - val_loss: 1.6109 - val_accuracy: 0.4308\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.5865 - accuracy: 0.4301 - val_loss: 1.6318 - val_accuracy: 0.4187\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.5666 - accuracy: 0.4363 - val_loss: 1.6983 - val_accuracy: 0.4021\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.5693 - accuracy: 0.4361 - val_loss: 1.5920 - val_accuracy: 0.4349\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.5531 - accuracy: 0.4471 - val_loss: 1.5769 - val_accuracy: 0.4413\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.5403 - accuracy: 0.4469 - val_loss: 1.6085 - val_accuracy: 0.4339\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.5275 - accuracy: 0.4528 - val_loss: 1.6146 - val_accuracy: 0.4366\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.5152 - accuracy: 0.4597 - val_loss: 1.6494 - val_accuracy: 0.4246\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.5166 - accuracy: 0.4575 - val_loss: 1.5383 - val_accuracy: 0.4541\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.5054 - accuracy: 0.4589 - val_loss: 1.5762 - val_accuracy: 0.4496\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4889 - accuracy: 0.4690 - val_loss: 1.5860 - val_accuracy: 0.4516\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4805 - accuracy: 0.4701 - val_loss: 1.5328 - val_accuracy: 0.4578\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4846 - accuracy: 0.4700 - val_loss: 1.5898 - val_accuracy: 0.4537\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4728 - accuracy: 0.4709 - val_loss: 1.5651 - val_accuracy: 0.4540\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4535 - accuracy: 0.4825 - val_loss: 1.5968 - val_accuracy: 0.4429\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4430 - accuracy: 0.4833 - val_loss: 1.5002 - val_accuracy: 0.4747\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4384 - accuracy: 0.4854 - val_loss: 1.5731 - val_accuracy: 0.4569\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4365 - accuracy: 0.4841 - val_loss: 1.4887 - val_accuracy: 0.4776\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4253 - accuracy: 0.4867 - val_loss: 1.4857 - val_accuracy: 0.4780\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4280 - accuracy: 0.4902 - val_loss: 1.5749 - val_accuracy: 0.4558\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4096 - accuracy: 0.4945 - val_loss: 1.5006 - val_accuracy: 0.4737\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4184 - accuracy: 0.4969 - val_loss: 1.5085 - val_accuracy: 0.4756\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.3973 - accuracy: 0.5025 - val_loss: 1.5656 - val_accuracy: 0.4655\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3962 - accuracy: 0.5000 - val_loss: 1.4714 - val_accuracy: 0.4807\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3967 - accuracy: 0.5024 - val_loss: 1.4851 - val_accuracy: 0.4750\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3880 - accuracy: 0.5050 - val_loss: 1.4588 - val_accuracy: 0.4904\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3785 - accuracy: 0.5088 - val_loss: 1.4765 - val_accuracy: 0.4866\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3721 - accuracy: 0.5101 - val_loss: 1.5321 - val_accuracy: 0.4791\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3697 - accuracy: 0.5116 - val_loss: 1.5053 - val_accuracy: 0.4851\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.3572 - accuracy: 0.5138 - val_loss: 1.4416 - val_accuracy: 0.5018\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3566 - accuracy: 0.5155 - val_loss: 1.4901 - val_accuracy: 0.4825\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.3582 - accuracy: 0.5163 - val_loss: 1.4525 - val_accuracy: 0.4956\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.3469 - accuracy: 0.5179 - val_loss: 1.4920 - val_accuracy: 0.4814\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3376 - accuracy: 0.5210 - val_loss: 1.4657 - val_accuracy: 0.4924\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 13s 159ms/step - loss: 1.3369 - accuracy: 0.5221 - val_loss: 1.5488 - val_accuracy: 0.4838\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 13s 160ms/step - loss: 1.3371 - accuracy: 0.5224 - val_loss: 1.4636 - val_accuracy: 0.4976\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 12s 158ms/step - loss: 1.3296 - accuracy: 0.5247 - val_loss: 1.5066 - val_accuracy: 0.4867\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3158 - accuracy: 0.5313 - val_loss: 1.4679 - val_accuracy: 0.4880\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3125 - accuracy: 0.5301 - val_loss: 1.5234 - val_accuracy: 0.4815\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3123 - accuracy: 0.5322 - val_loss: 1.5076 - val_accuracy: 0.4961\n",
      "Epoch 00069: early stopping\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.3924 - accuracy: 0.5145\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4416 - accuracy: 0.5018\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4112 - accuracy: 0.5075\n",
      "Train accuracy: 0.5144749879837036\n",
      "Validation accuracy: 0.501800000667572\n",
      "Test accuracy: 0.5074999928474426\n",
      "small_grid_model_2\n",
      "1.train. Normal\n",
      "1.test. Normal\n",
      "Split: train, validation and test\n",
      "(40000, 32, 32, 3)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"small_grid_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,069,386\n",
      "Trainable params: 1,069,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      " 1/79 [..............................] - ETA: 0s - loss: 17.6208 - accuracy: 0.1074WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0169s). Check your callbacks.\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 4.1285 - accuracy: 0.1995 - val_loss: 1.9588 - val_accuracy: 0.2832\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.8947 - accuracy: 0.3056 - val_loss: 1.8564 - val_accuracy: 0.3348\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.8222 - accuracy: 0.3399 - val_loss: 1.8291 - val_accuracy: 0.3602\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.7638 - accuracy: 0.3627 - val_loss: 1.7626 - val_accuracy: 0.3768\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.7468 - accuracy: 0.3675 - val_loss: 1.7107 - val_accuracy: 0.3932\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.7094 - accuracy: 0.3852 - val_loss: 1.6791 - val_accuracy: 0.4042\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.6844 - accuracy: 0.3967 - val_loss: 1.7484 - val_accuracy: 0.3938\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.6588 - accuracy: 0.4039 - val_loss: 1.7000 - val_accuracy: 0.4010\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.6417 - accuracy: 0.4101 - val_loss: 1.7048 - val_accuracy: 0.3997\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.6149 - accuracy: 0.4184 - val_loss: 1.6394 - val_accuracy: 0.4258\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.6037 - accuracy: 0.4205 - val_loss: 1.6739 - val_accuracy: 0.4121\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.5706 - accuracy: 0.4351 - val_loss: 1.5703 - val_accuracy: 0.4412\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.5661 - accuracy: 0.4342 - val_loss: 1.6896 - val_accuracy: 0.4085\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.5384 - accuracy: 0.4470 - val_loss: 1.5924 - val_accuracy: 0.4376\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.5258 - accuracy: 0.4552 - val_loss: 1.6346 - val_accuracy: 0.4334\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.5060 - accuracy: 0.4560 - val_loss: 1.6650 - val_accuracy: 0.4259\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.4930 - accuracy: 0.4634 - val_loss: 1.5577 - val_accuracy: 0.4485\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.4782 - accuracy: 0.4709 - val_loss: 1.5913 - val_accuracy: 0.4456\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.4652 - accuracy: 0.4743 - val_loss: 1.6125 - val_accuracy: 0.4424\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4511 - accuracy: 0.4800 - val_loss: 1.6038 - val_accuracy: 0.4452\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4468 - accuracy: 0.4816 - val_loss: 1.5698 - val_accuracy: 0.4542\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.4358 - accuracy: 0.4878 - val_loss: 1.5871 - val_accuracy: 0.4483\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.4108 - accuracy: 0.4937 - val_loss: 1.7008 - val_accuracy: 0.4294\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.4116 - accuracy: 0.4936 - val_loss: 1.4953 - val_accuracy: 0.4754\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.3973 - accuracy: 0.5019 - val_loss: 1.5021 - val_accuracy: 0.4758\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.3846 - accuracy: 0.5063 - val_loss: 1.5314 - val_accuracy: 0.4676\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3723 - accuracy: 0.5101 - val_loss: 1.5277 - val_accuracy: 0.4875\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3681 - accuracy: 0.5116 - val_loss: 1.5290 - val_accuracy: 0.4820\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3511 - accuracy: 0.5164 - val_loss: 1.5105 - val_accuracy: 0.4875\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3497 - accuracy: 0.5149 - val_loss: 1.4918 - val_accuracy: 0.4867\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.3441 - accuracy: 0.5217 - val_loss: 1.5289 - val_accuracy: 0.4803\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3329 - accuracy: 0.5257 - val_loss: 1.4879 - val_accuracy: 0.4864\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3235 - accuracy: 0.5281 - val_loss: 1.5622 - val_accuracy: 0.4730\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3154 - accuracy: 0.5291 - val_loss: 1.5049 - val_accuracy: 0.5003\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3081 - accuracy: 0.5321 - val_loss: 1.5129 - val_accuracy: 0.4960\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2973 - accuracy: 0.5345 - val_loss: 1.5603 - val_accuracy: 0.4859\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2971 - accuracy: 0.5365 - val_loss: 1.5117 - val_accuracy: 0.4993\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2784 - accuracy: 0.5469 - val_loss: 1.3689 - val_accuracy: 0.5246\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.2821 - accuracy: 0.5423 - val_loss: 1.4735 - val_accuracy: 0.5024\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.2779 - accuracy: 0.5437 - val_loss: 1.3904 - val_accuracy: 0.5245\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.2741 - accuracy: 0.5463 - val_loss: 1.4430 - val_accuracy: 0.5059\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.2604 - accuracy: 0.5512 - val_loss: 1.4769 - val_accuracy: 0.5073\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.2571 - accuracy: 0.5503 - val_loss: 1.4222 - val_accuracy: 0.5221\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2535 - accuracy: 0.5525 - val_loss: 1.4401 - val_accuracy: 0.5094\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.2422 - accuracy: 0.5585 - val_loss: 1.4684 - val_accuracy: 0.5119\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2591 - accuracy: 0.5529 - val_loss: 1.4536 - val_accuracy: 0.5151\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 1.2475 - accuracy: 0.5570 - val_loss: 1.3899 - val_accuracy: 0.5213\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 13s 160ms/step - loss: 1.2472 - accuracy: 0.5573 - val_loss: 1.4126 - val_accuracy: 0.5217\n",
      "Epoch 00048: early stopping\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.3295 - accuracy: 0.5347\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3689 - accuracy: 0.5246\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3758 - accuracy: 0.5257\n",
      "Train accuracy: 0.5347499847412109\n",
      "Validation accuracy: 0.5246000289916992\n",
      "Test accuracy: 0.5256999731063843\n",
      "small_grid_model_3\n",
      "1.train. Normal\n",
      "1.test. Normal\n",
      "Split: train, validation and test\n",
      "(40000, 32, 32, 3)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"small_grid_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,119,370\n",
      "Trainable params: 2,119,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 5.6244 - accuracy: 0.1922 - val_loss: 1.9391 - val_accuracy: 0.2820\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.9135 - accuracy: 0.2945 - val_loss: 1.9437 - val_accuracy: 0.3053\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.8480 - accuracy: 0.3275 - val_loss: 1.8592 - val_accuracy: 0.3218\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.8000 - accuracy: 0.3433 - val_loss: 1.8344 - val_accuracy: 0.3381\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.7674 - accuracy: 0.3610 - val_loss: 1.7480 - val_accuracy: 0.3642\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.7410 - accuracy: 0.3696 - val_loss: 1.8087 - val_accuracy: 0.3506\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.7141 - accuracy: 0.3786 - val_loss: 1.7642 - val_accuracy: 0.3717\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.6886 - accuracy: 0.3934 - val_loss: 1.7131 - val_accuracy: 0.3819\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6787 - accuracy: 0.3950 - val_loss: 1.7173 - val_accuracy: 0.3872\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.6455 - accuracy: 0.4053 - val_loss: 1.6719 - val_accuracy: 0.4062\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.6194 - accuracy: 0.4171 - val_loss: 1.6924 - val_accuracy: 0.3978\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.5983 - accuracy: 0.4261 - val_loss: 1.7240 - val_accuracy: 0.4030\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.5737 - accuracy: 0.4363 - val_loss: 1.5795 - val_accuracy: 0.4407\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.5594 - accuracy: 0.4402 - val_loss: 1.5967 - val_accuracy: 0.4296\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.5335 - accuracy: 0.4503 - val_loss: 1.6096 - val_accuracy: 0.4390\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.5163 - accuracy: 0.4561 - val_loss: 1.5714 - val_accuracy: 0.4523\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.4979 - accuracy: 0.4632 - val_loss: 1.5708 - val_accuracy: 0.4540\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.4717 - accuracy: 0.4727 - val_loss: 1.6155 - val_accuracy: 0.4432\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4503 - accuracy: 0.4814 - val_loss: 1.5519 - val_accuracy: 0.4656\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.4263 - accuracy: 0.4881 - val_loss: 1.5260 - val_accuracy: 0.4750\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.4340 - accuracy: 0.4892 - val_loss: 1.5142 - val_accuracy: 0.4724\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3993 - accuracy: 0.4984 - val_loss: 1.5732 - val_accuracy: 0.4630\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3927 - accuracy: 0.50 - 12s 152ms/step - loss: 1.3927 - accuracy: 0.5030 - val_loss: 1.5519 - val_accuracy: 0.4748\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.3763 - accuracy: 0.5084 - val_loss: 1.5033 - val_accuracy: 0.4857\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3677 - accuracy: 0.5109 - val_loss: 1.5268 - val_accuracy: 0.4845\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.3480 - accuracy: 0.5189 - val_loss: 1.5046 - val_accuracy: 0.4850\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.3460 - accuracy: 0.5206 - val_loss: 1.4901 - val_accuracy: 0.4947\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.3341 - accuracy: 0.5266 - val_loss: 1.5069 - val_accuracy: 0.4870\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3279 - accuracy: 0.5298 - val_loss: 1.4212 - val_accuracy: 0.5126\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.3113 - accuracy: 0.5316 - val_loss: 1.4900 - val_accuracy: 0.4893\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.3060 - accuracy: 0.5363 - val_loss: 1.5014 - val_accuracy: 0.4919\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.3068 - accuracy: 0.5363 - val_loss: 1.5251 - val_accuracy: 0.4893\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.2838 - accuracy: 0.5419 - val_loss: 1.5055 - val_accuracy: 0.5008\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2844 - accuracy: 0.5418 - val_loss: 1.4030 - val_accuracy: 0.5217\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.2671 - accuracy: 0.5480 - val_loss: 1.4988 - val_accuracy: 0.5031\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.2679 - accuracy: 0.5502 - val_loss: 1.5178 - val_accuracy: 0.4965\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.2555 - accuracy: 0.5588 - val_loss: 1.4416 - val_accuracy: 0.5173\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2517 - accuracy: 0.5525 - val_loss: 1.4251 - val_accuracy: 0.5161\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.2513 - accuracy: 0.5551 - val_loss: 1.4268 - val_accuracy: 0.5169\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.2442 - accuracy: 0.5571 - val_loss: 1.4051 - val_accuracy: 0.5245\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.2373 - accuracy: 0.5607 - val_loss: 1.4158 - val_accuracy: 0.5228\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2254 - accuracy: 0.5630 - val_loss: 1.3614 - val_accuracy: 0.5366\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2324 - accuracy: 0.5633 - val_loss: 1.4163 - val_accuracy: 0.5209\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2171 - accuracy: 0.5677 - val_loss: 1.4009 - val_accuracy: 0.5270\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2044 - accuracy: 0.5717 - val_loss: 1.4364 - val_accuracy: 0.5219\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.2100 - accuracy: 0.5684 - val_loss: 1.3906 - val_accuracy: 0.5306\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.2105 - accuracy: 0.5691 - val_loss: 1.2980 - val_accuracy: 0.5557\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.2016 - accuracy: 0.5734 - val_loss: 1.3794 - val_accuracy: 0.5334\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 1.1954 - accuracy: 0.5743 - val_loss: 1.3918 - val_accuracy: 0.5290\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.1897 - accuracy: 0.5776 - val_loss: 1.4053 - val_accuracy: 0.5350\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.1917 - accuracy: 0.5778 - val_loss: 1.3811 - val_accuracy: 0.5390\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.1827 - accuracy: 0.5805 - val_loss: 1.3372 - val_accuracy: 0.5475\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.1860 - accuracy: 0.5813 - val_loss: 1.3221 - val_accuracy: 0.5550\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.1787 - accuracy: 0.5835 - val_loss: 1.3999 - val_accuracy: 0.5262\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 1.1685 - accuracy: 0.5840 - val_loss: 1.3832 - val_accuracy: 0.5422\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.1637 - accuracy: 0.5864 - val_loss: 1.4131 - val_accuracy: 0.5291\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.1726 - accuracy: 0.5861 - val_loss: 1.3500 - val_accuracy: 0.5401\n",
      "Epoch 00057: early stopping\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.2177 - accuracy: 0.5735\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2980 - accuracy: 0.5557\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2751 - accuracy: 0.5587\n",
      "Train accuracy: 0.5735250115394592\n",
      "Validation accuracy: 0.5557000041007996\n",
      "Test accuracy: 0.5587000250816345\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(grid_small.shape[0]):\n",
    "    \n",
    "    model_name_ = \"small_grid_model_\" + str(i)\n",
    "    print(model_name_)\n",
    "    \n",
    "    morphological_test_cifar_10(results_directory_ = \"Results_5_\",\n",
    "                                model_name_ = model_name_,\n",
    "                                structuring_elements_depth_ = [0, 0],\n",
    "                                transormation_type_ = None,\n",
    "                                structuring_elements_type_ = None,\n",
    "                                structuring_elements_initsize_ = None,\n",
    "                                structuring_elements_step_ = None,\n",
    "                                addborder_ = None,\n",
    "                                morphological_transformation_mode_ = False,\n",
    "                                start_neurons_ = grid_small[\"start_neurons_hp\"][i],\n",
    "                                dense_neurons_ = grid_small[\"dense_neurons_hp\"][i],\n",
    "                                epochs_ = 100,\n",
    "                                batch_size_ = 512,\n",
    "                                augmentation_ = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be294fec-7aba-4640-8582-2f354500f1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big_grid_model_27\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 9)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 9)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 9)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 9)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        2624      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,121,098\n",
      "Trainable params: 2,121,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (40000, 32, 32, 9) (9 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n",
      "C:\\Users\\admin\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (10000, 32, 32, 9) (9 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - 29s 364ms/step - loss: 11.0192 - accuracy: 0.1346 - val_loss: 2.2486 - val_accuracy: 0.1760\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 29s 366ms/step - loss: 2.1930 - accuracy: 0.1859 - val_loss: 2.1848 - val_accuracy: 0.1980\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 29s 363ms/step - loss: 2.1523 - accuracy: 0.2042 - val_loss: 2.1603 - val_accuracy: 0.2010\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 29s 369ms/step - loss: 2.1264 - accuracy: 0.2123 - val_loss: 2.1802 - val_accuracy: 0.2068\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 29s 365ms/step - loss: 2.1061 - accuracy: 0.2249 - val_loss: 2.1755 - val_accuracy: 0.2060\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 29s 365ms/step - loss: 2.0853 - accuracy: 0.2329 - val_loss: 2.2170 - val_accuracy: 0.2019\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 29s 367ms/step - loss: 2.0676 - accuracy: 0.2431 - val_loss: 2.1438 - val_accuracy: 0.2197\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 29s 365ms/step - loss: 2.0588 - accuracy: 0.2480 - val_loss: 2.0982 - val_accuracy: 0.2449\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 29s 366ms/step - loss: 2.0433 - accuracy: 0.2562 - val_loss: 2.1585 - val_accuracy: 0.2168\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 29s 369ms/step - loss: 2.0330 - accuracy: 0.2568 - val_loss: 2.1375 - val_accuracy: 0.2153\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 29s 369ms/step - loss: 2.0148 - accuracy: 0.2677 - val_loss: 2.0436 - val_accuracy: 0.2593\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 29s 364ms/step - loss: 2.0024 - accuracy: 0.2731 - val_loss: 2.0600 - val_accuracy: 0.2558\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 28s 360ms/step - loss: 1.9895 - accuracy: 0.2799 - val_loss: 2.0614 - val_accuracy: 0.2552\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.9824 - accuracy: 0.2812 - val_loss: 2.0600 - val_accuracy: 0.2521\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.9690 - accuracy: 0.2883 - val_loss: 2.0209 - val_accuracy: 0.2738\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.9621 - accuracy: 0.2923 - val_loss: 1.9985 - val_accuracy: 0.2862\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.9518 - accuracy: 0.2970 - val_loss: 1.9407 - val_accuracy: 0.3088\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.9352 - accuracy: 0.3036 - val_loss: 1.9708 - val_accuracy: 0.2926\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.9330 - accuracy: 0.3046 - val_loss: 1.9495 - val_accuracy: 0.3040\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.9215 - accuracy: 0.3090 - val_loss: 1.9063 - val_accuracy: 0.3163\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 28s 360ms/step - loss: 1.8997 - accuracy: 0.3171 - val_loss: 1.8811 - val_accuracy: 0.3276\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.8857 - accuracy: 0.3232 - val_loss: 1.8790 - val_accuracy: 0.3360\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.8805 - accuracy: 0.3243 - val_loss: 1.9315 - val_accuracy: 0.3072\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.8713 - accuracy: 0.3301 - val_loss: 1.8487 - val_accuracy: 0.3420\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8634 - accuracy: 0.3334 - val_loss: 1.8371 - val_accuracy: 0.3484\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.8631 - accuracy: 0.3354 - val_loss: 1.8221 - val_accuracy: 0.3528\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.8428 - accuracy: 0.3408 - val_loss: 1.8324 - val_accuracy: 0.3530\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8257 - accuracy: 0.3465 - val_loss: 1.8419 - val_accuracy: 0.3495\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.8203 - accuracy: 0.3507 - val_loss: 1.8220 - val_accuracy: 0.3501\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8280 - accuracy: 0.3527 - val_loss: 1.8344 - val_accuracy: 0.3515\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.8012 - accuracy: 0.3600 - val_loss: 1.8054 - val_accuracy: 0.3589\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.7893 - accuracy: 0.3596 - val_loss: 1.7652 - val_accuracy: 0.3733\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.7717 - accuracy: 0.3672 - val_loss: 1.7627 - val_accuracy: 0.3762\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.7664 - accuracy: 0.3708 - val_loss: 1.7445 - val_accuracy: 0.3801\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.7493 - accuracy: 0.3772 - val_loss: 1.7579 - val_accuracy: 0.3730\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7345 - accuracy: 0.3808 - val_loss: 1.7408 - val_accuracy: 0.3806\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.7417 - accuracy: 0.3783 - val_loss: 1.9002 - val_accuracy: 0.3230\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.7236 - accuracy: 0.3865 - val_loss: 1.7656 - val_accuracy: 0.3769\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.7134 - accuracy: 0.3890 - val_loss: 1.6811 - val_accuracy: 0.4021\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7091 - accuracy: 0.3921 - val_loss: 1.7127 - val_accuracy: 0.3925\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.7100 - accuracy: 0.3907 - val_loss: 1.6928 - val_accuracy: 0.3876\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.6986 - accuracy: 0.3915 - val_loss: 1.7225 - val_accuracy: 0.3906\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6740 - accuracy: 0.4060 - val_loss: 1.6949 - val_accuracy: 0.3913\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 28s 360ms/step - loss: 1.6566 - accuracy: 0.4088 - val_loss: 1.7304 - val_accuracy: 0.3834\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.6728 - accuracy: 0.4045 - val_loss: 1.7049 - val_accuracy: 0.3892\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 28s 360ms/step - loss: 1.6516 - accuracy: 0.4102 - val_loss: 1.6382 - val_accuracy: 0.4105\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6445 - accuracy: 0.4144 - val_loss: 1.6544 - val_accuracy: 0.4033\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.6545 - accuracy: 0.4101 - val_loss: 1.6190 - val_accuracy: 0.4208\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.6238 - accuracy: 0.4227 - val_loss: 1.5743 - val_accuracy: 0.4388\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.6069 - accuracy: 0.4287 - val_loss: 1.5504 - val_accuracy: 0.4468\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6050 - accuracy: 0.4278 - val_loss: 1.5450 - val_accuracy: 0.4498\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.6008 - accuracy: 0.4293 - val_loss: 1.5916 - val_accuracy: 0.4334\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5962 - accuracy: 0.4306 - val_loss: 1.6190 - val_accuracy: 0.4185\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5770 - accuracy: 0.4344 - val_loss: 1.5592 - val_accuracy: 0.4445\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5933 - accuracy: 0.4317 - val_loss: 1.5246 - val_accuracy: 0.4542\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5825 - accuracy: 0.4372 - val_loss: 1.5855 - val_accuracy: 0.4381\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5621 - accuracy: 0.4436 - val_loss: 1.5905 - val_accuracy: 0.4278\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.5592 - accuracy: 0.4460 - val_loss: 1.5754 - val_accuracy: 0.4363\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5495 - accuracy: 0.4475 - val_loss: 1.5193 - val_accuracy: 0.4558\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5775 - accuracy: 0.4385 - val_loss: 1.5193 - val_accuracy: 0.4550\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5512 - accuracy: 0.4506 - val_loss: 1.5316 - val_accuracy: 0.4540\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5518 - accuracy: 0.4505 - val_loss: 1.5286 - val_accuracy: 0.4535\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5502 - accuracy: 0.4468 - val_loss: 1.5640 - val_accuracy: 0.4402\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5350 - accuracy: 0.4525 - val_loss: 1.5444 - val_accuracy: 0.4464\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5409 - accuracy: 0.4511 - val_loss: 1.5066 - val_accuracy: 0.4607\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.5389 - accuracy: 0.4525 - val_loss: 1.5222 - val_accuracy: 0.4538\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5130 - accuracy: 0.4625 - val_loss: 1.5298 - val_accuracy: 0.4546\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5197 - accuracy: 0.4589 - val_loss: 1.5172 - val_accuracy: 0.4613\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5184 - accuracy: 0.4594 - val_loss: 1.5491 - val_accuracy: 0.4562\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.5213 - accuracy: 0.4600 - val_loss: 1.4667 - val_accuracy: 0.4790\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.5140 - accuracy: 0.4627 - val_loss: 1.4334 - val_accuracy: 0.4855\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.5184 - accuracy: 0.4619 - val_loss: 1.4927 - val_accuracy: 0.4692\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.4904 - accuracy: 0.4734 - val_loss: 1.5079 - val_accuracy: 0.4677\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.4981 - accuracy: 0.4660 - val_loss: 1.4812 - val_accuracy: 0.4728\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.4980 - accuracy: 0.4676 - val_loss: 1.4345 - val_accuracy: 0.4928\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.4749 - accuracy: 0.4783 - val_loss: 1.5282 - val_accuracy: 0.4503\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.4812 - accuracy: 0.4730 - val_loss: 1.5275 - val_accuracy: 0.4608\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.4796 - accuracy: 0.4746 - val_loss: 1.4771 - val_accuracy: 0.4806\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4729 - accuracy: 0.4757 - val_loss: 1.4377 - val_accuracy: 0.4866\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4977 - accuracy: 0.4684 - val_loss: 1.5196 - val_accuracy: 0.4558\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4781 - accuracy: 0.4755 - val_loss: 1.4708 - val_accuracy: 0.4753\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.4652 - accuracy: 0.4803 - val_loss: 1.4646 - val_accuracy: 0.4857\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.4707 - accuracy: 0.4774 - val_loss: 1.4425 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.4562 - accuracy: 0.4820 - val_loss: 1.4301 - val_accuracy: 0.4940\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.4607 - accuracy: 0.4816 - val_loss: 1.4105 - val_accuracy: 0.4981\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.4499 - accuracy: 0.4839 - val_loss: 1.4102 - val_accuracy: 0.5052\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4512 - accuracy: 0.4842 - val_loss: 1.3934 - val_accuracy: 0.5121\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4381 - accuracy: 0.4913 - val_loss: 1.4602 - val_accuracy: 0.4854\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.4433 - accuracy: 0.4883 - val_loss: 1.4456 - val_accuracy: 0.4910\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4353 - accuracy: 0.4930 - val_loss: 1.4448 - val_accuracy: 0.5009\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4371 - accuracy: 0.4890 - val_loss: 1.4292 - val_accuracy: 0.4954\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4325 - accuracy: 0.4939 - val_loss: 1.4128 - val_accuracy: 0.5044\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.4440 - accuracy: 0.4863 - val_loss: 1.3950 - val_accuracy: 0.5060\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.4333 - accuracy: 0.4933 - val_loss: 1.3916 - val_accuracy: 0.5094\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4323 - accuracy: 0.4918 - val_loss: 1.4268 - val_accuracy: 0.4982\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4279 - accuracy: 0.4964 - val_loss: 1.3962 - val_accuracy: 0.5079\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4185 - accuracy: 0.4971 - val_loss: 1.3792 - val_accuracy: 0.5161\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.4219 - accuracy: 0.4955 - val_loss: 1.4584 - val_accuracy: 0.4899\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4175 - accuracy: 0.4993 - val_loss: 1.4089 - val_accuracy: 0.4996\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.4244 - accuracy: 0.4924 - val_loss: 1.4619 - val_accuracy: 0.4832\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3466 - accuracy: 0.5229\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3792 - accuracy: 0.5161\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3718 - accuracy: 0.5140\n",
      "Train accuracy: 0.5228750109672546\n",
      "Validation accuracy: 0.5160999894142151\n",
      "Test accuracy: 0.5139999985694885\n",
      "big_grid_model_28\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 9)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 9)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 9)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 9)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        1312      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 531,658\n",
      "Trainable params: 531,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 6.1335 - accuracy: 0.1506 - val_loss: 2.1740 - val_accuracy: 0.2069\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 2.1403 - accuracy: 0.2061 - val_loss: 2.1712 - val_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 2.1081 - accuracy: 0.2245 - val_loss: 2.1158 - val_accuracy: 0.2179\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 2.0900 - accuracy: 0.2342 - val_loss: 2.1391 - val_accuracy: 0.2191\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 2.0666 - accuracy: 0.2481 - val_loss: 2.0963 - val_accuracy: 0.2385\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 28s 360ms/step - loss: 2.0591 - accuracy: 0.2491 - val_loss: 2.0756 - val_accuracy: 0.2484\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 2.0465 - accuracy: 0.2560 - val_loss: 2.0777 - val_accuracy: 0.2470\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 28s 361ms/step - loss: 2.0400 - accuracy: 0.2600 - val_loss: 2.0605 - val_accuracy: 0.2565\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 2.0293 - accuracy: 0.2641 - val_loss: 2.0667 - val_accuracy: 0.2440\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 2.0119 - accuracy: 0.2737 - val_loss: 2.0760 - val_accuracy: 0.2508\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.9990 - accuracy: 0.2766 - val_loss: 2.0453 - val_accuracy: 0.2553\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 2.0002 - accuracy: 0.2768 - val_loss: 2.0011 - val_accuracy: 0.2786\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.9901 - accuracy: 0.2808 - val_loss: 2.0560 - val_accuracy: 0.2498\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.9833 - accuracy: 0.2806 - val_loss: 2.0391 - val_accuracy: 0.2652\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 29s 361ms/step - loss: 1.9870 - accuracy: 0.2810 - val_loss: 1.9785 - val_accuracy: 0.2847\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.9683 - accuracy: 0.2893 - val_loss: 1.9911 - val_accuracy: 0.2827\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.9622 - accuracy: 0.2933 - val_loss: 1.9509 - val_accuracy: 0.2970\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.9523 - accuracy: 0.2968 - val_loss: 1.9335 - val_accuracy: 0.3115\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.9527 - accuracy: 0.2990 - val_loss: 1.9862 - val_accuracy: 0.2921\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.9461 - accuracy: 0.2993 - val_loss: 1.9244 - val_accuracy: 0.3162\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.9347 - accuracy: 0.3042 - val_loss: 1.9024 - val_accuracy: 0.3161\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.9262 - accuracy: 0.3066 - val_loss: 1.9259 - val_accuracy: 0.3132\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.9235 - accuracy: 0.3068 - val_loss: 1.9313 - val_accuracy: 0.3127\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.9184 - accuracy: 0.3086 - val_loss: 1.9218 - val_accuracy: 0.3135\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.9124 - accuracy: 0.3117 - val_loss: 1.9091 - val_accuracy: 0.3193\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.9080 - accuracy: 0.3141 - val_loss: 1.8911 - val_accuracy: 0.3214\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8913 - accuracy: 0.3217 - val_loss: 1.8984 - val_accuracy: 0.3280\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8817 - accuracy: 0.3270 - val_loss: 1.8888 - val_accuracy: 0.3278\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.8807 - accuracy: 0.3246 - val_loss: 1.8949 - val_accuracy: 0.3235\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 28s 360ms/step - loss: 1.8718 - accuracy: 0.3307 - val_loss: 1.8976 - val_accuracy: 0.3232\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.8662 - accuracy: 0.3276 - val_loss: 1.8694 - val_accuracy: 0.3419\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8677 - accuracy: 0.3287 - val_loss: 1.8712 - val_accuracy: 0.3380\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.8536 - accuracy: 0.3340 - val_loss: 1.8590 - val_accuracy: 0.3370\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8442 - accuracy: 0.3382 - val_loss: 1.8395 - val_accuracy: 0.3430\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.8441 - accuracy: 0.3388 - val_loss: 1.8870 - val_accuracy: 0.3305\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8283 - accuracy: 0.3410 - val_loss: 1.8832 - val_accuracy: 0.3353\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.8403 - accuracy: 0.3408 - val_loss: 1.8573 - val_accuracy: 0.3344\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.8264 - accuracy: 0.3444 - val_loss: 1.8461 - val_accuracy: 0.3444\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8248 - accuracy: 0.3438 - val_loss: 1.7885 - val_accuracy: 0.3689\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.8126 - accuracy: 0.3505 - val_loss: 1.8309 - val_accuracy: 0.3481\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 28s 360ms/step - loss: 1.8164 - accuracy: 0.3473 - val_loss: 1.8036 - val_accuracy: 0.3600\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.7922 - accuracy: 0.3557 - val_loss: 1.7707 - val_accuracy: 0.3725\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.7925 - accuracy: 0.3603 - val_loss: 1.7994 - val_accuracy: 0.3665\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7882 - accuracy: 0.3571 - val_loss: 1.7894 - val_accuracy: 0.3640\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.7860 - accuracy: 0.3598 - val_loss: 1.8350 - val_accuracy: 0.3471\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.7916 - accuracy: 0.3570 - val_loss: 1.8386 - val_accuracy: 0.3430\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7954 - accuracy: 0.3587 - val_loss: 1.8379 - val_accuracy: 0.3452\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.7759 - accuracy: 0.3616 - val_loss: 1.8044 - val_accuracy: 0.3634\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.7624 - accuracy: 0.3679 - val_loss: 1.7416 - val_accuracy: 0.3782\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7646 - accuracy: 0.3699 - val_loss: 1.7210 - val_accuracy: 0.3831\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.7653 - accuracy: 0.3702 - val_loss: 1.7367 - val_accuracy: 0.3813\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.7565 - accuracy: 0.3726 - val_loss: 1.7523 - val_accuracy: 0.3762\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.7632 - accuracy: 0.3686 - val_loss: 1.7667 - val_accuracy: 0.3731\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.7298 - accuracy: 0.3797 - val_loss: 1.7220 - val_accuracy: 0.3891\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.7270 - accuracy: 0.3823 - val_loss: 1.7361 - val_accuracy: 0.3918\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.7292 - accuracy: 0.3801 - val_loss: 1.8021 - val_accuracy: 0.3545\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.7208 - accuracy: 0.3867 - val_loss: 1.7267 - val_accuracy: 0.3914\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 28s 361ms/step - loss: 1.7135 - accuracy: 0.3883 - val_loss: 1.7179 - val_accuracy: 0.3922\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.7094 - accuracy: 0.3895 - val_loss: 1.7004 - val_accuracy: 0.3983\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7016 - accuracy: 0.3906 - val_loss: 1.6783 - val_accuracy: 0.4078\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.6933 - accuracy: 0.3935 - val_loss: 1.6961 - val_accuracy: 0.3972\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6948 - accuracy: 0.3963 - val_loss: 1.7148 - val_accuracy: 0.3980\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6940 - accuracy: 0.3972 - val_loss: 1.7112 - val_accuracy: 0.3991\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6809 - accuracy: 0.4022 - val_loss: 1.6940 - val_accuracy: 0.3986\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6794 - accuracy: 0.4027 - val_loss: 1.6645 - val_accuracy: 0.4130\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6732 - accuracy: 0.4059 - val_loss: 1.6724 - val_accuracy: 0.4099\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6598 - accuracy: 0.4112 - val_loss: 1.6775 - val_accuracy: 0.4102\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6776 - accuracy: 0.4041 - val_loss: 1.6937 - val_accuracy: 0.3946\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6578 - accuracy: 0.4139 - val_loss: 1.7066 - val_accuracy: 0.3983\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.6518 - accuracy: 0.4126 - val_loss: 1.7077 - val_accuracy: 0.4005\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6566 - accuracy: 0.4087 - val_loss: 1.6272 - val_accuracy: 0.4221\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6465 - accuracy: 0.4110 - val_loss: 1.6382 - val_accuracy: 0.4202\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6447 - accuracy: 0.4126 - val_loss: 1.5893 - val_accuracy: 0.4365\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6451 - accuracy: 0.4145 - val_loss: 1.6384 - val_accuracy: 0.4189\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6364 - accuracy: 0.4184 - val_loss: 1.6256 - val_accuracy: 0.4261\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.6330 - accuracy: 0.4180 - val_loss: 1.6245 - val_accuracy: 0.4246\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 29s 361ms/step - loss: 1.6330 - accuracy: 0.4196 - val_loss: 1.5989 - val_accuracy: 0.4330\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.6248 - accuracy: 0.4202 - val_loss: 1.6582 - val_accuracy: 0.4220\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.6262 - accuracy: 0.4222 - val_loss: 1.6960 - val_accuracy: 0.4178\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.6281 - accuracy: 0.4208 - val_loss: 1.5891 - val_accuracy: 0.4368\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6159 - accuracy: 0.4264 - val_loss: 1.6319 - val_accuracy: 0.4253\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6195 - accuracy: 0.4221 - val_loss: 1.6056 - val_accuracy: 0.4349\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.6106 - accuracy: 0.4277 - val_loss: 1.6467 - val_accuracy: 0.4209\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.6126 - accuracy: 0.4252 - val_loss: 1.6574 - val_accuracy: 0.4203\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6126 - accuracy: 0.4256 - val_loss: 1.5994 - val_accuracy: 0.4435\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6072 - accuracy: 0.4301 - val_loss: 1.6262 - val_accuracy: 0.4289\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.6028 - accuracy: 0.4290 - val_loss: 1.5971 - val_accuracy: 0.4357\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6024 - accuracy: 0.4277 - val_loss: 1.6200 - val_accuracy: 0.4292\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5994 - accuracy: 0.4311 - val_loss: 1.6224 - val_accuracy: 0.4252\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5973 - accuracy: 0.4331 - val_loss: 1.6016 - val_accuracy: 0.4361\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5967 - accuracy: 0.4291 - val_loss: 1.6505 - val_accuracy: 0.4261\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5847 - accuracy: 0.4396 - val_loss: 1.5935 - val_accuracy: 0.4374\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5831 - accuracy: 0.4380 - val_loss: 1.5437 - val_accuracy: 0.4506\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5787 - accuracy: 0.4371 - val_loss: 1.5976 - val_accuracy: 0.4350\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5802 - accuracy: 0.4388 - val_loss: 1.5619 - val_accuracy: 0.4441\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5806 - accuracy: 0.4355 - val_loss: 1.5547 - val_accuracy: 0.4527\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5771 - accuracy: 0.4399 - val_loss: 1.5564 - val_accuracy: 0.4542\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.5750 - accuracy: 0.4414 - val_loss: 1.5961 - val_accuracy: 0.4397\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 29s 362ms/step - loss: 1.5749 - accuracy: 0.4408 - val_loss: 1.5775 - val_accuracy: 0.4504\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5709 - accuracy: 0.4414 - val_loss: 1.5906 - val_accuracy: 0.4452\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.5287 - accuracy: 0.4552\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5564 - accuracy: 0.4542\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5376 - accuracy: 0.4549\n",
      "Train accuracy: 0.4551750123500824\n",
      "Validation accuracy: 0.45419999957084656\n",
      "Test accuracy: 0.45489999651908875\n",
      "big_grid_model_29\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 9)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 9)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 9)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 9)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        1312      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,057,354\n",
      "Trainable params: 1,057,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 6.9273 - accuracy: 0.1280 - val_loss: 2.2385 - val_accuracy: 0.1664\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 29s 362ms/step - loss: 2.1976 - accuracy: 0.1748 - val_loss: 2.2299 - val_accuracy: 0.1723\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 2.1679 - accuracy: 0.1896 - val_loss: 2.2049 - val_accuracy: 0.1845\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 2.1320 - accuracy: 0.2116 - val_loss: 2.1736 - val_accuracy: 0.2060\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 2.1048 - accuracy: 0.2290 - val_loss: 2.1444 - val_accuracy: 0.2170\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 2.0906 - accuracy: 0.2334 - val_loss: 2.1225 - val_accuracy: 0.2317\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 2.0689 - accuracy: 0.2459 - val_loss: 2.1268 - val_accuracy: 0.2214\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 2.0780 - accuracy: 0.2396 - val_loss: 2.0934 - val_accuracy: 0.2503\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 2.0534 - accuracy: 0.2498 - val_loss: 2.0627 - val_accuracy: 0.2639\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 2.0373 - accuracy: 0.2627 - val_loss: 2.0784 - val_accuracy: 0.2540\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 2.0159 - accuracy: 0.2683 - val_loss: 2.0555 - val_accuracy: 0.2649\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 2.0198 - accuracy: 0.2688 - val_loss: 2.0521 - val_accuracy: 0.2585\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 2.0036 - accuracy: 0.2747 - val_loss: 2.0348 - val_accuracy: 0.2631\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 2.0032 - accuracy: 0.2750 - val_loss: 2.0638 - val_accuracy: 0.2551\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.9845 - accuracy: 0.2820 - val_loss: 2.1677 - val_accuracy: 0.2283\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.9787 - accuracy: 0.2842 - val_loss: 2.0218 - val_accuracy: 0.2739\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.9710 - accuracy: 0.2885 - val_loss: 2.0637 - val_accuracy: 0.2617\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.9570 - accuracy: 0.2929 - val_loss: 2.0290 - val_accuracy: 0.2737\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.9529 - accuracy: 0.2986 - val_loss: 2.0763 - val_accuracy: 0.2587\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.9453 - accuracy: 0.2968 - val_loss: 1.9561 - val_accuracy: 0.3030\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.9333 - accuracy: 0.3039 - val_loss: 2.0088 - val_accuracy: 0.2840\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.9263 - accuracy: 0.3074 - val_loss: 2.0418 - val_accuracy: 0.2657\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.9166 - accuracy: 0.3092 - val_loss: 1.9880 - val_accuracy: 0.2929\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.9071 - accuracy: 0.3155 - val_loss: 1.9462 - val_accuracy: 0.3082\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.8926 - accuracy: 0.3225 - val_loss: 1.9138 - val_accuracy: 0.3230\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.9006 - accuracy: 0.3167 - val_loss: 1.9107 - val_accuracy: 0.3233\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.8734 - accuracy: 0.3282 - val_loss: 1.9424 - val_accuracy: 0.3131\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.8661 - accuracy: 0.3280 - val_loss: 1.9154 - val_accuracy: 0.3233\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.8617 - accuracy: 0.3323 - val_loss: 1.9174 - val_accuracy: 0.3204\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.8605 - accuracy: 0.3331 - val_loss: 1.8977 - val_accuracy: 0.3232\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.8401 - accuracy: 0.3410 - val_loss: 1.8495 - val_accuracy: 0.3496\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.8280 - accuracy: 0.3430 - val_loss: 1.8633 - val_accuracy: 0.3406\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 28s 351ms/step - loss: 1.8245 - accuracy: 0.3478 - val_loss: 2.0308 - val_accuracy: 0.2747\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.8227 - accuracy: 0.3443 - val_loss: 1.8325 - val_accuracy: 0.3467\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8097 - accuracy: 0.3498 - val_loss: 1.8246 - val_accuracy: 0.3534\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.8005 - accuracy: 0.3562 - val_loss: 1.8499 - val_accuracy: 0.3428\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.8077 - accuracy: 0.3525 - val_loss: 1.8016 - val_accuracy: 0.3691\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7916 - accuracy: 0.3571 - val_loss: 1.8162 - val_accuracy: 0.3589\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.7948 - accuracy: 0.3576 - val_loss: 1.7994 - val_accuracy: 0.3583\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.7760 - accuracy: 0.3638 - val_loss: 1.8369 - val_accuracy: 0.3486\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.7754 - accuracy: 0.3640 - val_loss: 1.8298 - val_accuracy: 0.3505\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7655 - accuracy: 0.3678 - val_loss: 1.7557 - val_accuracy: 0.3765\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.7607 - accuracy: 0.3702 - val_loss: 1.7534 - val_accuracy: 0.3779\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.7444 - accuracy: 0.3726 - val_loss: 1.7645 - val_accuracy: 0.3730\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.7461 - accuracy: 0.3756 - val_loss: 1.7523 - val_accuracy: 0.3721\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.7308 - accuracy: 0.3813 - val_loss: 1.8015 - val_accuracy: 0.3641\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.7294 - accuracy: 0.3789 - val_loss: 1.7812 - val_accuracy: 0.3652\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.7274 - accuracy: 0.3871 - val_loss: 1.7790 - val_accuracy: 0.3742\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.7252 - accuracy: 0.3818 - val_loss: 1.7411 - val_accuracy: 0.3869\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.7153 - accuracy: 0.3858 - val_loss: 1.7505 - val_accuracy: 0.3812\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.7135 - accuracy: 0.3860 - val_loss: 1.7483 - val_accuracy: 0.3821\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.7057 - accuracy: 0.3911 - val_loss: 1.7310 - val_accuracy: 0.3850\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.7135 - accuracy: 0.3865 - val_loss: 1.7072 - val_accuracy: 0.3923\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6818 - accuracy: 0.4002 - val_loss: 1.7839 - val_accuracy: 0.3689\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6882 - accuracy: 0.3935 - val_loss: 1.6822 - val_accuracy: 0.4042\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6832 - accuracy: 0.3979 - val_loss: 1.7161 - val_accuracy: 0.3971\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6696 - accuracy: 0.4029 - val_loss: 1.6847 - val_accuracy: 0.3978\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6613 - accuracy: 0.4089 - val_loss: 1.6662 - val_accuracy: 0.4048\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6544 - accuracy: 0.4112 - val_loss: 1.6832 - val_accuracy: 0.4024\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6560 - accuracy: 0.4126 - val_loss: 1.6761 - val_accuracy: 0.4116\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6560 - accuracy: 0.4105 - val_loss: 1.6447 - val_accuracy: 0.4223\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6453 - accuracy: 0.4139 - val_loss: 1.6826 - val_accuracy: 0.3953\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6395 - accuracy: 0.4162 - val_loss: 1.6845 - val_accuracy: 0.4059\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6321 - accuracy: 0.4197 - val_loss: 1.8567 - val_accuracy: 0.3358\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.6320 - accuracy: 0.4183 - val_loss: 1.7000 - val_accuracy: 0.4099\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6268 - accuracy: 0.4196 - val_loss: 1.6532 - val_accuracy: 0.4219\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.6123 - accuracy: 0.4258 - val_loss: 1.6673 - val_accuracy: 0.4151\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6204 - accuracy: 0.4265 - val_loss: 1.6902 - val_accuracy: 0.4015\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.6070 - accuracy: 0.4291 - val_loss: 1.6734 - val_accuracy: 0.4122\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6123 - accuracy: 0.4267 - val_loss: 1.6130 - val_accuracy: 0.4331\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5975 - accuracy: 0.4313 - val_loss: 1.6103 - val_accuracy: 0.4352\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5939 - accuracy: 0.4348 - val_loss: 1.6441 - val_accuracy: 0.4213\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5885 - accuracy: 0.4345 - val_loss: 1.5993 - val_accuracy: 0.4341\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5840 - accuracy: 0.4380 - val_loss: 1.5807 - val_accuracy: 0.4426\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5966 - accuracy: 0.4299 - val_loss: 1.5871 - val_accuracy: 0.4375\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5867 - accuracy: 0.4350 - val_loss: 1.6133 - val_accuracy: 0.4335\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5776 - accuracy: 0.4388 - val_loss: 1.6493 - val_accuracy: 0.4326\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5795 - accuracy: 0.4377 - val_loss: 1.5702 - val_accuracy: 0.4430\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5808 - accuracy: 0.4381 - val_loss: 1.5563 - val_accuracy: 0.4485\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5723 - accuracy: 0.4422 - val_loss: 1.5643 - val_accuracy: 0.4562\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5654 - accuracy: 0.4441 - val_loss: 1.5713 - val_accuracy: 0.4442\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.5669 - accuracy: 0.4444 - val_loss: 1.5646 - val_accuracy: 0.4454\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5637 - accuracy: 0.4439 - val_loss: 1.5703 - val_accuracy: 0.4501\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5636 - accuracy: 0.4456 - val_loss: 1.5866 - val_accuracy: 0.4383\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5562 - accuracy: 0.4469 - val_loss: 1.5571 - val_accuracy: 0.4505\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5571 - accuracy: 0.4457 - val_loss: 1.5393 - val_accuracy: 0.4534\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5588 - accuracy: 0.4454 - val_loss: 1.5541 - val_accuracy: 0.4583\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.5502 - accuracy: 0.4471 - val_loss: 1.6715 - val_accuracy: 0.4133\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5466 - accuracy: 0.4487 - val_loss: 1.6012 - val_accuracy: 0.4410\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5514 - accuracy: 0.4505 - val_loss: 1.5664 - val_accuracy: 0.4450\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5407 - accuracy: 0.4537 - val_loss: 1.5016 - val_accuracy: 0.4644\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5516 - accuracy: 0.4484 - val_loss: 1.5405 - val_accuracy: 0.4586\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5374 - accuracy: 0.4541 - val_loss: 1.6209 - val_accuracy: 0.4272\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5276 - accuracy: 0.4569 - val_loss: 1.5443 - val_accuracy: 0.4573\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5338 - accuracy: 0.4552 - val_loss: 1.6057 - val_accuracy: 0.4416\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5271 - accuracy: 0.4597 - val_loss: 1.5945 - val_accuracy: 0.4474\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5303 - accuracy: 0.4579 - val_loss: 1.5873 - val_accuracy: 0.4387\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.5223 - accuracy: 0.4586 - val_loss: 1.5950 - val_accuracy: 0.4397\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5264 - accuracy: 0.4561 - val_loss: 1.5729 - val_accuracy: 0.4531\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5188 - accuracy: 0.4604 - val_loss: 1.5230 - val_accuracy: 0.4672\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.4835 - accuracy: 0.4789\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5230 - accuracy: 0.4672\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5084 - accuracy: 0.4722\n",
      "Train accuracy: 0.47894999384880066\n",
      "Validation accuracy: 0.46720001101493835\n",
      "Test accuracy: 0.4722000062465668\n",
      "big_grid_model_30\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 9)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 9)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 9)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 9)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        2624      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,071,114\n",
      "Trainable params: 1,071,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 29s 364ms/step - loss: 6.7959 - accuracy: 0.1736 - val_loss: 2.1355 - val_accuracy: 0.2146\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 2.0832 - accuracy: 0.2357 - val_loss: 2.0221 - val_accuracy: 0.2745\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 2.0480 - accuracy: 0.2562 - val_loss: 2.0106 - val_accuracy: 0.2724\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 2.0179 - accuracy: 0.2706 - val_loss: 1.9892 - val_accuracy: 0.2860\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 2.0058 - accuracy: 0.2727 - val_loss: 1.9662 - val_accuracy: 0.3026\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.9822 - accuracy: 0.2854 - val_loss: 1.9395 - val_accuracy: 0.3100\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.9647 - accuracy: 0.2940 - val_loss: 1.9841 - val_accuracy: 0.2912\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 28s 360ms/step - loss: 1.9411 - accuracy: 0.3031 - val_loss: 1.9071 - val_accuracy: 0.3227\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.9286 - accuracy: 0.3093 - val_loss: 1.8914 - val_accuracy: 0.3198\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.9329 - accuracy: 0.3057 - val_loss: 1.9104 - val_accuracy: 0.3302\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.9047 - accuracy: 0.3189 - val_loss: 1.8553 - val_accuracy: 0.3387\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8948 - accuracy: 0.3196 - val_loss: 1.8492 - val_accuracy: 0.3326\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8869 - accuracy: 0.3235 - val_loss: 1.9113 - val_accuracy: 0.3107\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8702 - accuracy: 0.3307 - val_loss: 1.8497 - val_accuracy: 0.3426\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.8557 - accuracy: 0.3393 - val_loss: 1.8179 - val_accuracy: 0.3581\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.8557 - accuracy: 0.3400 - val_loss: 1.8232 - val_accuracy: 0.3560\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.8437 - accuracy: 0.3446 - val_loss: 1.9005 - val_accuracy: 0.3224\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.8330 - accuracy: 0.3458 - val_loss: 1.7915 - val_accuracy: 0.3642\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.8113 - accuracy: 0.3541 - val_loss: 1.8136 - val_accuracy: 0.3590\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.7958 - accuracy: 0.3613 - val_loss: 1.7701 - val_accuracy: 0.3675\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.7903 - accuracy: 0.3611 - val_loss: 1.7960 - val_accuracy: 0.3509\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.7833 - accuracy: 0.3624 - val_loss: 1.7855 - val_accuracy: 0.3697\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.7728 - accuracy: 0.3673 - val_loss: 1.7369 - val_accuracy: 0.3832\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.7603 - accuracy: 0.3709 - val_loss: 1.7407 - val_accuracy: 0.3854\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.7511 - accuracy: 0.3763 - val_loss: 1.7573 - val_accuracy: 0.3815\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.7349 - accuracy: 0.3780 - val_loss: 1.7441 - val_accuracy: 0.3713\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.7202 - accuracy: 0.3856 - val_loss: 1.6838 - val_accuracy: 0.4017\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.7169 - accuracy: 0.3855 - val_loss: 1.7218 - val_accuracy: 0.3835\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6997 - accuracy: 0.3924 - val_loss: 1.6713 - val_accuracy: 0.4024\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6922 - accuracy: 0.3924 - val_loss: 1.6623 - val_accuracy: 0.4124\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6995 - accuracy: 0.3950 - val_loss: 1.6375 - val_accuracy: 0.4121\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.6872 - accuracy: 0.3971 - val_loss: 1.6444 - val_accuracy: 0.4238\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6840 - accuracy: 0.3960 - val_loss: 1.6634 - val_accuracy: 0.3984\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6659 - accuracy: 0.4071 - val_loss: 1.6789 - val_accuracy: 0.4039\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6570 - accuracy: 0.4095 - val_loss: 1.6694 - val_accuracy: 0.3944\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.6596 - accuracy: 0.4064 - val_loss: 1.6518 - val_accuracy: 0.4076\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6538 - accuracy: 0.4105 - val_loss: 1.6363 - val_accuracy: 0.4138\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6361 - accuracy: 0.4137 - val_loss: 1.6412 - val_accuracy: 0.4131\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6362 - accuracy: 0.4150 - val_loss: 1.6052 - val_accuracy: 0.4271\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6242 - accuracy: 0.4187 - val_loss: 1.5808 - val_accuracy: 0.4388\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6208 - accuracy: 0.4238 - val_loss: 1.6276 - val_accuracy: 0.4173\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6208 - accuracy: 0.4215 - val_loss: 1.6390 - val_accuracy: 0.4227\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 29s 364ms/step - loss: 1.6197 - accuracy: 0.4229 - val_loss: 1.5623 - val_accuracy: 0.4382\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5970 - accuracy: 0.4341 - val_loss: 1.5583 - val_accuracy: 0.4468\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5975 - accuracy: 0.4317 - val_loss: 1.5430 - val_accuracy: 0.4423\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5946 - accuracy: 0.4294 - val_loss: 1.5885 - val_accuracy: 0.4386\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5847 - accuracy: 0.4322 - val_loss: 1.5489 - val_accuracy: 0.4508\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5747 - accuracy: 0.4376 - val_loss: 1.5529 - val_accuracy: 0.4506\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5813 - accuracy: 0.4347 - val_loss: 1.5346 - val_accuracy: 0.4535\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5746 - accuracy: 0.4409 - val_loss: 1.5012 - val_accuracy: 0.4677\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5750 - accuracy: 0.4365 - val_loss: 1.5648 - val_accuracy: 0.4431\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5633 - accuracy: 0.4424 - val_loss: 1.5068 - val_accuracy: 0.4594\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.5645 - accuracy: 0.4419 - val_loss: 1.5071 - val_accuracy: 0.4685\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.5659 - accuracy: 0.4425 - val_loss: 1.5703 - val_accuracy: 0.4408\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5550 - accuracy: 0.4465 - val_loss: 1.5478 - val_accuracy: 0.4411\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5575 - accuracy: 0.4433 - val_loss: 1.5045 - val_accuracy: 0.4650\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5457 - accuracy: 0.4487 - val_loss: 1.4977 - val_accuracy: 0.4764\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5394 - accuracy: 0.4546 - val_loss: 1.5163 - val_accuracy: 0.4611\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5373 - accuracy: 0.4522 - val_loss: 1.4852 - val_accuracy: 0.4723\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5297 - accuracy: 0.4533 - val_loss: 1.4928 - val_accuracy: 0.4696\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.5418 - accuracy: 0.4522 - val_loss: 1.5079 - val_accuracy: 0.4581\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.5271 - accuracy: 0.4543 - val_loss: 1.4955 - val_accuracy: 0.4675\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.5340 - accuracy: 0.4539 - val_loss: 1.5159 - val_accuracy: 0.4641\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.5180 - accuracy: 0.4608 - val_loss: 1.4579 - val_accuracy: 0.4835\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.5180 - accuracy: 0.4579 - val_loss: 1.4442 - val_accuracy: 0.4907\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 29s 361ms/step - loss: 1.5080 - accuracy: 0.4670 - val_loss: 1.4665 - val_accuracy: 0.4750\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5112 - accuracy: 0.4629 - val_loss: 1.4835 - val_accuracy: 0.4806\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5083 - accuracy: 0.4645 - val_loss: 1.4356 - val_accuracy: 0.4899\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5046 - accuracy: 0.4650 - val_loss: 1.4430 - val_accuracy: 0.4925\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5198 - accuracy: 0.4606 - val_loss: 1.5020 - val_accuracy: 0.4632\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.4993 - accuracy: 0.4665 - val_loss: 1.4605 - val_accuracy: 0.4784\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.4969 - accuracy: 0.4710 - val_loss: 1.4737 - val_accuracy: 0.4813\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5045 - accuracy: 0.4666 - val_loss: 1.4672 - val_accuracy: 0.4780\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.4924 - accuracy: 0.4693 - val_loss: 1.4872 - val_accuracy: 0.4650\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.4851 - accuracy: 0.4721 - val_loss: 1.4316 - val_accuracy: 0.4923\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.4941 - accuracy: 0.4688 - val_loss: 1.4582 - val_accuracy: 0.4756\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 31s 392ms/step - loss: 1.4847 - accuracy: 0.4742 - val_loss: 1.4561 - val_accuracy: 0.4760\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.4911 - accuracy: 0.4703 - val_loss: 1.5239 - val_accuracy: 0.4563\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.4842 - accuracy: 0.4742 - val_loss: 1.4495 - val_accuracy: 0.4889\n",
      "Epoch 00079: early stopping\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.4106 - accuracy: 0.4960\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4430 - accuracy: 0.4925\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4238 - accuracy: 0.4917\n",
      "Train accuracy: 0.49597498774528503\n",
      "Validation accuracy: 0.4925000071525574\n",
      "Test accuracy: 0.4916999936103821\n",
      "big_grid_model_31\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 9)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 9)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 9)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 9)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        2624      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,121,098\n",
      "Trainable params: 2,121,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 9.0605 - accuracy: 0.1802 - val_loss: 2.1186 - val_accuracy: 0.2259\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 2.0728 - accuracy: 0.2467 - val_loss: 2.0369 - val_accuracy: 0.2741\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 2.0383 - accuracy: 0.2597 - val_loss: 1.9953 - val_accuracy: 0.2818\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.9929 - accuracy: 0.2814 - val_loss: 1.9816 - val_accuracy: 0.2847\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.9739 - accuracy: 0.2901 - val_loss: 1.9348 - val_accuracy: 0.3090\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 28s 360ms/step - loss: 1.9681 - accuracy: 0.2924 - val_loss: 1.9159 - val_accuracy: 0.3178\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.9337 - accuracy: 0.3061 - val_loss: 1.9391 - val_accuracy: 0.3077\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.9269 - accuracy: 0.3088 - val_loss: 1.9074 - val_accuracy: 0.3257\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.9067 - accuracy: 0.3151 - val_loss: 1.9098 - val_accuracy: 0.3090\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.9030 - accuracy: 0.3171 - val_loss: 1.8667 - val_accuracy: 0.3393\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.8877 - accuracy: 0.3266 - val_loss: 1.8356 - val_accuracy: 0.3499\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.8717 - accuracy: 0.3298 - val_loss: 1.8838 - val_accuracy: 0.3285\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.8609 - accuracy: 0.3325 - val_loss: 1.8694 - val_accuracy: 0.3308\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.8579 - accuracy: 0.3374 - val_loss: 1.8077 - val_accuracy: 0.3522\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.8469 - accuracy: 0.3392 - val_loss: 1.8172 - val_accuracy: 0.3503\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.8169 - accuracy: 0.3523 - val_loss: 1.8526 - val_accuracy: 0.3332\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.8016 - accuracy: 0.3560 - val_loss: 1.7932 - val_accuracy: 0.3569\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.7928 - accuracy: 0.3580 - val_loss: 1.7721 - val_accuracy: 0.3680\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7758 - accuracy: 0.3672 - val_loss: 1.7642 - val_accuracy: 0.3711\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.7647 - accuracy: 0.3701 - val_loss: 1.7219 - val_accuracy: 0.3809\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.7512 - accuracy: 0.3720 - val_loss: 1.7911 - val_accuracy: 0.3557\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7334 - accuracy: 0.3832 - val_loss: 1.7679 - val_accuracy: 0.3740\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.7303 - accuracy: 0.3808 - val_loss: 1.7265 - val_accuracy: 0.3937\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7108 - accuracy: 0.3885 - val_loss: 1.7081 - val_accuracy: 0.4006\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.7213 - accuracy: 0.3887 - val_loss: 1.6755 - val_accuracy: 0.4042\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.7126 - accuracy: 0.3872 - val_loss: 1.6904 - val_accuracy: 0.4047\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6997 - accuracy: 0.3946 - val_loss: 1.7083 - val_accuracy: 0.4030\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.6770 - accuracy: 0.4029 - val_loss: 1.6449 - val_accuracy: 0.4217\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6800 - accuracy: 0.4019 - val_loss: 1.6950 - val_accuracy: 0.4038\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6823 - accuracy: 0.4009 - val_loss: 1.6932 - val_accuracy: 0.4068\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6566 - accuracy: 0.4093 - val_loss: 1.6255 - val_accuracy: 0.4321\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6550 - accuracy: 0.4091 - val_loss: 1.6713 - val_accuracy: 0.4053\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.6474 - accuracy: 0.4119 - val_loss: 1.6667 - val_accuracy: 0.4040\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 28s 351ms/step - loss: 1.6362 - accuracy: 0.4172 - val_loss: 1.5838 - val_accuracy: 0.4439\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.6283 - accuracy: 0.4201 - val_loss: 1.5835 - val_accuracy: 0.4412\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6195 - accuracy: 0.4207 - val_loss: 1.5753 - val_accuracy: 0.4442\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.6228 - accuracy: 0.4239 - val_loss: 1.5707 - val_accuracy: 0.4507\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6102 - accuracy: 0.4265 - val_loss: 1.5741 - val_accuracy: 0.4376\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.6126 - accuracy: 0.4251 - val_loss: 1.6543 - val_accuracy: 0.4204\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.5894 - accuracy: 0.4353 - val_loss: 1.5626 - val_accuracy: 0.4459\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.5881 - accuracy: 0.4361 - val_loss: 1.5879 - val_accuracy: 0.4482\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.5817 - accuracy: 0.4351 - val_loss: 1.5236 - val_accuracy: 0.4696\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5856 - accuracy: 0.4332 - val_loss: 1.5606 - val_accuracy: 0.4483\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5641 - accuracy: 0.4457 - val_loss: 1.5575 - val_accuracy: 0.4467\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5727 - accuracy: 0.4424 - val_loss: 1.5330 - val_accuracy: 0.4674\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5620 - accuracy: 0.4427 - val_loss: 1.5603 - val_accuracy: 0.4463\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5618 - accuracy: 0.4464 - val_loss: 1.5394 - val_accuracy: 0.4612\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5505 - accuracy: 0.4514 - val_loss: 1.5239 - val_accuracy: 0.4664\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.5515 - accuracy: 0.4484 - val_loss: 1.5794 - val_accuracy: 0.4453\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5410 - accuracy: 0.4507 - val_loss: 1.5168 - val_accuracy: 0.4583\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 28s 351ms/step - loss: 1.5373 - accuracy: 0.4539 - val_loss: 1.5029 - val_accuracy: 0.4725\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.5415 - accuracy: 0.4520 - val_loss: 1.5447 - val_accuracy: 0.4609\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5223 - accuracy: 0.4604 - val_loss: 1.5110 - val_accuracy: 0.4711\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.5211 - accuracy: 0.4590 - val_loss: 1.5639 - val_accuracy: 0.4500\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5223 - accuracy: 0.4594 - val_loss: 1.4968 - val_accuracy: 0.4751\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5298 - accuracy: 0.4568 - val_loss: 1.4709 - val_accuracy: 0.4856\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 28s 351ms/step - loss: 1.5177 - accuracy: 0.4622 - val_loss: 1.5013 - val_accuracy: 0.4790\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.5101 - accuracy: 0.4658 - val_loss: 1.4439 - val_accuracy: 0.4904\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.5069 - accuracy: 0.4634 - val_loss: 1.4455 - val_accuracy: 0.4885\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5010 - accuracy: 0.4679 - val_loss: 1.5323 - val_accuracy: 0.4625\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 28s 351ms/step - loss: 1.4977 - accuracy: 0.4712 - val_loss: 1.4932 - val_accuracy: 0.4649\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4896 - accuracy: 0.4753 - val_loss: 1.4620 - val_accuracy: 0.4831\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.5029 - accuracy: 0.4650 - val_loss: 1.4392 - val_accuracy: 0.4928\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.4946 - accuracy: 0.4682 - val_loss: 1.5641 - val_accuracy: 0.4600\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 28s 351ms/step - loss: 1.4878 - accuracy: 0.4703 - val_loss: 1.4647 - val_accuracy: 0.4903\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4804 - accuracy: 0.4766 - val_loss: 1.4610 - val_accuracy: 0.4904\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 28s 350ms/step - loss: 1.4824 - accuracy: 0.4736 - val_loss: 1.4612 - val_accuracy: 0.4880\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4779 - accuracy: 0.4757 - val_loss: 1.4582 - val_accuracy: 0.4884\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 28s 350ms/step - loss: 1.4827 - accuracy: 0.4749 - val_loss: 1.4343 - val_accuracy: 0.4935\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4744 - accuracy: 0.4758 - val_loss: 1.4557 - val_accuracy: 0.4915\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.4686 - accuracy: 0.4812 - val_loss: 1.4058 - val_accuracy: 0.5073\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.4635 - accuracy: 0.4849 - val_loss: 1.4342 - val_accuracy: 0.4987\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4551 - accuracy: 0.4843 - val_loss: 1.4308 - val_accuracy: 0.4998\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4651 - accuracy: 0.4787 - val_loss: 1.4492 - val_accuracy: 0.4940\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 28s 351ms/step - loss: 1.4502 - accuracy: 0.4852 - val_loss: 1.4798 - val_accuracy: 0.4785\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.4663 - accuracy: 0.4802 - val_loss: 1.4392 - val_accuracy: 0.4991\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.4461 - accuracy: 0.4879 - val_loss: 1.4574 - val_accuracy: 0.4878\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.4510 - accuracy: 0.4891 - val_loss: 1.4375 - val_accuracy: 0.4980\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4464 - accuracy: 0.4855 - val_loss: 1.4369 - val_accuracy: 0.4951\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.4296 - accuracy: 0.4947 - val_loss: 1.4017 - val_accuracy: 0.5099\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.4365 - accuracy: 0.4920 - val_loss: 1.4644 - val_accuracy: 0.5012\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4422 - accuracy: 0.4886 - val_loss: 1.4113 - val_accuracy: 0.5052\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4364 - accuracy: 0.4893 - val_loss: 1.4279 - val_accuracy: 0.5054\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.4351 - accuracy: 0.4925 - val_loss: 1.4102 - val_accuracy: 0.5098\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.4274 - accuracy: 0.4960 - val_loss: 1.4091 - val_accuracy: 0.5090\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.4412 - accuracy: 0.4931 - val_loss: 1.4125 - val_accuracy: 0.5060\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 28s 356ms/step - loss: 1.4253 - accuracy: 0.4958 - val_loss: 1.3857 - val_accuracy: 0.5141\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4224 - accuracy: 0.4973 - val_loss: 1.3781 - val_accuracy: 0.5168\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4115 - accuracy: 0.5014 - val_loss: 1.5026 - val_accuracy: 0.4805\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 28s 357ms/step - loss: 1.4211 - accuracy: 0.4957 - val_loss: 1.4462 - val_accuracy: 0.4901\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 28s 351ms/step - loss: 1.4158 - accuracy: 0.4955 - val_loss: 1.3964 - val_accuracy: 0.5117\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.4122 - accuracy: 0.4994 - val_loss: 1.3681 - val_accuracy: 0.5251\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4080 - accuracy: 0.5017 - val_loss: 1.3963 - val_accuracy: 0.5138\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.4063 - accuracy: 0.5032 - val_loss: 1.3295 - val_accuracy: 0.5352\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.4123 - accuracy: 0.4996 - val_loss: 1.3733 - val_accuracy: 0.5223\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.4058 - accuracy: 0.5048 - val_loss: 1.3701 - val_accuracy: 0.5221\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 28s 354ms/step - loss: 1.4025 - accuracy: 0.5046 - val_loss: 1.3513 - val_accuracy: 0.5247\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 28s 358ms/step - loss: 1.4050 - accuracy: 0.5022 - val_loss: 1.3986 - val_accuracy: 0.5116\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 28s 351ms/step - loss: 1.3971 - accuracy: 0.5081 - val_loss: 1.4117 - val_accuracy: 0.5084\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 28s 352ms/step - loss: 1.3992 - accuracy: 0.5061 - val_loss: 1.3950 - val_accuracy: 0.5197\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.2805 - accuracy: 0.5446\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3295 - accuracy: 0.5352\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3111 - accuracy: 0.5363\n",
      "Train accuracy: 0.5445500016212463\n",
      "Validation accuracy: 0.5351999998092651\n",
      "Test accuracy: 0.536300003528595\n",
      "big_grid_model_32\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 11)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 11)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        1600      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 531,946\n",
      "Trainable params: 531,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (40000, 32, 32, 11) (11 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n",
      "C:\\Users\\admin\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (10000, 32, 32, 11) (11 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 10.2082 - accuracy: 0.1275 - val_loss: 2.3070 - val_accuracy: 0.1185\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 2.2211 - accuracy: 0.1706 - val_loss: 2.2805 - val_accuracy: 0.1571\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 2.1733 - accuracy: 0.1953 - val_loss: 2.1886 - val_accuracy: 0.1902\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 2.1521 - accuracy: 0.2039 - val_loss: 2.2129 - val_accuracy: 0.1804\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 2.1293 - accuracy: 0.2142 - val_loss: 2.1750 - val_accuracy: 0.1941\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 2.1250 - accuracy: 0.2188 - val_loss: 2.1590 - val_accuracy: 0.2015\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 2.1013 - accuracy: 0.2280 - val_loss: 2.1374 - val_accuracy: 0.2187\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 2.0833 - accuracy: 0.2353 - val_loss: 2.1533 - val_accuracy: 0.2183\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 2.0766 - accuracy: 0.2412 - val_loss: 2.1153 - val_accuracy: 0.2279\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 2.0625 - accuracy: 0.2474 - val_loss: 2.1304 - val_accuracy: 0.2138\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 2.0560 - accuracy: 0.2513 - val_loss: 2.1219 - val_accuracy: 0.2269\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 2.0505 - accuracy: 0.2519 - val_loss: 2.0718 - val_accuracy: 0.2384\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 2.0439 - accuracy: 0.2528 - val_loss: 2.0663 - val_accuracy: 0.2418\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 2.0334 - accuracy: 0.2601 - val_loss: 2.0239 - val_accuracy: 0.2656\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 2.0349 - accuracy: 0.2592 - val_loss: 2.0334 - val_accuracy: 0.2619\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 2.0335 - accuracy: 0.2597 - val_loss: 2.0424 - val_accuracy: 0.2550\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 2.0182 - accuracy: 0.2657 - val_loss: 2.0087 - val_accuracy: 0.2736\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 2.0140 - accuracy: 0.2696 - val_loss: 2.0914 - val_accuracy: 0.2450\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 2.0022 - accuracy: 0.2743 - val_loss: 2.0768 - val_accuracy: 0.2522\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 2.0018 - accuracy: 0.2756 - val_loss: 2.0027 - val_accuracy: 0.2725\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 2.0125 - accuracy: 0.2741 - val_loss: 2.0182 - val_accuracy: 0.2683\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.9919 - accuracy: 0.2776 - val_loss: 1.9861 - val_accuracy: 0.2808\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9872 - accuracy: 0.2808 - val_loss: 1.9794 - val_accuracy: 0.2790\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9838 - accuracy: 0.2795 - val_loss: 1.9607 - val_accuracy: 0.2925\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.9756 - accuracy: 0.2825 - val_loss: 1.9883 - val_accuracy: 0.2825\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.9754 - accuracy: 0.2866 - val_loss: 1.9682 - val_accuracy: 0.2868\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.9653 - accuracy: 0.2897 - val_loss: 1.9665 - val_accuracy: 0.2926\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9667 - accuracy: 0.2900 - val_loss: 1.9845 - val_accuracy: 0.2782\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.9573 - accuracy: 0.2906 - val_loss: 2.0001 - val_accuracy: 0.2819\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.9598 - accuracy: 0.2911 - val_loss: 1.9419 - val_accuracy: 0.3012\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9645 - accuracy: 0.2898 - val_loss: 1.9553 - val_accuracy: 0.2952\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9459 - accuracy: 0.2970 - val_loss: 1.9699 - val_accuracy: 0.2917\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.9415 - accuracy: 0.3014 - val_loss: 1.9626 - val_accuracy: 0.2963\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.9470 - accuracy: 0.2975 - val_loss: 1.9534 - val_accuracy: 0.2935\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.9393 - accuracy: 0.3002 - val_loss: 1.9578 - val_accuracy: 0.2969\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9310 - accuracy: 0.3020 - val_loss: 1.9316 - val_accuracy: 0.3104\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.9282 - accuracy: 0.3011 - val_loss: 1.9303 - val_accuracy: 0.3085\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9264 - accuracy: 0.3062 - val_loss: 1.9528 - val_accuracy: 0.3009\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.9206 - accuracy: 0.3043 - val_loss: 1.9014 - val_accuracy: 0.3179\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.9166 - accuracy: 0.3135 - val_loss: 1.9553 - val_accuracy: 0.2999\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.9127 - accuracy: 0.3136 - val_loss: 1.9805 - val_accuracy: 0.2947\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.9056 - accuracy: 0.3130 - val_loss: 1.9284 - val_accuracy: 0.3100\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8962 - accuracy: 0.3204 - val_loss: 1.9019 - val_accuracy: 0.3206\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.8973 - accuracy: 0.3198 - val_loss: 1.9639 - val_accuracy: 0.2981\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8869 - accuracy: 0.3226 - val_loss: 1.9286 - val_accuracy: 0.3157\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8863 - accuracy: 0.3230 - val_loss: 1.9243 - val_accuracy: 0.3121\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.8930 - accuracy: 0.3200 - val_loss: 1.8849 - val_accuracy: 0.3298\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8831 - accuracy: 0.3234 - val_loss: 1.9073 - val_accuracy: 0.3195\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.8735 - accuracy: 0.3286 - val_loss: 1.8721 - val_accuracy: 0.3362\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.8799 - accuracy: 0.3258 - val_loss: 1.9674 - val_accuracy: 0.3013\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.8669 - accuracy: 0.3307 - val_loss: 1.9146 - val_accuracy: 0.3211\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.8674 - accuracy: 0.3304 - val_loss: 1.8961 - val_accuracy: 0.3258\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8596 - accuracy: 0.3305 - val_loss: 1.8740 - val_accuracy: 0.3333\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8531 - accuracy: 0.3376 - val_loss: 1.8709 - val_accuracy: 0.3353\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.8585 - accuracy: 0.3338 - val_loss: 1.8592 - val_accuracy: 0.3352\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8542 - accuracy: 0.3351 - val_loss: 1.8819 - val_accuracy: 0.3312\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.8374 - accuracy: 0.3436 - val_loss: 1.8808 - val_accuracy: 0.3329\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8337 - accuracy: 0.3445 - val_loss: 1.8811 - val_accuracy: 0.3349\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.8323 - accuracy: 0.3445 - val_loss: 1.8713 - val_accuracy: 0.3295\n",
      "Epoch 00059: early stopping\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.8650 - accuracy: 0.3371\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.8721 - accuracy: 0.3362\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.8637 - accuracy: 0.3410\n",
      "Train accuracy: 0.33709999918937683\n",
      "Validation accuracy: 0.3361999988555908\n",
      "Test accuracy: 0.3409999907016754\n",
      "big_grid_model_33\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 11)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 11)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        1600      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,057,642\n",
      "Trainable params: 1,057,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 10.5562 - accuracy: 0.1452 - val_loss: 2.2373 - val_accuracy: 0.1630\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 2.1815 - accuracy: 0.1894 - val_loss: 2.1591 - val_accuracy: 0.2034\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 2.1397 - accuracy: 0.2094 - val_loss: 2.2162 - val_accuracy: 0.2127\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 2.1143 - accuracy: 0.2217 - val_loss: 2.1439 - val_accuracy: 0.2160\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 2.0998 - accuracy: 0.2307 - val_loss: 2.0947 - val_accuracy: 0.2362\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 2.0877 - accuracy: 0.2362 - val_loss: 2.0727 - val_accuracy: 0.2448\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 2.0796 - accuracy: 0.2408 - val_loss: 2.0626 - val_accuracy: 0.2512\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 2.0510 - accuracy: 0.2517 - val_loss: 2.0577 - val_accuracy: 0.2534\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 34s 434ms/step - loss: 2.0432 - accuracy: 0.2546 - val_loss: 2.0373 - val_accuracy: 0.2583\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 2.0408 - accuracy: 0.2601 - val_loss: 2.0100 - val_accuracy: 0.2708\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 2.0264 - accuracy: 0.2619 - val_loss: 2.0138 - val_accuracy: 0.2631\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 2.0160 - accuracy: 0.2679 - val_loss: 2.0531 - val_accuracy: 0.2558\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 2.0100 - accuracy: 0.2689 - val_loss: 2.0248 - val_accuracy: 0.2726\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 2.0068 - accuracy: 0.2701 - val_loss: 2.0034 - val_accuracy: 0.2795\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9974 - accuracy: 0.2769 - val_loss: 2.0510 - val_accuracy: 0.2664\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9943 - accuracy: 0.2761 - val_loss: 2.0625 - val_accuracy: 0.2543\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9856 - accuracy: 0.2804 - val_loss: 1.9944 - val_accuracy: 0.2819\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9837 - accuracy: 0.2772 - val_loss: 1.9720 - val_accuracy: 0.2881\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.9765 - accuracy: 0.2848 - val_loss: 2.0381 - val_accuracy: 0.2693\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 34s 433ms/step - loss: 1.9711 - accuracy: 0.2879 - val_loss: 1.9934 - val_accuracy: 0.2810\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.9598 - accuracy: 0.2903 - val_loss: 1.9690 - val_accuracy: 0.2870\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.9675 - accuracy: 0.2864 - val_loss: 2.0273 - val_accuracy: 0.2579\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.9529 - accuracy: 0.2937 - val_loss: 1.9976 - val_accuracy: 0.2805\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.9433 - accuracy: 0.2997 - val_loss: 1.9632 - val_accuracy: 0.2917\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9438 - accuracy: 0.2981 - val_loss: 1.9558 - val_accuracy: 0.2972\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.9465 - accuracy: 0.2989 - val_loss: 1.9588 - val_accuracy: 0.2994\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.9326 - accuracy: 0.3029 - val_loss: 1.9871 - val_accuracy: 0.2884\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.9329 - accuracy: 0.2986 - val_loss: 1.9742 - val_accuracy: 0.2888\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.9295 - accuracy: 0.3045 - val_loss: 1.9672 - val_accuracy: 0.2945\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 1.9212 - accuracy: 0.3054 - val_loss: 1.9833 - val_accuracy: 0.2931\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.9231 - accuracy: 0.3098 - val_loss: 1.9613 - val_accuracy: 0.2844\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.9043 - accuracy: 0.3154 - val_loss: 1.9480 - val_accuracy: 0.3098\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.9007 - accuracy: 0.3191 - val_loss: 1.9717 - val_accuracy: 0.2962\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8937 - accuracy: 0.3167 - val_loss: 2.0187 - val_accuracy: 0.2803\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.8950 - accuracy: 0.3162 - val_loss: 1.9496 - val_accuracy: 0.2986\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.8932 - accuracy: 0.3212 - val_loss: 1.9994 - val_accuracy: 0.2832\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8880 - accuracy: 0.3198 - val_loss: 1.9924 - val_accuracy: 0.2800\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8846 - accuracy: 0.3234 - val_loss: 1.9624 - val_accuracy: 0.3019\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8687 - accuracy: 0.3275 - val_loss: 1.8908 - val_accuracy: 0.3194\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.8733 - accuracy: 0.3272 - val_loss: 1.9535 - val_accuracy: 0.2988\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8663 - accuracy: 0.3277 - val_loss: 1.8717 - val_accuracy: 0.3276\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.8634 - accuracy: 0.3316 - val_loss: 1.9164 - val_accuracy: 0.3091\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.8568 - accuracy: 0.3339 - val_loss: 1.9691 - val_accuracy: 0.2963\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8598 - accuracy: 0.3318 - val_loss: 1.9327 - val_accuracy: 0.3132\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.8556 - accuracy: 0.3329 - val_loss: 1.9155 - val_accuracy: 0.3135\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8518 - accuracy: 0.3383 - val_loss: 1.9853 - val_accuracy: 0.2884\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.8389 - accuracy: 0.3395 - val_loss: 1.9084 - val_accuracy: 0.3245\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8320 - accuracy: 0.3420 - val_loss: 1.8760 - val_accuracy: 0.3347\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8302 - accuracy: 0.3426 - val_loss: 1.8905 - val_accuracy: 0.3223\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8299 - accuracy: 0.3410 - val_loss: 1.9306 - val_accuracy: 0.3118\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8254 - accuracy: 0.3457 - val_loss: 1.9646 - val_accuracy: 0.3036\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.8165 - accuracy: 0.3511 - val_loss: 1.9024 - val_accuracy: 0.3218\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.8102 - accuracy: 0.3535 - val_loss: 1.8746 - val_accuracy: 0.3265\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.8057 - accuracy: 0.3520 - val_loss: 1.8138 - val_accuracy: 0.3538\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.8090 - accuracy: 0.3517 - val_loss: 1.8409 - val_accuracy: 0.3409\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.8144 - accuracy: 0.3489 - val_loss: 1.8550 - val_accuracy: 0.3350\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.8018 - accuracy: 0.3540 - val_loss: 1.8358 - val_accuracy: 0.3454\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7897 - accuracy: 0.3597 - val_loss: 1.8584 - val_accuracy: 0.3350\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.7929 - accuracy: 0.3572 - val_loss: 1.8402 - val_accuracy: 0.3404\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.7843 - accuracy: 0.3617 - val_loss: 1.7911 - val_accuracy: 0.3566\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.7869 - accuracy: 0.3629 - val_loss: 1.8313 - val_accuracy: 0.3437\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.7799 - accuracy: 0.3631 - val_loss: 1.8410 - val_accuracy: 0.3385\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.7699 - accuracy: 0.3641 - val_loss: 1.8072 - val_accuracy: 0.3575\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7626 - accuracy: 0.3720 - val_loss: 1.8465 - val_accuracy: 0.3446\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7732 - accuracy: 0.3659 - val_loss: 1.7555 - val_accuracy: 0.3750\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7702 - accuracy: 0.3666 - val_loss: 1.8108 - val_accuracy: 0.3583\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7531 - accuracy: 0.3755 - val_loss: 1.7848 - val_accuracy: 0.3625\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.7574 - accuracy: 0.3715 - val_loss: 1.8682 - val_accuracy: 0.3340\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.7428 - accuracy: 0.3796 - val_loss: 1.7817 - val_accuracy: 0.3637\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.7436 - accuracy: 0.3767 - val_loss: 1.8883 - val_accuracy: 0.3305\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7357 - accuracy: 0.3781 - val_loss: 1.7788 - val_accuracy: 0.3664\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.7256 - accuracy: 0.3829 - val_loss: 1.7415 - val_accuracy: 0.3752\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.7313 - accuracy: 0.3810 - val_loss: 1.7906 - val_accuracy: 0.3599\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.7250 - accuracy: 0.3826 - val_loss: 1.8126 - val_accuracy: 0.3490\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.7164 - accuracy: 0.3868 - val_loss: 1.7095 - val_accuracy: 0.3816\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.7120 - accuracy: 0.3896 - val_loss: 1.7471 - val_accuracy: 0.3711\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.7155 - accuracy: 0.3893 - val_loss: 1.8208 - val_accuracy: 0.3564\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.6980 - accuracy: 0.3920 - val_loss: 1.7252 - val_accuracy: 0.3851\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7010 - accuracy: 0.3952 - val_loss: 1.7443 - val_accuracy: 0.3806\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.6990 - accuracy: 0.3956 - val_loss: 1.7793 - val_accuracy: 0.3623\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7087 - accuracy: 0.3906 - val_loss: 1.7486 - val_accuracy: 0.3800\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.6921 - accuracy: 0.3990 - val_loss: 1.7381 - val_accuracy: 0.3815\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.7122 - accuracy: 0.3872 - val_loss: 1.6842 - val_accuracy: 0.3952\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.6820 - accuracy: 0.4023 - val_loss: 1.6856 - val_accuracy: 0.4003\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.6749 - accuracy: 0.4015 - val_loss: 1.7630 - val_accuracy: 0.3745\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.6786 - accuracy: 0.4017 - val_loss: 1.7085 - val_accuracy: 0.3939\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.6794 - accuracy: 0.4050 - val_loss: 1.6470 - val_accuracy: 0.4075\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.6665 - accuracy: 0.4043 - val_loss: 1.6722 - val_accuracy: 0.4064\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6682 - accuracy: 0.4035 - val_loss: 1.6558 - val_accuracy: 0.4099\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6625 - accuracy: 0.4079 - val_loss: 1.6729 - val_accuracy: 0.4070\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 1.6668 - accuracy: 0.4046 - val_loss: 1.6559 - val_accuracy: 0.4113\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.6524 - accuracy: 0.4092 - val_loss: 1.6325 - val_accuracy: 0.4168\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6557 - accuracy: 0.4076 - val_loss: 1.6692 - val_accuracy: 0.4031\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.6460 - accuracy: 0.4118 - val_loss: 1.6228 - val_accuracy: 0.4194\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.6430 - accuracy: 0.4125 - val_loss: 1.6015 - val_accuracy: 0.4237\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.6445 - accuracy: 0.4134 - val_loss: 1.6496 - val_accuracy: 0.4100\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.6460 - accuracy: 0.4104 - val_loss: 1.6967 - val_accuracy: 0.3940\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.6406 - accuracy: 0.4133 - val_loss: 1.6214 - val_accuracy: 0.4273\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 1.6303 - accuracy: 0.4179 - val_loss: 1.6263 - val_accuracy: 0.4189\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.6273 - accuracy: 0.4162 - val_loss: 1.6370 - val_accuracy: 0.4195\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.5994 - accuracy: 0.4326\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6214 - accuracy: 0.4273\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6122 - accuracy: 0.4304\n",
      "Train accuracy: 0.4326249957084656\n",
      "Validation accuracy: 0.42730000615119934\n",
      "Test accuracy: 0.430400013923645\n",
      "big_grid_model_34\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 11)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 11)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        3200      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,071,690\n",
      "Trainable params: 1,071,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 34s 432ms/step - loss: 10.3484 - accuracy: 0.1242 - val_loss: 2.2533 - val_accuracy: 0.1566\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 2.2050 - accuracy: 0.1710 - val_loss: 2.1965 - val_accuracy: 0.1858\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 2.1606 - accuracy: 0.1955 - val_loss: 2.1726 - val_accuracy: 0.2037\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 2.1293 - accuracy: 0.2133 - val_loss: 2.1532 - val_accuracy: 0.2007\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 2.1133 - accuracy: 0.2190 - val_loss: 2.1837 - val_accuracy: 0.2010\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 2.1022 - accuracy: 0.2272 - val_loss: 2.1725 - val_accuracy: 0.2190\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 2.0789 - accuracy: 0.2376 - val_loss: 2.2375 - val_accuracy: 0.2016\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 2.0634 - accuracy: 0.2457 - val_loss: 2.0915 - val_accuracy: 0.2452\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 2.0555 - accuracy: 0.2473 - val_loss: 2.2034 - val_accuracy: 0.2055\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 2.0546 - accuracy: 0.2471 - val_loss: 2.0525 - val_accuracy: 0.2661\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 2.0302 - accuracy: 0.2608 - val_loss: 2.0470 - val_accuracy: 0.2524\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 2.0148 - accuracy: 0.2650 - val_loss: 2.0404 - val_accuracy: 0.2614\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 2.0052 - accuracy: 0.2704 - val_loss: 2.0484 - val_accuracy: 0.2619\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9907 - accuracy: 0.2777 - val_loss: 2.0556 - val_accuracy: 0.2602\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.9823 - accuracy: 0.2793 - val_loss: 1.9713 - val_accuracy: 0.2896\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.9750 - accuracy: 0.2822 - val_loss: 2.0462 - val_accuracy: 0.2714\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.9603 - accuracy: 0.2929 - val_loss: 1.9945 - val_accuracy: 0.2878\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.9420 - accuracy: 0.2997 - val_loss: 1.9964 - val_accuracy: 0.2841\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9350 - accuracy: 0.3023 - val_loss: 1.9167 - val_accuracy: 0.3142\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.9188 - accuracy: 0.3115 - val_loss: 1.9558 - val_accuracy: 0.2964\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.9131 - accuracy: 0.3112 - val_loss: 1.9358 - val_accuracy: 0.3057\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9024 - accuracy: 0.3138 - val_loss: 1.9741 - val_accuracy: 0.3017\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8895 - accuracy: 0.3198 - val_loss: 1.9313 - val_accuracy: 0.3067\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 34s 436ms/step - loss: 1.8888 - accuracy: 0.3218 - val_loss: 1.9400 - val_accuracy: 0.3052\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.8714 - accuracy: 0.3292 - val_loss: 1.9322 - val_accuracy: 0.3115\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8640 - accuracy: 0.3333 - val_loss: 1.8846 - val_accuracy: 0.3260\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.8567 - accuracy: 0.3347 - val_loss: 1.8405 - val_accuracy: 0.3398\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.8396 - accuracy: 0.3395 - val_loss: 1.8691 - val_accuracy: 0.3297\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.8315 - accuracy: 0.3443 - val_loss: 1.8355 - val_accuracy: 0.3497\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8274 - accuracy: 0.3439 - val_loss: 1.8247 - val_accuracy: 0.3486\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.8281 - accuracy: 0.3460 - val_loss: 1.8600 - val_accuracy: 0.3408\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.8209 - accuracy: 0.3473 - val_loss: 1.8038 - val_accuracy: 0.3552\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.8119 - accuracy: 0.3507 - val_loss: 1.8029 - val_accuracy: 0.3565\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.7934 - accuracy: 0.3578 - val_loss: 1.8340 - val_accuracy: 0.3432\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7902 - accuracy: 0.3608 - val_loss: 1.8084 - val_accuracy: 0.3655\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7781 - accuracy: 0.3672 - val_loss: 1.7694 - val_accuracy: 0.3805\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 1.7771 - accuracy: 0.3686 - val_loss: 1.7517 - val_accuracy: 0.3774\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7770 - accuracy: 0.3649 - val_loss: 1.8611 - val_accuracy: 0.3348\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.7592 - accuracy: 0.3713 - val_loss: 1.9164 - val_accuracy: 0.3245\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.7558 - accuracy: 0.3713 - val_loss: 1.8542 - val_accuracy: 0.3437\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.7513 - accuracy: 0.3742 - val_loss: 1.7622 - val_accuracy: 0.3780\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.7301 - accuracy: 0.3853 - val_loss: 1.7177 - val_accuracy: 0.3924\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7297 - accuracy: 0.3859 - val_loss: 1.7706 - val_accuracy: 0.3686\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.7358 - accuracy: 0.3827 - val_loss: 1.6857 - val_accuracy: 0.4085\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7132 - accuracy: 0.3888 - val_loss: 1.7046 - val_accuracy: 0.3976\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.7168 - accuracy: 0.3893 - val_loss: 1.6901 - val_accuracy: 0.4002\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.7140 - accuracy: 0.3898 - val_loss: 1.7757 - val_accuracy: 0.3644\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.6984 - accuracy: 0.3959 - val_loss: 1.7548 - val_accuracy: 0.3771\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.6941 - accuracy: 0.3997 - val_loss: 1.6557 - val_accuracy: 0.4093\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.6780 - accuracy: 0.4027 - val_loss: 1.6719 - val_accuracy: 0.4105\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.6757 - accuracy: 0.4051 - val_loss: 1.6750 - val_accuracy: 0.4082\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 1.6633 - accuracy: 0.4096 - val_loss: 1.7484 - val_accuracy: 0.3779\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 1.6591 - accuracy: 0.4099 - val_loss: 1.6463 - val_accuracy: 0.4191\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.6489 - accuracy: 0.4105 - val_loss: 1.6073 - val_accuracy: 0.4237\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.6415 - accuracy: 0.4146 - val_loss: 1.6144 - val_accuracy: 0.4353\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.6488 - accuracy: 0.4142 - val_loss: 1.6000 - val_accuracy: 0.4340\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.6424 - accuracy: 0.4160 - val_loss: 1.5727 - val_accuracy: 0.4476\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.6234 - accuracy: 0.4216 - val_loss: 1.6602 - val_accuracy: 0.4124\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 1.6187 - accuracy: 0.4228 - val_loss: 1.6545 - val_accuracy: 0.4148\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.6164 - accuracy: 0.4246 - val_loss: 1.5793 - val_accuracy: 0.4407\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.6073 - accuracy: 0.4302 - val_loss: 1.5812 - val_accuracy: 0.4437\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.5989 - accuracy: 0.4311 - val_loss: 1.7102 - val_accuracy: 0.3932\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.6104 - accuracy: 0.4270 - val_loss: 1.5595 - val_accuracy: 0.4502\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.5865 - accuracy: 0.4345 - val_loss: 1.6149 - val_accuracy: 0.4319\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.5965 - accuracy: 0.4313 - val_loss: 1.5943 - val_accuracy: 0.4361\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.5987 - accuracy: 0.4302 - val_loss: 1.6874 - val_accuracy: 0.4068\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.5876 - accuracy: 0.4349 - val_loss: 1.5455 - val_accuracy: 0.4570\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.5840 - accuracy: 0.4374 - val_loss: 1.5722 - val_accuracy: 0.4451\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.5677 - accuracy: 0.4460 - val_loss: 1.5700 - val_accuracy: 0.4534\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.5781 - accuracy: 0.4388 - val_loss: 1.6564 - val_accuracy: 0.4299\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.5716 - accuracy: 0.4414 - val_loss: 1.5613 - val_accuracy: 0.4517\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.5668 - accuracy: 0.4437 - val_loss: 1.5424 - val_accuracy: 0.4645\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.5733 - accuracy: 0.4403 - val_loss: 1.6184 - val_accuracy: 0.4368\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.5559 - accuracy: 0.4490 - val_loss: 1.5513 - val_accuracy: 0.4512\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.5565 - accuracy: 0.4471 - val_loss: 1.5240 - val_accuracy: 0.4672\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.5557 - accuracy: 0.4486 - val_loss: 1.5983 - val_accuracy: 0.4407\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 1.5516 - accuracy: 0.4458 - val_loss: 1.5718 - val_accuracy: 0.4531\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.5386 - accuracy: 0.4530 - val_loss: 1.6065 - val_accuracy: 0.4519\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.5395 - accuracy: 0.4526 - val_loss: 1.6221 - val_accuracy: 0.4328\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.5378 - accuracy: 0.4554 - val_loss: 1.4935 - val_accuracy: 0.4819\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.5208 - accuracy: 0.4613 - val_loss: 1.5242 - val_accuracy: 0.4683\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.5370 - accuracy: 0.4549 - val_loss: 1.5251 - val_accuracy: 0.4648\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.5403 - accuracy: 0.4502 - val_loss: 1.5447 - val_accuracy: 0.4754\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.5316 - accuracy: 0.4586 - val_loss: 1.5148 - val_accuracy: 0.4703\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.5135 - accuracy: 0.4602 - val_loss: 1.6065 - val_accuracy: 0.4528\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.5182 - accuracy: 0.4620 - val_loss: 1.5325 - val_accuracy: 0.4718\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.5123 - accuracy: 0.4641 - val_loss: 1.4516 - val_accuracy: 0.4946\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.5090 - accuracy: 0.4643 - val_loss: 1.4965 - val_accuracy: 0.4732\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.4969 - accuracy: 0.4704 - val_loss: 1.4959 - val_accuracy: 0.4758\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.5216 - accuracy: 0.4598 - val_loss: 1.4981 - val_accuracy: 0.4749\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 1.5008 - accuracy: 0.4674 - val_loss: 1.4669 - val_accuracy: 0.4919\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.5013 - accuracy: 0.4699 - val_loss: 1.4719 - val_accuracy: 0.4871\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.4953 - accuracy: 0.4699 - val_loss: 1.5578 - val_accuracy: 0.4626\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.4905 - accuracy: 0.4718 - val_loss: 1.5739 - val_accuracy: 0.4525\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.4918 - accuracy: 0.4721 - val_loss: 1.5027 - val_accuracy: 0.4714\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.4742 - accuracy: 0.4740 - val_loss: 1.5091 - val_accuracy: 0.4802\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.4871 - accuracy: 0.4738 - val_loss: 1.4843 - val_accuracy: 0.4781\n",
      "Epoch 00097: early stopping\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.4219 - accuracy: 0.4951\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4516 - accuracy: 0.4946\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4373 - accuracy: 0.4964\n",
      "Train accuracy: 0.49514999985694885\n",
      "Validation accuracy: 0.49459999799728394\n",
      "Test accuracy: 0.49639999866485596\n",
      "big_grid_model_35\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 11)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 11)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        3200      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,121,674\n",
      "Trainable params: 2,121,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 11.9613 - accuracy: 0.1217 - val_loss: 2.2867 - val_accuracy: 0.1315\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 2.2452 - accuracy: 0.1572 - val_loss: 2.2443 - val_accuracy: 0.1599\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 2.1996 - accuracy: 0.1822 - val_loss: 2.2519 - val_accuracy: 0.1667\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 2.1734 - accuracy: 0.1962 - val_loss: 2.2068 - val_accuracy: 0.1926\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 2.1580 - accuracy: 0.2061 - val_loss: 2.2198 - val_accuracy: 0.1874\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 2.1368 - accuracy: 0.2167 - val_loss: 2.2533 - val_accuracy: 0.1587\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 2.1346 - accuracy: 0.2165 - val_loss: 2.1723 - val_accuracy: 0.1967\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 2.1241 - accuracy: 0.2211 - val_loss: 2.1555 - val_accuracy: 0.2062\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 2.1069 - accuracy: 0.2280 - val_loss: 2.1625 - val_accuracy: 0.2054\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 2.0928 - accuracy: 0.2386 - val_loss: 2.1291 - val_accuracy: 0.2356\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 2.0863 - accuracy: 0.2397 - val_loss: 2.2501 - val_accuracy: 0.1895\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 2.0718 - accuracy: 0.2431 - val_loss: 2.1019 - val_accuracy: 0.2285\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 2.0606 - accuracy: 0.2490 - val_loss: 2.2553 - val_accuracy: 0.2120\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 2.0450 - accuracy: 0.2546 - val_loss: 2.0704 - val_accuracy: 0.2436\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 2.0365 - accuracy: 0.2606 - val_loss: 2.0851 - val_accuracy: 0.2430\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 2.0238 - accuracy: 0.2651 - val_loss: 2.0976 - val_accuracy: 0.2455\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9934 - accuracy: 0.2817 - val_loss: 2.0844 - val_accuracy: 0.2528\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.9787 - accuracy: 0.2883 - val_loss: 2.0843 - val_accuracy: 0.2582\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.9773 - accuracy: 0.2880 - val_loss: 2.0276 - val_accuracy: 0.2669\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.9626 - accuracy: 0.2949 - val_loss: 1.9969 - val_accuracy: 0.2886\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.9586 - accuracy: 0.2934 - val_loss: 2.0628 - val_accuracy: 0.2596\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.9437 - accuracy: 0.2993 - val_loss: 1.9926 - val_accuracy: 0.2846\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.9207 - accuracy: 0.3106 - val_loss: 1.9677 - val_accuracy: 0.2918\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.9048 - accuracy: 0.3144 - val_loss: 2.0493 - val_accuracy: 0.2673\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9052 - accuracy: 0.3173 - val_loss: 1.9448 - val_accuracy: 0.3057\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8941 - accuracy: 0.3227 - val_loss: 1.9233 - val_accuracy: 0.3099\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8888 - accuracy: 0.3227 - val_loss: 1.9396 - val_accuracy: 0.3029\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8871 - accuracy: 0.3243 - val_loss: 1.9299 - val_accuracy: 0.3086\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8637 - accuracy: 0.3304 - val_loss: 2.0392 - val_accuracy: 0.2751\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8613 - accuracy: 0.3327 - val_loss: 1.9420 - val_accuracy: 0.3006\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8555 - accuracy: 0.3340 - val_loss: 1.9815 - val_accuracy: 0.2858\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8481 - accuracy: 0.3399 - val_loss: 1.9294 - val_accuracy: 0.3099\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.8380 - accuracy: 0.3412 - val_loss: 1.9185 - val_accuracy: 0.3181\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8179 - accuracy: 0.3498 - val_loss: 1.9413 - val_accuracy: 0.3088\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.8124 - accuracy: 0.3525 - val_loss: 1.8936 - val_accuracy: 0.3229\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8085 - accuracy: 0.3544 - val_loss: 1.9098 - val_accuracy: 0.3192\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7983 - accuracy: 0.3570 - val_loss: 1.8564 - val_accuracy: 0.3392\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7901 - accuracy: 0.3573 - val_loss: 1.8055 - val_accuracy: 0.3613\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7900 - accuracy: 0.3611 - val_loss: 1.8337 - val_accuracy: 0.3487\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7707 - accuracy: 0.3677 - val_loss: 1.8645 - val_accuracy: 0.3339\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.7619 - accuracy: 0.3682 - val_loss: 1.8378 - val_accuracy: 0.3403\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.7512 - accuracy: 0.3728 - val_loss: 1.7559 - val_accuracy: 0.3745\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7464 - accuracy: 0.3763 - val_loss: 1.7766 - val_accuracy: 0.3744\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.7292 - accuracy: 0.3790 - val_loss: 1.7982 - val_accuracy: 0.3622\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7270 - accuracy: 0.3819 - val_loss: 1.7198 - val_accuracy: 0.3880\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.7145 - accuracy: 0.3855 - val_loss: 1.7614 - val_accuracy: 0.3710\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.7128 - accuracy: 0.3846 - val_loss: 1.7068 - val_accuracy: 0.3922\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.6921 - accuracy: 0.3947 - val_loss: 1.7371 - val_accuracy: 0.3840\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6859 - accuracy: 0.3965 - val_loss: 1.7208 - val_accuracy: 0.3861\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.6776 - accuracy: 0.4018 - val_loss: 1.7337 - val_accuracy: 0.3833\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.6815 - accuracy: 0.3988 - val_loss: 1.7001 - val_accuracy: 0.3928\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6594 - accuracy: 0.4097 - val_loss: 1.7037 - val_accuracy: 0.4006\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.6571 - accuracy: 0.4082 - val_loss: 1.6270 - val_accuracy: 0.4199\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6433 - accuracy: 0.4145 - val_loss: 1.6737 - val_accuracy: 0.4032\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.6552 - accuracy: 0.4113 - val_loss: 1.7158 - val_accuracy: 0.3876\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6292 - accuracy: 0.4206 - val_loss: 1.6722 - val_accuracy: 0.4029\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6363 - accuracy: 0.4160 - val_loss: 1.6265 - val_accuracy: 0.4217\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6179 - accuracy: 0.4241 - val_loss: 1.6387 - val_accuracy: 0.4192\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6159 - accuracy: 0.4240 - val_loss: 1.5864 - val_accuracy: 0.4322\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.5996 - accuracy: 0.4313 - val_loss: 1.6298 - val_accuracy: 0.4291\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6166 - accuracy: 0.4232 - val_loss: 1.5462 - val_accuracy: 0.4502\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.6013 - accuracy: 0.4295 - val_loss: 1.6895 - val_accuracy: 0.4100\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6122 - accuracy: 0.4263 - val_loss: 1.6405 - val_accuracy: 0.4165\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.5859 - accuracy: 0.4350 - val_loss: 1.7050 - val_accuracy: 0.4008\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.5868 - accuracy: 0.4338 - val_loss: 1.6734 - val_accuracy: 0.4103\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.5870 - accuracy: 0.4365 - val_loss: 1.5976 - val_accuracy: 0.4367\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 34s 432ms/step - loss: 1.5679 - accuracy: 0.4404 - val_loss: 1.6118 - val_accuracy: 0.4279\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.5620 - accuracy: 0.4450 - val_loss: 1.5531 - val_accuracy: 0.4550\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.5561 - accuracy: 0.4472 - val_loss: 1.5463 - val_accuracy: 0.4527\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.5449 - accuracy: 0.4515 - val_loss: 1.5914 - val_accuracy: 0.4367\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.5525 - accuracy: 0.4476 - val_loss: 1.5429 - val_accuracy: 0.4512\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.5421 - accuracy: 0.4523 - val_loss: 1.5371 - val_accuracy: 0.4608\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.5362 - accuracy: 0.4512 - val_loss: 1.5957 - val_accuracy: 0.4341\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.5371 - accuracy: 0.4508 - val_loss: 1.6532 - val_accuracy: 0.4322\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.5278 - accuracy: 0.4570 - val_loss: 1.5419 - val_accuracy: 0.4584\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.5321 - accuracy: 0.4551 - val_loss: 1.6242 - val_accuracy: 0.4278\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.5380 - accuracy: 0.4538 - val_loss: 1.5600 - val_accuracy: 0.4489\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.5247 - accuracy: 0.4590 - val_loss: 1.5595 - val_accuracy: 0.4523\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.5102 - accuracy: 0.4622 - val_loss: 1.5783 - val_accuracy: 0.4475\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.5150 - accuracy: 0.4592 - val_loss: 1.6498 - val_accuracy: 0.4086\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.5051 - accuracy: 0.4649 - val_loss: 1.5087 - val_accuracy: 0.4649\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.5154 - accuracy: 0.4614 - val_loss: 1.5417 - val_accuracy: 0.4616\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.5017 - accuracy: 0.4650 - val_loss: 1.5296 - val_accuracy: 0.4726\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.5056 - accuracy: 0.4644 - val_loss: 1.6311 - val_accuracy: 0.4299\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.5011 - accuracy: 0.4657 - val_loss: 1.5032 - val_accuracy: 0.4630\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.5017 - accuracy: 0.4649 - val_loss: 1.5224 - val_accuracy: 0.4650\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.4789 - accuracy: 0.4748 - val_loss: 1.5160 - val_accuracy: 0.4625\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.4906 - accuracy: 0.4687 - val_loss: 1.5445 - val_accuracy: 0.4679\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.4859 - accuracy: 0.4715 - val_loss: 1.5880 - val_accuracy: 0.4381\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.4787 - accuracy: 0.4750 - val_loss: 1.4537 - val_accuracy: 0.4892\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.4733 - accuracy: 0.4784 - val_loss: 1.5045 - val_accuracy: 0.4671\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.4759 - accuracy: 0.4765 - val_loss: 1.4282 - val_accuracy: 0.5011\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.4833 - accuracy: 0.4721 - val_loss: 1.4278 - val_accuracy: 0.4975\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.4775 - accuracy: 0.4744 - val_loss: 1.4861 - val_accuracy: 0.4778\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.4657 - accuracy: 0.4783 - val_loss: 1.4232 - val_accuracy: 0.5009\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.4622 - accuracy: 0.4782 - val_loss: 1.5194 - val_accuracy: 0.4680\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.4465 - accuracy: 0.4883 - val_loss: 1.4507 - val_accuracy: 0.4924\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.4462 - accuracy: 0.4867 - val_loss: 1.4770 - val_accuracy: 0.4907\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.4417 - accuracy: 0.4913 - val_loss: 1.4743 - val_accuracy: 0.4792\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.4566 - accuracy: 0.4814 - val_loss: 1.4793 - val_accuracy: 0.4862\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.3926 - accuracy: 0.5088\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4282 - accuracy: 0.5011\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4191 - accuracy: 0.5081\n",
      "Train accuracy: 0.508774995803833\n",
      "Validation accuracy: 0.5011000037193298\n",
      "Test accuracy: 0.5080999732017517\n",
      "big_grid_model_36\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 11)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 11)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        1600      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 531,946\n",
      "Trainable params: 531,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 8.7585 - accuracy: 0.1490 - val_loss: 2.1615 - val_accuracy: 0.1963\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 2.1460 - accuracy: 0.1992 - val_loss: 2.1116 - val_accuracy: 0.2200\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 2.1077 - accuracy: 0.2220 - val_loss: 2.0664 - val_accuracy: 0.2386\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 2.0834 - accuracy: 0.2347 - val_loss: 2.0514 - val_accuracy: 0.2546\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 2.0545 - accuracy: 0.2476 - val_loss: 2.0353 - val_accuracy: 0.2619\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 2.0505 - accuracy: 0.2498 - val_loss: 2.0224 - val_accuracy: 0.2675\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 2.0359 - accuracy: 0.2572 - val_loss: 2.0003 - val_accuracy: 0.2748\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 2.0253 - accuracy: 0.2654 - val_loss: 2.0195 - val_accuracy: 0.2609\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 2.0188 - accuracy: 0.2678 - val_loss: 2.0133 - val_accuracy: 0.2717\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 2.0064 - accuracy: 0.2726 - val_loss: 1.9963 - val_accuracy: 0.2702\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 2.0039 - accuracy: 0.2731 - val_loss: 1.9915 - val_accuracy: 0.2761\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.9931 - accuracy: 0.2767 - val_loss: 1.9996 - val_accuracy: 0.2708\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.9897 - accuracy: 0.2801 - val_loss: 1.9858 - val_accuracy: 0.2732\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.9841 - accuracy: 0.2806 - val_loss: 1.9911 - val_accuracy: 0.2757\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.9728 - accuracy: 0.2857 - val_loss: 1.9628 - val_accuracy: 0.2928\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9687 - accuracy: 0.2873 - val_loss: 1.9906 - val_accuracy: 0.2707\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9635 - accuracy: 0.2887 - val_loss: 1.9367 - val_accuracy: 0.3003\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.9508 - accuracy: 0.2968 - val_loss: 1.9259 - val_accuracy: 0.3039\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.9494 - accuracy: 0.2975 - val_loss: 1.9308 - val_accuracy: 0.3058\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.9438 - accuracy: 0.3000 - val_loss: 1.9426 - val_accuracy: 0.2954\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9396 - accuracy: 0.3010 - val_loss: 1.9237 - val_accuracy: 0.3046\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9310 - accuracy: 0.3046 - val_loss: 1.9171 - val_accuracy: 0.3106\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.9240 - accuracy: 0.3102 - val_loss: 1.9002 - val_accuracy: 0.3171\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.9184 - accuracy: 0.3122 - val_loss: 1.9302 - val_accuracy: 0.3056\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.9124 - accuracy: 0.3125 - val_loss: 1.9009 - val_accuracy: 0.3184\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.9044 - accuracy: 0.3152 - val_loss: 1.9051 - val_accuracy: 0.3070\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.8944 - accuracy: 0.3206 - val_loss: 1.8648 - val_accuracy: 0.3309\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8913 - accuracy: 0.3198 - val_loss: 1.8886 - val_accuracy: 0.3208\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8830 - accuracy: 0.3247 - val_loss: 1.8823 - val_accuracy: 0.3195\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8813 - accuracy: 0.3238 - val_loss: 1.8896 - val_accuracy: 0.3234\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.8736 - accuracy: 0.3263 - val_loss: 1.8639 - val_accuracy: 0.3230\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8735 - accuracy: 0.3280 - val_loss: 1.8712 - val_accuracy: 0.3224\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8682 - accuracy: 0.3307 - val_loss: 1.8523 - val_accuracy: 0.3321\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.8525 - accuracy: 0.3345 - val_loss: 1.9114 - val_accuracy: 0.3067\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8447 - accuracy: 0.3394 - val_loss: 1.8620 - val_accuracy: 0.3353\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.8426 - accuracy: 0.3386 - val_loss: 1.8659 - val_accuracy: 0.3376\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.8398 - accuracy: 0.3395 - val_loss: 1.8636 - val_accuracy: 0.3264\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8402 - accuracy: 0.3377 - val_loss: 1.8523 - val_accuracy: 0.3389\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8294 - accuracy: 0.3449 - val_loss: 1.8549 - val_accuracy: 0.3358\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8259 - accuracy: 0.3421 - val_loss: 1.8431 - val_accuracy: 0.3300\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.8128 - accuracy: 0.3506 - val_loss: 1.8472 - val_accuracy: 0.3340\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.8172 - accuracy: 0.3466 - val_loss: 1.8280 - val_accuracy: 0.3459\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.8092 - accuracy: 0.3503 - val_loss: 1.8215 - val_accuracy: 0.3417\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.8055 - accuracy: 0.3513 - val_loss: 1.8402 - val_accuracy: 0.3320\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7972 - accuracy: 0.3568 - val_loss: 1.7970 - val_accuracy: 0.3572\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7989 - accuracy: 0.3511 - val_loss: 1.8718 - val_accuracy: 0.3313\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7863 - accuracy: 0.3568 - val_loss: 1.8090 - val_accuracy: 0.3498\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7942 - accuracy: 0.3536 - val_loss: 1.7929 - val_accuracy: 0.3582\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.7787 - accuracy: 0.3616 - val_loss: 1.7780 - val_accuracy: 0.3603\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.7770 - accuracy: 0.3632 - val_loss: 1.8482 - val_accuracy: 0.3381\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7850 - accuracy: 0.3564 - val_loss: 1.7740 - val_accuracy: 0.3650\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.7724 - accuracy: 0.3656 - val_loss: 1.7582 - val_accuracy: 0.3702\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7686 - accuracy: 0.3643 - val_loss: 1.7482 - val_accuracy: 0.3683\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7644 - accuracy: 0.3641 - val_loss: 1.7442 - val_accuracy: 0.3760\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.7494 - accuracy: 0.3723 - val_loss: 1.7665 - val_accuracy: 0.3735\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7578 - accuracy: 0.3648 - val_loss: 1.7539 - val_accuracy: 0.3763\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7609 - accuracy: 0.3628 - val_loss: 1.7665 - val_accuracy: 0.3705\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7475 - accuracy: 0.3697 - val_loss: 1.7387 - val_accuracy: 0.3736\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.7464 - accuracy: 0.3734 - val_loss: 1.7538 - val_accuracy: 0.3723\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7299 - accuracy: 0.3806 - val_loss: 1.7316 - val_accuracy: 0.3816\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7310 - accuracy: 0.3782 - val_loss: 1.7031 - val_accuracy: 0.3917\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7274 - accuracy: 0.3805 - val_loss: 1.7080 - val_accuracy: 0.3898\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7279 - accuracy: 0.3809 - val_loss: 1.9164 - val_accuracy: 0.3189\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.7294 - accuracy: 0.3778 - val_loss: 1.6703 - val_accuracy: 0.4003\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7167 - accuracy: 0.3838 - val_loss: 1.7084 - val_accuracy: 0.3944\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7147 - accuracy: 0.3835 - val_loss: 1.7254 - val_accuracy: 0.3864\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6984 - accuracy: 0.3894 - val_loss: 1.6984 - val_accuracy: 0.3988\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7079 - accuracy: 0.3884 - val_loss: 1.7075 - val_accuracy: 0.3917\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.6938 - accuracy: 0.3939 - val_loss: 1.7337 - val_accuracy: 0.3832\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 1.6978 - accuracy: 0.3908 - val_loss: 1.6869 - val_accuracy: 0.3979\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.6975 - accuracy: 0.3929 - val_loss: 1.6819 - val_accuracy: 0.4036\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6825 - accuracy: 0.3940 - val_loss: 1.6853 - val_accuracy: 0.4043\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.6846 - accuracy: 0.3947 - val_loss: 1.6792 - val_accuracy: 0.4001\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6961 - accuracy: 0.3950 - val_loss: 1.6481 - val_accuracy: 0.4076\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6812 - accuracy: 0.3999 - val_loss: 1.6779 - val_accuracy: 0.4031\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 34s 433ms/step - loss: 1.6792 - accuracy: 0.3961 - val_loss: 1.6416 - val_accuracy: 0.4129\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6716 - accuracy: 0.4017 - val_loss: 1.7143 - val_accuracy: 0.3930\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.6673 - accuracy: 0.4022 - val_loss: 1.6496 - val_accuracy: 0.4127\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 1.6598 - accuracy: 0.4050 - val_loss: 1.7122 - val_accuracy: 0.3923\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6581 - accuracy: 0.4085 - val_loss: 1.6133 - val_accuracy: 0.4200\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 36s 452ms/step - loss: 1.6513 - accuracy: 0.4121 - val_loss: 1.6461 - val_accuracy: 0.4144\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 35s 445ms/step - loss: 1.6601 - accuracy: 0.4080 - val_loss: 1.6196 - val_accuracy: 0.4217\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1.6564 - accuracy: 0.4060 - val_loss: 1.6278 - val_accuracy: 0.4231\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.6468 - accuracy: 0.4126 - val_loss: 1.6430 - val_accuracy: 0.4180\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 35s 445ms/step - loss: 1.6377 - accuracy: 0.4153 - val_loss: 1.5904 - val_accuracy: 0.4389\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.6392 - accuracy: 0.4143 - val_loss: 1.6070 - val_accuracy: 0.4272\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 35s 444ms/step - loss: 1.6333 - accuracy: 0.4171 - val_loss: 1.6574 - val_accuracy: 0.4145\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 36s 451ms/step - loss: 1.6319 - accuracy: 0.4157 - val_loss: 1.5839 - val_accuracy: 0.4372\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1.6348 - accuracy: 0.4175 - val_loss: 1.5939 - val_accuracy: 0.4333\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1.6281 - accuracy: 0.4180 - val_loss: 1.6199 - val_accuracy: 0.4278\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1.6287 - accuracy: 0.4203 - val_loss: 1.5827 - val_accuracy: 0.4425\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1.6249 - accuracy: 0.4208 - val_loss: 1.5883 - val_accuracy: 0.4358\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 36s 456ms/step - loss: 1.6245 - accuracy: 0.4189 - val_loss: 1.6293 - val_accuracy: 0.4216\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.6215 - accuracy: 0.4212 - val_loss: 1.5944 - val_accuracy: 0.4342\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.6133 - accuracy: 0.4218 - val_loss: 1.5799 - val_accuracy: 0.4392\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.6179 - accuracy: 0.4245 - val_loss: 1.6035 - val_accuracy: 0.4314\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.6081 - accuracy: 0.4290 - val_loss: 1.6979 - val_accuracy: 0.4005\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 36s 450ms/step - loss: 1.6181 - accuracy: 0.4232 - val_loss: 1.5601 - val_accuracy: 0.4438\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1.6074 - accuracy: 0.4280 - val_loss: 1.5955 - val_accuracy: 0.4411\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1.6107 - accuracy: 0.4271 - val_loss: 1.6024 - val_accuracy: 0.4287\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.5436 - accuracy: 0.4484\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5601 - accuracy: 0.4438\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5557 - accuracy: 0.4456\n",
      "Train accuracy: 0.4484249949455261\n",
      "Validation accuracy: 0.4438000023365021\n",
      "Test accuracy: 0.4456000030040741\n",
      "big_grid_model_37\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 11)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 11)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        1600      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,057,642\n",
      "Trainable params: 1,057,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 8.5440 - accuracy: 0.1464 - val_loss: 2.2221 - val_accuracy: 0.1653\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 35s 445ms/step - loss: 2.1591 - accuracy: 0.1903 - val_loss: 2.1643 - val_accuracy: 0.1842\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 2.1169 - accuracy: 0.2139 - val_loss: 2.1319 - val_accuracy: 0.2063\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 36s 458ms/step - loss: 2.0960 - accuracy: 0.2271 - val_loss: 2.1056 - val_accuracy: 0.2190\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 36s 450ms/step - loss: 2.0820 - accuracy: 0.2343 - val_loss: 2.0980 - val_accuracy: 0.2263\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 2.0645 - accuracy: 0.2417 - val_loss: 2.0796 - val_accuracy: 0.2371\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 36s 454ms/step - loss: 2.0545 - accuracy: 0.2516 - val_loss: 2.0701 - val_accuracy: 0.2446\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 2.0397 - accuracy: 0.2542 - val_loss: 2.0826 - val_accuracy: 0.2475\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 2.0307 - accuracy: 0.2569 - val_loss: 2.0881 - val_accuracy: 0.2342\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 2.0232 - accuracy: 0.2659 - val_loss: 2.0480 - val_accuracy: 0.2591\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 2.0153 - accuracy: 0.2688 - val_loss: 2.0371 - val_accuracy: 0.2615\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 2.0009 - accuracy: 0.2754 - val_loss: 2.0372 - val_accuracy: 0.2647\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 36s 452ms/step - loss: 1.9969 - accuracy: 0.2756 - val_loss: 2.0203 - val_accuracy: 0.2803\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 36s 453ms/step - loss: 1.9860 - accuracy: 0.2815 - val_loss: 2.0548 - val_accuracy: 0.2515\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.9777 - accuracy: 0.2855 - val_loss: 2.0396 - val_accuracy: 0.2701\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.9777 - accuracy: 0.2873 - val_loss: 2.0134 - val_accuracy: 0.2715\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 35s 444ms/step - loss: 1.9667 - accuracy: 0.2900 - val_loss: 2.0056 - val_accuracy: 0.2775\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.9528 - accuracy: 0.2983 - val_loss: 1.9964 - val_accuracy: 0.2868\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1.9484 - accuracy: 0.2959 - val_loss: 2.0071 - val_accuracy: 0.2765\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1.9525 - accuracy: 0.2961 - val_loss: 1.9800 - val_accuracy: 0.2999\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.9427 - accuracy: 0.3017 - val_loss: 1.9574 - val_accuracy: 0.3043\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.9322 - accuracy: 0.3030 - val_loss: 1.9693 - val_accuracy: 0.2968\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.9282 - accuracy: 0.3041 - val_loss: 1.9694 - val_accuracy: 0.2906\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.9190 - accuracy: 0.3070 - val_loss: 1.9668 - val_accuracy: 0.3034\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.9216 - accuracy: 0.3090 - val_loss: 1.9606 - val_accuracy: 0.2983\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.9143 - accuracy: 0.3117 - val_loss: 1.9733 - val_accuracy: 0.2908\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.9157 - accuracy: 0.3143 - val_loss: 1.9379 - val_accuracy: 0.3090\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.9012 - accuracy: 0.3156 - val_loss: 1.9435 - val_accuracy: 0.3061\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8923 - accuracy: 0.3222 - val_loss: 1.9136 - val_accuracy: 0.3198\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.8852 - accuracy: 0.3238 - val_loss: 1.8916 - val_accuracy: 0.3247\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.8893 - accuracy: 0.3234 - val_loss: 1.9106 - val_accuracy: 0.3207\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.8755 - accuracy: 0.3271 - val_loss: 1.8998 - val_accuracy: 0.3232\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8701 - accuracy: 0.3323 - val_loss: 1.9325 - val_accuracy: 0.3077\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8585 - accuracy: 0.3345 - val_loss: 1.8998 - val_accuracy: 0.3221\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.8547 - accuracy: 0.3344 - val_loss: 1.9265 - val_accuracy: 0.3114\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.8550 - accuracy: 0.3343 - val_loss: 1.8934 - val_accuracy: 0.3210\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8492 - accuracy: 0.3341 - val_loss: 1.8623 - val_accuracy: 0.3350\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8410 - accuracy: 0.3412 - val_loss: 1.8537 - val_accuracy: 0.3395\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.8369 - accuracy: 0.3444 - val_loss: 1.8562 - val_accuracy: 0.3402\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8335 - accuracy: 0.3447 - val_loss: 1.8499 - val_accuracy: 0.3507\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8299 - accuracy: 0.3463 - val_loss: 1.8122 - val_accuracy: 0.3577\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 34s 433ms/step - loss: 1.8106 - accuracy: 0.3512 - val_loss: 1.8168 - val_accuracy: 0.3542\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8159 - accuracy: 0.3490 - val_loss: 1.8294 - val_accuracy: 0.3512\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.8016 - accuracy: 0.3563 - val_loss: 1.7971 - val_accuracy: 0.3559\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7939 - accuracy: 0.3586 - val_loss: 1.8012 - val_accuracy: 0.3589\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7809 - accuracy: 0.3622 - val_loss: 1.8012 - val_accuracy: 0.3589\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7814 - accuracy: 0.3626 - val_loss: 1.7696 - val_accuracy: 0.3680\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7812 - accuracy: 0.3622 - val_loss: 1.7920 - val_accuracy: 0.3739\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7711 - accuracy: 0.3666 - val_loss: 1.7850 - val_accuracy: 0.3658\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7668 - accuracy: 0.3637 - val_loss: 1.7636 - val_accuracy: 0.3696\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7632 - accuracy: 0.3712 - val_loss: 1.7542 - val_accuracy: 0.3713\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.7583 - accuracy: 0.3732 - val_loss: 1.7876 - val_accuracy: 0.3646\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.7525 - accuracy: 0.3737 - val_loss: 1.7550 - val_accuracy: 0.3769\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.7414 - accuracy: 0.3784 - val_loss: 1.7474 - val_accuracy: 0.3799\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7424 - accuracy: 0.3756 - val_loss: 1.6949 - val_accuracy: 0.4005\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7339 - accuracy: 0.3794 - val_loss: 1.7213 - val_accuracy: 0.3867\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7319 - accuracy: 0.3812 - val_loss: 1.7776 - val_accuracy: 0.3745\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7206 - accuracy: 0.3866 - val_loss: 1.7251 - val_accuracy: 0.3852\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 1.7274 - accuracy: 0.3801 - val_loss: 1.6896 - val_accuracy: 0.4018\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7132 - accuracy: 0.3856 - val_loss: 1.7255 - val_accuracy: 0.3926\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7055 - accuracy: 0.3927 - val_loss: 1.7276 - val_accuracy: 0.3874\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.7042 - accuracy: 0.3949 - val_loss: 1.7246 - val_accuracy: 0.3906\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.6900 - accuracy: 0.3966 - val_loss: 1.6786 - val_accuracy: 0.4079\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6917 - accuracy: 0.3952 - val_loss: 1.6734 - val_accuracy: 0.4053\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6875 - accuracy: 0.3986 - val_loss: 1.6735 - val_accuracy: 0.4085\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.6691 - accuracy: 0.4063 - val_loss: 1.6219 - val_accuracy: 0.4281\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.6752 - accuracy: 0.4033 - val_loss: 1.7463 - val_accuracy: 0.3916\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6740 - accuracy: 0.4043 - val_loss: 1.6901 - val_accuracy: 0.4097\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6737 - accuracy: 0.4034 - val_loss: 1.6858 - val_accuracy: 0.4046\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.6764 - accuracy: 0.4020 - val_loss: 1.6617 - val_accuracy: 0.4101\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.6528 - accuracy: 0.4076 - val_loss: 1.6249 - val_accuracy: 0.4207\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.6448 - accuracy: 0.4127 - val_loss: 1.6312 - val_accuracy: 0.4212\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.6498 - accuracy: 0.4130 - val_loss: 1.6618 - val_accuracy: 0.4122\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.6444 - accuracy: 0.4144 - val_loss: 1.6998 - val_accuracy: 0.3957\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.6385 - accuracy: 0.4173 - val_loss: 1.5957 - val_accuracy: 0.4356\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.6414 - accuracy: 0.4110 - val_loss: 1.6020 - val_accuracy: 0.4297\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 34s 433ms/step - loss: 1.6390 - accuracy: 0.4168 - val_loss: 1.5681 - val_accuracy: 0.4453\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.6194 - accuracy: 0.4220 - val_loss: 1.6201 - val_accuracy: 0.4238\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 33s 418ms/step - loss: 1.6226 - accuracy: 0.4224 - val_loss: 1.5790 - val_accuracy: 0.4436\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.6234 - accuracy: 0.4193 - val_loss: 1.6285 - val_accuracy: 0.4206\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.6248 - accuracy: 0.4209 - val_loss: 1.6017 - val_accuracy: 0.4313\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.6087 - accuracy: 0.4252 - val_loss: 1.6400 - val_accuracy: 0.4209\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.6140 - accuracy: 0.4238 - val_loss: 1.5803 - val_accuracy: 0.4416\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6087 - accuracy: 0.4267 - val_loss: 1.6059 - val_accuracy: 0.4325\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6168 - accuracy: 0.4252 - val_loss: 1.5605 - val_accuracy: 0.4488\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.6042 - accuracy: 0.4254 - val_loss: 1.5933 - val_accuracy: 0.4345\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.6020 - accuracy: 0.4274 - val_loss: 1.5679 - val_accuracy: 0.4366\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.5953 - accuracy: 0.4336 - val_loss: 1.5384 - val_accuracy: 0.4531\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.5850 - accuracy: 0.4355 - val_loss: 1.5284 - val_accuracy: 0.4509\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.5944 - accuracy: 0.4316 - val_loss: 1.5742 - val_accuracy: 0.4352\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.5852 - accuracy: 0.4363 - val_loss: 1.5797 - val_accuracy: 0.4372\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.5741 - accuracy: 0.4368 - val_loss: 1.5830 - val_accuracy: 0.4417\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.5795 - accuracy: 0.4383 - val_loss: 1.5395 - val_accuracy: 0.4508\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.5705 - accuracy: 0.4410 - val_loss: 1.5769 - val_accuracy: 0.4418\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 1.5674 - accuracy: 0.4405 - val_loss: 1.6127 - val_accuracy: 0.4261\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.5673 - accuracy: 0.4418 - val_loss: 1.6089 - val_accuracy: 0.4273\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 33s 420ms/step - loss: 1.5707 - accuracy: 0.4400 - val_loss: 1.5357 - val_accuracy: 0.4619\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 33s 418ms/step - loss: 1.5710 - accuracy: 0.4399 - val_loss: 1.5861 - val_accuracy: 0.4387\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 33s 419ms/step - loss: 1.5579 - accuracy: 0.4403 - val_loss: 1.5320 - val_accuracy: 0.4600\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.5613 - accuracy: 0.4449 - val_loss: 1.5335 - val_accuracy: 0.4573\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.5096 - accuracy: 0.4672\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5357 - accuracy: 0.4619\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5224 - accuracy: 0.4685\n",
      "Train accuracy: 0.4671500027179718\n",
      "Validation accuracy: 0.461899995803833\n",
      "Test accuracy: 0.4684999883174896\n",
      "big_grid_model_38\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 11)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 11)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        3200      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,071,690\n",
      "Trainable params: 1,071,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 7.0748 - accuracy: 0.1458 - val_loss: 2.1746 - val_accuracy: 0.1735\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 2.1384 - accuracy: 0.2104 - val_loss: 2.1486 - val_accuracy: 0.2179\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 2.0815 - accuracy: 0.2370 - val_loss: 2.0526 - val_accuracy: 0.2536\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 2.0609 - accuracy: 0.2489 - val_loss: 2.0673 - val_accuracy: 0.2482\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 2.0413 - accuracy: 0.2591 - val_loss: 2.0054 - val_accuracy: 0.2736\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 2.0237 - accuracy: 0.2631 - val_loss: 1.9964 - val_accuracy: 0.2812\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 2.0092 - accuracy: 0.2709 - val_loss: 1.9740 - val_accuracy: 0.2937\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 1.9829 - accuracy: 0.2815 - val_loss: 1.9688 - val_accuracy: 0.2957\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.9703 - accuracy: 0.2888 - val_loss: 1.9574 - val_accuracy: 0.2983\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 34s 436ms/step - loss: 1.9787 - accuracy: 0.2870 - val_loss: 1.9053 - val_accuracy: 0.3142\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.9500 - accuracy: 0.2955 - val_loss: 1.9494 - val_accuracy: 0.3073\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.9430 - accuracy: 0.2990 - val_loss: 1.9049 - val_accuracy: 0.3235\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9265 - accuracy: 0.3062 - val_loss: 1.9537 - val_accuracy: 0.3108\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.9187 - accuracy: 0.3137 - val_loss: 1.8905 - val_accuracy: 0.3295\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.9168 - accuracy: 0.3088 - val_loss: 1.8924 - val_accuracy: 0.3246\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.9014 - accuracy: 0.3162 - val_loss: 1.8681 - val_accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.8870 - accuracy: 0.3212 - val_loss: 1.8654 - val_accuracy: 0.3399\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.8863 - accuracy: 0.3225 - val_loss: 1.8555 - val_accuracy: 0.3415\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.8655 - accuracy: 0.3299 - val_loss: 1.8229 - val_accuracy: 0.3542\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8587 - accuracy: 0.3339 - val_loss: 1.8766 - val_accuracy: 0.3255\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8545 - accuracy: 0.3350 - val_loss: 1.8469 - val_accuracy: 0.3396\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.8315 - accuracy: 0.3452 - val_loss: 1.8151 - val_accuracy: 0.3515\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.8296 - accuracy: 0.3446 - val_loss: 1.8266 - val_accuracy: 0.3505\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8189 - accuracy: 0.3492 - val_loss: 1.8534 - val_accuracy: 0.3416\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8166 - accuracy: 0.3478 - val_loss: 1.8295 - val_accuracy: 0.3582\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.8013 - accuracy: 0.3561 - val_loss: 1.8177 - val_accuracy: 0.3578\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 34s 436ms/step - loss: 1.7906 - accuracy: 0.3587 - val_loss: 1.8167 - val_accuracy: 0.3627\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.7841 - accuracy: 0.3623 - val_loss: 1.8629 - val_accuracy: 0.3467\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.7794 - accuracy: 0.3644 - val_loss: 1.7784 - val_accuracy: 0.3694\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7578 - accuracy: 0.3736 - val_loss: 1.7551 - val_accuracy: 0.3797\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7609 - accuracy: 0.3668 - val_loss: 1.7419 - val_accuracy: 0.3831\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.7523 - accuracy: 0.3722 - val_loss: 1.7174 - val_accuracy: 0.3954\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.7560 - accuracy: 0.3735 - val_loss: 1.7233 - val_accuracy: 0.3902\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.7316 - accuracy: 0.3821 - val_loss: 1.7559 - val_accuracy: 0.3802\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.7299 - accuracy: 0.3804 - val_loss: 1.6718 - val_accuracy: 0.4111\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.7162 - accuracy: 0.3868 - val_loss: 1.6989 - val_accuracy: 0.3957\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 1.7089 - accuracy: 0.3893 - val_loss: 1.7027 - val_accuracy: 0.3967\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.7051 - accuracy: 0.3929 - val_loss: 1.7939 - val_accuracy: 0.3799\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.6909 - accuracy: 0.3982 - val_loss: 1.7143 - val_accuracy: 0.3984\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.6747 - accuracy: 0.4018 - val_loss: 1.7024 - val_accuracy: 0.4040\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.6762 - accuracy: 0.4013 - val_loss: 1.7262 - val_accuracy: 0.3896\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 1.6698 - accuracy: 0.4024 - val_loss: 1.6744 - val_accuracy: 0.4113\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.6677 - accuracy: 0.4054 - val_loss: 1.6823 - val_accuracy: 0.4131\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.6729 - accuracy: 0.4042 - val_loss: 1.6296 - val_accuracy: 0.4257\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 34s 432ms/step - loss: 1.6420 - accuracy: 0.4116 - val_loss: 1.6519 - val_accuracy: 0.4128\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 35s 438ms/step - loss: 1.6425 - accuracy: 0.4129 - val_loss: 1.6919 - val_accuracy: 0.4062\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 36s 455ms/step - loss: 1.6318 - accuracy: 0.4166 - val_loss: 1.6296 - val_accuracy: 0.4291\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.6262 - accuracy: 0.4212 - val_loss: 1.6430 - val_accuracy: 0.4240\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.6208 - accuracy: 0.4226 - val_loss: 1.6112 - val_accuracy: 0.4322\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 36s 450ms/step - loss: 1.6146 - accuracy: 0.4256 - val_loss: 1.6463 - val_accuracy: 0.4238\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.6068 - accuracy: 0.4260 - val_loss: 1.5796 - val_accuracy: 0.4379\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.6123 - accuracy: 0.4260 - val_loss: 1.5799 - val_accuracy: 0.4433\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.5956 - accuracy: 0.4306 - val_loss: 1.6172 - val_accuracy: 0.4364\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.5845 - accuracy: 0.4347 - val_loss: 1.5800 - val_accuracy: 0.4450\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.6018 - accuracy: 0.4299 - val_loss: 1.5577 - val_accuracy: 0.4522\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 35s 443ms/step - loss: 1.5910 - accuracy: 0.4336 - val_loss: 1.5961 - val_accuracy: 0.4382\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.5814 - accuracy: 0.4376 - val_loss: 1.5827 - val_accuracy: 0.4455\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.5750 - accuracy: 0.4427 - val_loss: 1.5692 - val_accuracy: 0.4530\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.5708 - accuracy: 0.4417 - val_loss: 1.5462 - val_accuracy: 0.4560\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.5692 - accuracy: 0.4439 - val_loss: 1.5382 - val_accuracy: 0.4574\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.5630 - accuracy: 0.4426 - val_loss: 1.6120 - val_accuracy: 0.4284\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 34s 433ms/step - loss: 1.5632 - accuracy: 0.4427 - val_loss: 1.5515 - val_accuracy: 0.4591\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.5540 - accuracy: 0.4515 - val_loss: 1.5107 - val_accuracy: 0.4667\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.5505 - accuracy: 0.4478 - val_loss: 1.5390 - val_accuracy: 0.4558\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.5416 - accuracy: 0.4528 - val_loss: 1.5211 - val_accuracy: 0.4650\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.5389 - accuracy: 0.4532 - val_loss: 1.5001 - val_accuracy: 0.4734\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.5315 - accuracy: 0.4578 - val_loss: 1.4861 - val_accuracy: 0.4730\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.5182 - accuracy: 0.4590 - val_loss: 1.5028 - val_accuracy: 0.4674\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.5163 - accuracy: 0.4635 - val_loss: 1.5688 - val_accuracy: 0.4481\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.5245 - accuracy: 0.4589 - val_loss: 1.4970 - val_accuracy: 0.4775\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.5253 - accuracy: 0.4584 - val_loss: 1.4553 - val_accuracy: 0.4875\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.5250 - accuracy: 0.4624 - val_loss: 1.4878 - val_accuracy: 0.4784\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.5106 - accuracy: 0.4647 - val_loss: 1.4682 - val_accuracy: 0.4868\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.5014 - accuracy: 0.4660 - val_loss: 1.4616 - val_accuracy: 0.4866\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 34s 434ms/step - loss: 1.4993 - accuracy: 0.4684 - val_loss: 1.4665 - val_accuracy: 0.4819\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.5040 - accuracy: 0.4691 - val_loss: 1.5532 - val_accuracy: 0.4545\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.5099 - accuracy: 0.4655 - val_loss: 1.4370 - val_accuracy: 0.4975\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.5046 - accuracy: 0.4654 - val_loss: 1.4527 - val_accuracy: 0.4887\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.4971 - accuracy: 0.4710 - val_loss: 1.4893 - val_accuracy: 0.4759\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 34s 432ms/step - loss: 1.4810 - accuracy: 0.4760 - val_loss: 1.4891 - val_accuracy: 0.4796\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.4905 - accuracy: 0.4720 - val_loss: 1.5771 - val_accuracy: 0.4520\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.4928 - accuracy: 0.4733 - val_loss: 1.4559 - val_accuracy: 0.4912\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.4925 - accuracy: 0.4718 - val_loss: 1.4295 - val_accuracy: 0.4989\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.4770 - accuracy: 0.4775 - val_loss: 1.4810 - val_accuracy: 0.4853\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.4782 - accuracy: 0.4774 - val_loss: 1.4352 - val_accuracy: 0.4933\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.4622 - accuracy: 0.4799 - val_loss: 1.5474 - val_accuracy: 0.4638\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.4684 - accuracy: 0.4814 - val_loss: 1.4259 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 34s 428ms/step - loss: 1.4719 - accuracy: 0.4779 - val_loss: 1.4427 - val_accuracy: 0.4976\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.4593 - accuracy: 0.4848 - val_loss: 1.4142 - val_accuracy: 0.5049\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.4586 - accuracy: 0.4832 - val_loss: 1.4604 - val_accuracy: 0.4909\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.4629 - accuracy: 0.4809 - val_loss: 1.4379 - val_accuracy: 0.5003\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.4587 - accuracy: 0.4823 - val_loss: 1.4708 - val_accuracy: 0.4878\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.4679 - accuracy: 0.4839 - val_loss: 1.4155 - val_accuracy: 0.5031\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.4529 - accuracy: 0.4852 - val_loss: 1.4039 - val_accuracy: 0.5077\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 1.4511 - accuracy: 0.4885 - val_loss: 1.4316 - val_accuracy: 0.5003\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.4530 - accuracy: 0.4864 - val_loss: 1.3930 - val_accuracy: 0.5099\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.4466 - accuracy: 0.4893 - val_loss: 1.4263 - val_accuracy: 0.5086\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.4388 - accuracy: 0.4905 - val_loss: 1.4272 - val_accuracy: 0.5016\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 34s 424ms/step - loss: 1.4362 - accuracy: 0.4941 - val_loss: 1.3940 - val_accuracy: 0.5132\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 1.4324 - accuracy: 0.4939 - val_loss: 1.4576 - val_accuracy: 0.4989\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.3565 - accuracy: 0.5251\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3940 - accuracy: 0.5132\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3796 - accuracy: 0.5210\n",
      "Train accuracy: 0.5250999927520752\n",
      "Validation accuracy: 0.5131999850273132\n",
      "Test accuracy: 0.5210000276565552\n",
      "big_grid_model_39\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 11)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 11)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 11)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        3200      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,121,674\n",
      "Trainable params: 2,121,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 8.1304 - accuracy: 0.1291 - val_loss: 2.2658 - val_accuracy: 0.1442\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 34s 433ms/step - loss: 2.1794 - accuracy: 0.1859 - val_loss: 2.2045 - val_accuracy: 0.1823\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 2.1293 - accuracy: 0.2101 - val_loss: 2.1233 - val_accuracy: 0.2177\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 2.0942 - accuracy: 0.2298 - val_loss: 2.0761 - val_accuracy: 0.2490\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 2.0674 - accuracy: 0.2454 - val_loss: 2.0594 - val_accuracy: 0.2530\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 2.0573 - accuracy: 0.2502 - val_loss: 2.0380 - val_accuracy: 0.2664\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 2.0263 - accuracy: 0.2639 - val_loss: 1.9894 - val_accuracy: 0.2849\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 2.0129 - accuracy: 0.2726 - val_loss: 2.0326 - val_accuracy: 0.2657\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 2.0050 - accuracy: 0.2749 - val_loss: 1.9967 - val_accuracy: 0.2860\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 33s 423ms/step - loss: 2.0034 - accuracy: 0.2750 - val_loss: 1.9773 - val_accuracy: 0.2892\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 34s 432ms/step - loss: 1.9812 - accuracy: 0.2831 - val_loss: 1.9404 - val_accuracy: 0.3052\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 34s 437ms/step - loss: 1.9752 - accuracy: 0.2850 - val_loss: 1.9488 - val_accuracy: 0.3045\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 1.9577 - accuracy: 0.2953 - val_loss: 2.0088 - val_accuracy: 0.2849\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 33s 421ms/step - loss: 1.9539 - accuracy: 0.2941 - val_loss: 1.9385 - val_accuracy: 0.3116\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.9398 - accuracy: 0.3028 - val_loss: 1.9267 - val_accuracy: 0.3144\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.9388 - accuracy: 0.3023 - val_loss: 1.9275 - val_accuracy: 0.3097\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 33s 422ms/step - loss: 1.9165 - accuracy: 0.3106 - val_loss: 1.9090 - val_accuracy: 0.3214\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 34s 426ms/step - loss: 1.9112 - accuracy: 0.3136 - val_loss: 1.9021 - val_accuracy: 0.3222\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 33s 424ms/step - loss: 1.9161 - accuracy: 0.3104 - val_loss: 1.8683 - val_accuracy: 0.3408\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 34s 427ms/step - loss: 1.9090 - accuracy: 0.3110 - val_loss: 1.8857 - val_accuracy: 0.3354\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 1.8905 - accuracy: 0.3222 - val_loss: 1.9014 - val_accuracy: 0.3230\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8888 - accuracy: 0.3231 - val_loss: 1.8598 - val_accuracy: 0.3350\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 1.8744 - accuracy: 0.3252 - val_loss: 1.8517 - val_accuracy: 0.3375\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 35s 443ms/step - loss: 1.8676 - accuracy: 0.3275 - val_loss: 1.8842 - val_accuracy: 0.3317\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.8508 - accuracy: 0.3378 - val_loss: 1.8550 - val_accuracy: 0.3429\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 36s 449ms/step - loss: 1.8451 - accuracy: 0.3399 - val_loss: 1.8413 - val_accuracy: 0.3446\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.8571 - accuracy: 0.3339 - val_loss: 1.7973 - val_accuracy: 0.3641\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 36s 451ms/step - loss: 1.8160 - accuracy: 0.3489 - val_loss: 1.7858 - val_accuracy: 0.3721\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 36s 451ms/step - loss: 1.8093 - accuracy: 0.3505 - val_loss: 1.7960 - val_accuracy: 0.3691\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 36s 455ms/step - loss: 1.7893 - accuracy: 0.3598 - val_loss: 1.7654 - val_accuracy: 0.3807\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 36s 453ms/step - loss: 1.7762 - accuracy: 0.3656 - val_loss: 1.7598 - val_accuracy: 0.3819\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.7770 - accuracy: 0.3680 - val_loss: 1.7433 - val_accuracy: 0.3898\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 36s 451ms/step - loss: 1.7679 - accuracy: 0.3694 - val_loss: 1.7045 - val_accuracy: 0.3962\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.7578 - accuracy: 0.3725 - val_loss: 1.7929 - val_accuracy: 0.3699\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.7379 - accuracy: 0.3812 - val_loss: 1.7464 - val_accuracy: 0.3795\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 36s 451ms/step - loss: 1.7286 - accuracy: 0.3837 - val_loss: 1.6880 - val_accuracy: 0.3990\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.7100 - accuracy: 0.3905 - val_loss: 1.6789 - val_accuracy: 0.4064\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.7215 - accuracy: 0.3848 - val_loss: 1.7148 - val_accuracy: 0.3996\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 36s 454ms/step - loss: 1.7043 - accuracy: 0.3922 - val_loss: 1.7133 - val_accuracy: 0.4009\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 36s 452ms/step - loss: 1.6832 - accuracy: 0.3974 - val_loss: 1.6450 - val_accuracy: 0.4185\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.6785 - accuracy: 0.4013 - val_loss: 1.6379 - val_accuracy: 0.4181\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 36s 450ms/step - loss: 1.6735 - accuracy: 0.4033 - val_loss: 1.6269 - val_accuracy: 0.4243\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 36s 450ms/step - loss: 1.6543 - accuracy: 0.4098 - val_loss: 1.6131 - val_accuracy: 0.4328\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.6458 - accuracy: 0.4149 - val_loss: 1.6116 - val_accuracy: 0.4282\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.6329 - accuracy: 0.4217 - val_loss: 1.5958 - val_accuracy: 0.4320\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 36s 461ms/step - loss: 1.6249 - accuracy: 0.4187 - val_loss: 1.6018 - val_accuracy: 0.4355\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 36s 453ms/step - loss: 1.6241 - accuracy: 0.4253 - val_loss: 1.5688 - val_accuracy: 0.4495\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 36s 454ms/step - loss: 1.6182 - accuracy: 0.4260 - val_loss: 1.5588 - val_accuracy: 0.4540\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 36s 453ms/step - loss: 1.6061 - accuracy: 0.4278 - val_loss: 1.6481 - val_accuracy: 0.4177\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 36s 451ms/step - loss: 1.5981 - accuracy: 0.4305 - val_loss: 1.5964 - val_accuracy: 0.4376\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.5970 - accuracy: 0.4324 - val_loss: 1.5629 - val_accuracy: 0.4425\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.5775 - accuracy: 0.4378 - val_loss: 1.6496 - val_accuracy: 0.4226\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.5839 - accuracy: 0.4374 - val_loss: 1.5250 - val_accuracy: 0.4620\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.5727 - accuracy: 0.4390 - val_loss: 1.5530 - val_accuracy: 0.4569\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 35s 445ms/step - loss: 1.5625 - accuracy: 0.4487 - val_loss: 1.5398 - val_accuracy: 0.4563\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.5557 - accuracy: 0.4493 - val_loss: 1.5319 - val_accuracy: 0.4653\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 36s 452ms/step - loss: 1.5543 - accuracy: 0.4474 - val_loss: 1.4877 - val_accuracy: 0.4741\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 36s 453ms/step - loss: 1.5487 - accuracy: 0.4500 - val_loss: 1.5380 - val_accuracy: 0.4589\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.5471 - accuracy: 0.4496 - val_loss: 1.4997 - val_accuracy: 0.4723\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.5403 - accuracy: 0.4534 - val_loss: 1.6199 - val_accuracy: 0.4258\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.5435 - accuracy: 0.4545 - val_loss: 1.4792 - val_accuracy: 0.4774\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 36s 452ms/step - loss: 1.5233 - accuracy: 0.4578 - val_loss: 1.4953 - val_accuracy: 0.4734\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 36s 457ms/step - loss: 1.5248 - accuracy: 0.4633 - val_loss: 1.4921 - val_accuracy: 0.4719\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 36s 453ms/step - loss: 1.5240 - accuracy: 0.4614 - val_loss: 1.5233 - val_accuracy: 0.4579\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 36s 451ms/step - loss: 1.5164 - accuracy: 0.4587 - val_loss: 1.4798 - val_accuracy: 0.4795\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 36s 452ms/step - loss: 1.5079 - accuracy: 0.4649 - val_loss: 1.5077 - val_accuracy: 0.4672\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 36s 457ms/step - loss: 1.5071 - accuracy: 0.4714 - val_loss: 1.5109 - val_accuracy: 0.4650\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 36s 449ms/step - loss: 1.5063 - accuracy: 0.4669 - val_loss: 1.4855 - val_accuracy: 0.4736\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.5146 - accuracy: 0.4640 - val_loss: 1.5314 - val_accuracy: 0.4625\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 36s 455ms/step - loss: 1.4990 - accuracy: 0.4678 - val_loss: 1.4711 - val_accuracy: 0.4779\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 36s 450ms/step - loss: 1.4995 - accuracy: 0.4685 - val_loss: 1.4562 - val_accuracy: 0.4834\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 36s 452ms/step - loss: 1.4826 - accuracy: 0.4748 - val_loss: 1.4251 - val_accuracy: 0.4970\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 36s 449ms/step - loss: 1.4919 - accuracy: 0.4714 - val_loss: 1.4963 - val_accuracy: 0.4742\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 36s 452ms/step - loss: 1.4763 - accuracy: 0.4773 - val_loss: 1.4768 - val_accuracy: 0.4726\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 36s 453ms/step - loss: 1.4739 - accuracy: 0.4810 - val_loss: 1.4867 - val_accuracy: 0.4750\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 37s 462ms/step - loss: 1.4764 - accuracy: 0.4784 - val_loss: 1.4412 - val_accuracy: 0.4934\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.4721 - accuracy: 0.4803 - val_loss: 1.4469 - val_accuracy: 0.4898\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.4702 - accuracy: 0.4800 - val_loss: 1.5174 - val_accuracy: 0.4614\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 36s 459ms/step - loss: 1.4722 - accuracy: 0.4779 - val_loss: 1.4440 - val_accuracy: 0.4880\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.4569 - accuracy: 0.4847 - val_loss: 1.4175 - val_accuracy: 0.5038\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.4519 - accuracy: 0.4870 - val_loss: 1.4282 - val_accuracy: 0.4930\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.4634 - accuracy: 0.4794 - val_loss: 1.4373 - val_accuracy: 0.4969\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 35s 447ms/step - loss: 1.4664 - accuracy: 0.4806 - val_loss: 1.4333 - val_accuracy: 0.4891\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 35s 445ms/step - loss: 1.4509 - accuracy: 0.4872 - val_loss: 1.4128 - val_accuracy: 0.4986\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 36s 452ms/step - loss: 1.4581 - accuracy: 0.4840 - val_loss: 1.4162 - val_accuracy: 0.4967\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 36s 450ms/step - loss: 1.4404 - accuracy: 0.4921 - val_loss: 1.4348 - val_accuracy: 0.4948\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.4393 - accuracy: 0.4931 - val_loss: 1.4160 - val_accuracy: 0.4988\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 36s 450ms/step - loss: 1.4437 - accuracy: 0.4922 - val_loss: 1.4395 - val_accuracy: 0.4884\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.4417 - accuracy: 0.4913 - val_loss: 1.3627 - val_accuracy: 0.5165\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1.4325 - accuracy: 0.4933 - val_loss: 1.4075 - val_accuracy: 0.5090\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.4349 - accuracy: 0.4906 - val_loss: 1.4163 - val_accuracy: 0.5018\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.4388 - accuracy: 0.4891 - val_loss: 1.4079 - val_accuracy: 0.5012\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.4396 - accuracy: 0.4919 - val_loss: 1.3943 - val_accuracy: 0.5075\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 36s 452ms/step - loss: 1.4152 - accuracy: 0.5002 - val_loss: 1.4533 - val_accuracy: 0.4934\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 36s 450ms/step - loss: 1.4243 - accuracy: 0.4973 - val_loss: 1.4030 - val_accuracy: 0.5022\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 36s 457ms/step - loss: 1.4079 - accuracy: 0.5034 - val_loss: 1.4139 - val_accuracy: 0.5074\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1.4053 - accuracy: 0.5026 - val_loss: 1.3792 - val_accuracy: 0.5224\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.4067 - accuracy: 0.5048 - val_loss: 1.4078 - val_accuracy: 0.5065\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 35s 449ms/step - loss: 1.4161 - accuracy: 0.5005 - val_loss: 1.3679 - val_accuracy: 0.5181\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 35s 448ms/step - loss: 1.4035 - accuracy: 0.5028 - val_loss: 1.4444 - val_accuracy: 0.4975\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.3239 - accuracy: 0.5358\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3792 - accuracy: 0.5224\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3519 - accuracy: 0.5310\n",
      "Train accuracy: 0.5357999801635742\n",
      "Validation accuracy: 0.5224000215530396\n",
      "Test accuracy: 0.531000018119812\n",
      "big_grid_model_40\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 13)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 13)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        1888      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 532,234\n",
      "Trainable params: 532,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (40000, 32, 32, 13) (13 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n",
      "C:\\Users\\admin\\anaconda3\\envs\\GPU_ML_TF\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (10000, 32, 32, 13) (13 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 7.9871 - accuracy: 0.1095 - val_loss: 2.2938 - val_accuracy: 0.1437\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 2.2728 - accuracy: 0.1419 - val_loss: 2.2869 - val_accuracy: 0.1371\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 2.2440 - accuracy: 0.1592 - val_loss: 2.2818 - val_accuracy: 0.1464\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 2.2164 - accuracy: 0.1753 - val_loss: 2.2619 - val_accuracy: 0.1678\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 41s 518ms/step - loss: 2.1889 - accuracy: 0.1892 - val_loss: 2.1758 - val_accuracy: 0.1988\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 41s 518ms/step - loss: 2.1607 - accuracy: 0.2047 - val_loss: 2.1872 - val_accuracy: 0.1877\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 2.1352 - accuracy: 0.2146 - val_loss: 2.1732 - val_accuracy: 0.2106\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 2.1141 - accuracy: 0.2219 - val_loss: 2.1204 - val_accuracy: 0.2156\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 43s 543ms/step - loss: 2.0961 - accuracy: 0.2282 - val_loss: 2.1396 - val_accuracy: 0.2121\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 2.0833 - accuracy: 0.2359 - val_loss: 2.1033 - val_accuracy: 0.2344\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 2.0738 - accuracy: 0.2394 - val_loss: 2.1730 - val_accuracy: 0.2074\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 2.0654 - accuracy: 0.2419 - val_loss: 2.0800 - val_accuracy: 0.2356\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 2.0583 - accuracy: 0.2459 - val_loss: 2.1015 - val_accuracy: 0.2113\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 38s 487ms/step - loss: 2.0380 - accuracy: 0.2534 - val_loss: 2.2527 - val_accuracy: 0.1863\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 2.0386 - accuracy: 0.2553 - val_loss: 2.0587 - val_accuracy: 0.2430\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 2.0318 - accuracy: 0.2592 - val_loss: 2.0540 - val_accuracy: 0.2416\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 2.0175 - accuracy: 0.2650 - val_loss: 2.0635 - val_accuracy: 0.2381\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 2.0086 - accuracy: 0.2691 - val_loss: 2.0547 - val_accuracy: 0.2387\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 2.0152 - accuracy: 0.2674 - val_loss: 2.0229 - val_accuracy: 0.2678\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 2.0081 - accuracy: 0.2697 - val_loss: 2.0133 - val_accuracy: 0.2661\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 2.0036 - accuracy: 0.2678 - val_loss: 2.0180 - val_accuracy: 0.2690\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.9902 - accuracy: 0.2745 - val_loss: 2.0174 - val_accuracy: 0.2692\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.9800 - accuracy: 0.2804 - val_loss: 2.0198 - val_accuracy: 0.2703\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 39s 500ms/step - loss: 1.9777 - accuracy: 0.2769 - val_loss: 2.0068 - val_accuracy: 0.2665\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.9701 - accuracy: 0.2833 - val_loss: 2.0255 - val_accuracy: 0.2626\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.9714 - accuracy: 0.2854 - val_loss: 2.0884 - val_accuracy: 0.2415\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.9642 - accuracy: 0.2865 - val_loss: 2.0053 - val_accuracy: 0.2844\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 38s 486ms/step - loss: 1.9587 - accuracy: 0.2914 - val_loss: 1.9826 - val_accuracy: 0.2823\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 1.9543 - accuracy: 0.2937 - val_loss: 2.0228 - val_accuracy: 0.2657\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.9459 - accuracy: 0.2929 - val_loss: 1.9595 - val_accuracy: 0.2931\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.9417 - accuracy: 0.2970 - val_loss: 1.9873 - val_accuracy: 0.2833\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.9391 - accuracy: 0.2982 - val_loss: 1.9609 - val_accuracy: 0.3012\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.9385 - accuracy: 0.2946 - val_loss: 2.0808 - val_accuracy: 0.2502\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.9316 - accuracy: 0.3018 - val_loss: 1.9318 - val_accuracy: 0.3109\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.9122 - accuracy: 0.3085 - val_loss: 1.9487 - val_accuracy: 0.2989\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.9136 - accuracy: 0.3106 - val_loss: 1.9838 - val_accuracy: 0.2847\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 38s 487ms/step - loss: 1.9062 - accuracy: 0.3149 - val_loss: 1.9505 - val_accuracy: 0.2997\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 1.8986 - accuracy: 0.3174 - val_loss: 1.9292 - val_accuracy: 0.3088\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.8893 - accuracy: 0.3181 - val_loss: 1.9710 - val_accuracy: 0.2979\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.8863 - accuracy: 0.3212 - val_loss: 1.9073 - val_accuracy: 0.3161\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 1.8826 - accuracy: 0.3238 - val_loss: 1.9079 - val_accuracy: 0.3159\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.8777 - accuracy: 0.3257 - val_loss: 1.9972 - val_accuracy: 0.2833\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.8704 - accuracy: 0.3274 - val_loss: 1.8853 - val_accuracy: 0.3292\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 1.8606 - accuracy: 0.3302 - val_loss: 1.8770 - val_accuracy: 0.3275\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 38s 487ms/step - loss: 1.8358 - accuracy: 0.3408 - val_loss: 1.8593 - val_accuracy: 0.3421\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.8548 - accuracy: 0.3333 - val_loss: 1.9570 - val_accuracy: 0.2983\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.8486 - accuracy: 0.3377 - val_loss: 1.9587 - val_accuracy: 0.2984\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.8322 - accuracy: 0.3423 - val_loss: 2.0102 - val_accuracy: 0.2781\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.8196 - accuracy: 0.3476 - val_loss: 1.9044 - val_accuracy: 0.3228\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.8124 - accuracy: 0.3523 - val_loss: 1.8845 - val_accuracy: 0.3258\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 1.8100 - accuracy: 0.3501 - val_loss: 1.8700 - val_accuracy: 0.3419\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 38s 487ms/step - loss: 1.8036 - accuracy: 0.3544 - val_loss: 1.8326 - val_accuracy: 0.3461\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 1.8159 - accuracy: 0.3494 - val_loss: 1.8578 - val_accuracy: 0.3461\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.8040 - accuracy: 0.3538 - val_loss: 1.9024 - val_accuracy: 0.3279\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.7938 - accuracy: 0.3546 - val_loss: 1.8244 - val_accuracy: 0.3467\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.7860 - accuracy: 0.3603 - val_loss: 1.8831 - val_accuracy: 0.3332\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 38s 487ms/step - loss: 1.7818 - accuracy: 0.3636 - val_loss: 1.8380 - val_accuracy: 0.3518\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 1.7713 - accuracy: 0.3637 - val_loss: 1.7994 - val_accuracy: 0.3643\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.7927 - accuracy: 0.3601 - val_loss: 1.8474 - val_accuracy: 0.3404\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.7819 - accuracy: 0.3619 - val_loss: 1.8207 - val_accuracy: 0.3481\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.7676 - accuracy: 0.3654 - val_loss: 1.8255 - val_accuracy: 0.3492\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.7622 - accuracy: 0.3651 - val_loss: 1.7791 - val_accuracy: 0.3694\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.7665 - accuracy: 0.3674 - val_loss: 1.7687 - val_accuracy: 0.3705\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.7704 - accuracy: 0.3659 - val_loss: 1.7576 - val_accuracy: 0.3688\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.7709 - accuracy: 0.3668 - val_loss: 1.8263 - val_accuracy: 0.3526\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.7620 - accuracy: 0.3696 - val_loss: 1.7657 - val_accuracy: 0.3727\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.7483 - accuracy: 0.3734 - val_loss: 1.7313 - val_accuracy: 0.3790\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.7533 - accuracy: 0.3725 - val_loss: 1.8017 - val_accuracy: 0.3601\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.7500 - accuracy: 0.3735 - val_loss: 1.7756 - val_accuracy: 0.3664\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.7422 - accuracy: 0.3765 - val_loss: 1.8207 - val_accuracy: 0.3519\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 1.7430 - accuracy: 0.3791 - val_loss: 1.7869 - val_accuracy: 0.3621\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.7323 - accuracy: 0.3799 - val_loss: 1.7368 - val_accuracy: 0.3872\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.7309 - accuracy: 0.3797 - val_loss: 1.7542 - val_accuracy: 0.3772\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.7277 - accuracy: 0.3821 - val_loss: 1.8039 - val_accuracy: 0.3683\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.7194 - accuracy: 0.3862 - val_loss: 1.7084 - val_accuracy: 0.3909\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.7241 - accuracy: 0.3841 - val_loss: 1.7129 - val_accuracy: 0.3887\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 38s 487ms/step - loss: 1.7153 - accuracy: 0.3865 - val_loss: 1.9178 - val_accuracy: 0.3271\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 1.7242 - accuracy: 0.3838 - val_loss: 1.8770 - val_accuracy: 0.3474\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.7061 - accuracy: 0.3896 - val_loss: 1.7410 - val_accuracy: 0.3836\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 38s 486ms/step - loss: 1.7076 - accuracy: 0.3921 - val_loss: 1.7300 - val_accuracy: 0.3878\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 1.6983 - accuracy: 0.3923 - val_loss: 1.7996 - val_accuracy: 0.3580\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 38s 485ms/step - loss: 1.6941 - accuracy: 0.3947 - val_loss: 1.6872 - val_accuracy: 0.3978\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.6947 - accuracy: 0.3943 - val_loss: 1.7526 - val_accuracy: 0.3752\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.6923 - accuracy: 0.3968 - val_loss: 1.7258 - val_accuracy: 0.3847\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 40s 500ms/step - loss: 1.6898 - accuracy: 0.3971 - val_loss: 1.6875 - val_accuracy: 0.3999\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.6902 - accuracy: 0.3945 - val_loss: 1.7764 - val_accuracy: 0.3717\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.6956 - accuracy: 0.3971 - val_loss: 1.6738 - val_accuracy: 0.4103\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.6901 - accuracy: 0.3974 - val_loss: 1.6813 - val_accuracy: 0.4074\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.6761 - accuracy: 0.4021 - val_loss: 1.6460 - val_accuracy: 0.4177\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 39s 487ms/step - loss: 1.6738 - accuracy: 0.4043 - val_loss: 1.7109 - val_accuracy: 0.3962\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 1.6738 - accuracy: 0.4039 - val_loss: 1.6552 - val_accuracy: 0.4097\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.6711 - accuracy: 0.4027 - val_loss: 1.7244 - val_accuracy: 0.3870\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 1.6713 - accuracy: 0.4042 - val_loss: 1.7006 - val_accuracy: 0.4029\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.6661 - accuracy: 0.4070 - val_loss: 1.7351 - val_accuracy: 0.3947\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.6580 - accuracy: 0.4096 - val_loss: 1.6581 - val_accuracy: 0.4158\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.6649 - accuracy: 0.4059 - val_loss: 1.7071 - val_accuracy: 0.3950\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.6583 - accuracy: 0.4074 - val_loss: 1.6663 - val_accuracy: 0.4109\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.6524 - accuracy: 0.4108 - val_loss: 1.6391 - val_accuracy: 0.4200\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.6521 - accuracy: 0.4132 - val_loss: 1.6348 - val_accuracy: 0.4198\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.6649 - accuracy: 0.4074 - val_loss: 1.6259 - val_accuracy: 0.4235\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.5971 - accuracy: 0.4269\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6259 - accuracy: 0.4235\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6137 - accuracy: 0.4245\n",
      "Train accuracy: 0.4268999993801117\n",
      "Validation accuracy: 0.4235000014305115\n",
      "Test accuracy: 0.4244999885559082\n",
      "big_grid_model_41\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 13)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 13)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        1888      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,057,930\n",
      "Trainable params: 1,057,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 11.1483 - accuracy: 0.1152 - val_loss: 2.2860 - val_accuracy: 0.1257\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 2.2665 - accuracy: 0.1499 - val_loss: 2.2658 - val_accuracy: 0.1466\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 2.2445 - accuracy: 0.1671 - val_loss: 2.2538 - val_accuracy: 0.1611\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 2.2227 - accuracy: 0.1811 - val_loss: 2.2423 - val_accuracy: 0.1745\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 2.2077 - accuracy: 0.1887 - val_loss: 2.2678 - val_accuracy: 0.1642\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 2.1926 - accuracy: 0.1949 - val_loss: 2.2581 - val_accuracy: 0.1560\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 2.1728 - accuracy: 0.2033 - val_loss: 2.2635 - val_accuracy: 0.1794\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 2.1646 - accuracy: 0.2058 - val_loss: 2.2422 - val_accuracy: 0.1805\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 2.1539 - accuracy: 0.2105 - val_loss: 2.1862 - val_accuracy: 0.2107\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 2.1429 - accuracy: 0.2192 - val_loss: 2.1991 - val_accuracy: 0.2110\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 2.1283 - accuracy: 0.2250 - val_loss: 2.1680 - val_accuracy: 0.2165\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 2.1181 - accuracy: 0.2263 - val_loss: 2.1567 - val_accuracy: 0.2187\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 2.1105 - accuracy: 0.2328 - val_loss: 2.1523 - val_accuracy: 0.2221\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 2.1039 - accuracy: 0.2351 - val_loss: 2.1264 - val_accuracy: 0.2328\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 2.0984 - accuracy: 0.2344 - val_loss: 2.1095 - val_accuracy: 0.2309\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 2.0900 - accuracy: 0.2360 - val_loss: 2.1313 - val_accuracy: 0.2384\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 2.0904 - accuracy: 0.2362 - val_loss: 2.0719 - val_accuracy: 0.2474\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 2.0683 - accuracy: 0.2481 - val_loss: 2.1379 - val_accuracy: 0.2456\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 2.0632 - accuracy: 0.2475 - val_loss: 2.1115 - val_accuracy: 0.2325\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 2.0558 - accuracy: 0.2528 - val_loss: 2.0591 - val_accuracy: 0.2661\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 2.0526 - accuracy: 0.2501 - val_loss: 2.1651 - val_accuracy: 0.2245\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 38s 487ms/step - loss: 2.0445 - accuracy: 0.2573 - val_loss: 2.1313 - val_accuracy: 0.2231\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 2.0302 - accuracy: 0.2609 - val_loss: 2.1219 - val_accuracy: 0.2414\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 2.0305 - accuracy: 0.2599 - val_loss: 2.0874 - val_accuracy: 0.2365\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 2.0152 - accuracy: 0.2659 - val_loss: 2.0380 - val_accuracy: 0.2573\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 2.0070 - accuracy: 0.2706 - val_loss: 2.0611 - val_accuracy: 0.2418\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 2.0113 - accuracy: 0.2687 - val_loss: 2.0482 - val_accuracy: 0.2542\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 2.0014 - accuracy: 0.2722 - val_loss: 2.0695 - val_accuracy: 0.2467\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.9921 - accuracy: 0.2754 - val_loss: 2.0234 - val_accuracy: 0.2722\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.9899 - accuracy: 0.2789 - val_loss: 2.0153 - val_accuracy: 0.2617\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.9781 - accuracy: 0.2839 - val_loss: 1.9840 - val_accuracy: 0.2803\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.9642 - accuracy: 0.2866 - val_loss: 2.0010 - val_accuracy: 0.2649\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.9647 - accuracy: 0.2871 - val_loss: 1.9569 - val_accuracy: 0.2897\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.9548 - accuracy: 0.2912 - val_loss: 2.0376 - val_accuracy: 0.2564\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.9413 - accuracy: 0.2983 - val_loss: 1.9761 - val_accuracy: 0.2824\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.9261 - accuracy: 0.3031 - val_loss: 1.9410 - val_accuracy: 0.3014\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.9280 - accuracy: 0.3058 - val_loss: 1.9599 - val_accuracy: 0.2963\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.9206 - accuracy: 0.3061 - val_loss: 1.9360 - val_accuracy: 0.3029\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.9028 - accuracy: 0.3120 - val_loss: 1.9300 - val_accuracy: 0.3042\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 38s 487ms/step - loss: 1.8986 - accuracy: 0.3161 - val_loss: 1.9421 - val_accuracy: 0.2949\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.8960 - accuracy: 0.3151 - val_loss: 1.9113 - val_accuracy: 0.3068\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.8793 - accuracy: 0.3243 - val_loss: 1.8957 - val_accuracy: 0.3151\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.8739 - accuracy: 0.3222 - val_loss: 1.8860 - val_accuracy: 0.3230\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.8587 - accuracy: 0.3331 - val_loss: 1.9426 - val_accuracy: 0.2973\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.8576 - accuracy: 0.3318 - val_loss: 1.8944 - val_accuracy: 0.3184\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 38s 487ms/step - loss: 1.8501 - accuracy: 0.3358 - val_loss: 1.8774 - val_accuracy: 0.3238\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.8351 - accuracy: 0.3424 - val_loss: 1.8513 - val_accuracy: 0.3384\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 41s 514ms/step - loss: 1.8232 - accuracy: 0.3454 - val_loss: 1.8227 - val_accuracy: 0.3455\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.8187 - accuracy: 0.3472 - val_loss: 1.8385 - val_accuracy: 0.3455\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.8036 - accuracy: 0.3517 - val_loss: 1.8084 - val_accuracy: 0.3577\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.8095 - accuracy: 0.3507 - val_loss: 1.8331 - val_accuracy: 0.3437\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.8006 - accuracy: 0.3541 - val_loss: 1.7787 - val_accuracy: 0.3679\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.7806 - accuracy: 0.3607 - val_loss: 1.8339 - val_accuracy: 0.3495\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.7851 - accuracy: 0.3628 - val_loss: 1.8017 - val_accuracy: 0.3544\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.7789 - accuracy: 0.3638 - val_loss: 1.8331 - val_accuracy: 0.3315\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 1.7722 - accuracy: 0.3647 - val_loss: 1.7771 - val_accuracy: 0.3642\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.7633 - accuracy: 0.3692 - val_loss: 1.8186 - val_accuracy: 0.3565\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 1.7506 - accuracy: 0.3735 - val_loss: 1.8041 - val_accuracy: 0.3594\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.7491 - accuracy: 0.3752 - val_loss: 1.7744 - val_accuracy: 0.3631\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.7431 - accuracy: 0.3753 - val_loss: 1.8299 - val_accuracy: 0.3497\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.7394 - accuracy: 0.3796 - val_loss: 1.7524 - val_accuracy: 0.3714\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.7290 - accuracy: 0.3837 - val_loss: 1.7124 - val_accuracy: 0.3854\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.7158 - accuracy: 0.3873 - val_loss: 1.7625 - val_accuracy: 0.3700\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.7172 - accuracy: 0.3901 - val_loss: 1.7100 - val_accuracy: 0.3814\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.6930 - accuracy: 0.3966 - val_loss: 1.7804 - val_accuracy: 0.3580\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.7028 - accuracy: 0.3940 - val_loss: 1.6898 - val_accuracy: 0.3974\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 41s 514ms/step - loss: 1.6908 - accuracy: 0.3978 - val_loss: 1.7166 - val_accuracy: 0.3929\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.6900 - accuracy: 0.3950 - val_loss: 1.7893 - val_accuracy: 0.3682\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 41s 518ms/step - loss: 1.6893 - accuracy: 0.3988 - val_loss: 1.7595 - val_accuracy: 0.3762\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.6911 - accuracy: 0.3977 - val_loss: 1.7259 - val_accuracy: 0.3995\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.6766 - accuracy: 0.4036 - val_loss: 1.7104 - val_accuracy: 0.3989\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 41s 518ms/step - loss: 1.6704 - accuracy: 0.4045 - val_loss: 1.7355 - val_accuracy: 0.3785\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.6722 - accuracy: 0.4051 - val_loss: 1.7107 - val_accuracy: 0.3922\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 43s 546ms/step - loss: 1.6608 - accuracy: 0.4096 - val_loss: 1.7167 - val_accuracy: 0.3892\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.6622 - accuracy: 0.4098 - val_loss: 1.7446 - val_accuracy: 0.3829\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.6478 - accuracy: 0.4112 - val_loss: 1.7035 - val_accuracy: 0.3925\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.6506 - accuracy: 0.4140 - val_loss: 1.6956 - val_accuracy: 0.4000\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.6430 - accuracy: 0.4138 - val_loss: 1.7351 - val_accuracy: 0.3976\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.6356 - accuracy: 0.4173 - val_loss: 1.6908 - val_accuracy: 0.4010\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.6341 - accuracy: 0.4172 - val_loss: 1.6822 - val_accuracy: 0.4096\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.6376 - accuracy: 0.4177 - val_loss: 1.7282 - val_accuracy: 0.3906\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 1.6327 - accuracy: 0.4205 - val_loss: 1.7182 - val_accuracy: 0.3931\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.6310 - accuracy: 0.4195 - val_loss: 1.6915 - val_accuracy: 0.4053\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.6205 - accuracy: 0.4204 - val_loss: 1.6520 - val_accuracy: 0.4227\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.6236 - accuracy: 0.4236 - val_loss: 1.6163 - val_accuracy: 0.4316\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 39s 488ms/step - loss: 1.6077 - accuracy: 0.4288 - val_loss: 1.7023 - val_accuracy: 0.3998\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.6257 - accuracy: 0.4200 - val_loss: 1.6191 - val_accuracy: 0.4362\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 40s 504ms/step - loss: 1.6095 - accuracy: 0.4279 - val_loss: 1.6476 - val_accuracy: 0.4197\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.6053 - accuracy: 0.4286 - val_loss: 1.6154 - val_accuracy: 0.4318\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.5998 - accuracy: 0.4319 - val_loss: 1.6582 - val_accuracy: 0.4097\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.6037 - accuracy: 0.4290 - val_loss: 1.6645 - val_accuracy: 0.4216\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.5880 - accuracy: 0.4344 - val_loss: 1.6165 - val_accuracy: 0.4284\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.5893 - accuracy: 0.4369 - val_loss: 1.6383 - val_accuracy: 0.4294\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.5813 - accuracy: 0.4387 - val_loss: 1.7113 - val_accuracy: 0.3969\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.5821 - accuracy: 0.4382 - val_loss: 1.6170 - val_accuracy: 0.4355\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.5840 - accuracy: 0.4378 - val_loss: 1.6072 - val_accuracy: 0.4329\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5831 - accuracy: 0.4410 - val_loss: 1.6176 - val_accuracy: 0.4288\n",
      "Epoch 00097: early stopping\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.5873 - accuracy: 0.4401\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6191 - accuracy: 0.4362\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6028 - accuracy: 0.4312\n",
      "Train accuracy: 0.4401249885559082\n",
      "Validation accuracy: 0.43619999289512634\n",
      "Test accuracy: 0.4311999976634979\n",
      "big_grid_model_42\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 13)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 13)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        3776      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,072,266\n",
      "Trainable params: 1,072,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 42s 525ms/step - loss: 10.1603 - accuracy: 0.1188 - val_loss: 2.3185 - val_accuracy: 0.0993\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 42s 528ms/step - loss: 2.2478 - accuracy: 0.1515 - val_loss: 2.2907 - val_accuracy: 0.1265\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 42s 532ms/step - loss: 2.2184 - accuracy: 0.1757 - val_loss: 2.2045 - val_accuracy: 0.1895\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 42s 534ms/step - loss: 2.1930 - accuracy: 0.1864 - val_loss: 2.1860 - val_accuracy: 0.2025\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 2.1736 - accuracy: 0.1976 - val_loss: 2.1992 - val_accuracy: 0.1976\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 2.1624 - accuracy: 0.2033 - val_loss: 2.1731 - val_accuracy: 0.2071\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 2.1530 - accuracy: 0.2097 - val_loss: 2.1804 - val_accuracy: 0.1930\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 2.1354 - accuracy: 0.2158 - val_loss: 2.1553 - val_accuracy: 0.2168\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 2.1276 - accuracy: 0.2207 - val_loss: 2.1457 - val_accuracy: 0.2173\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 2.1199 - accuracy: 0.2229 - val_loss: 2.2221 - val_accuracy: 0.1844\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 2.1124 - accuracy: 0.2271 - val_loss: 2.1062 - val_accuracy: 0.2340\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 2.0894 - accuracy: 0.2348 - val_loss: 2.1201 - val_accuracy: 0.2281\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 2.0862 - accuracy: 0.2373 - val_loss: 2.1133 - val_accuracy: 0.2222\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 2.0750 - accuracy: 0.2429 - val_loss: 2.0780 - val_accuracy: 0.2502\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 2.0611 - accuracy: 0.2477 - val_loss: 2.0902 - val_accuracy: 0.2438\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 2.0455 - accuracy: 0.2550 - val_loss: 2.1392 - val_accuracy: 0.2443\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 2.0502 - accuracy: 0.2517 - val_loss: 2.1120 - val_accuracy: 0.2464\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 42s 536ms/step - loss: 2.0372 - accuracy: 0.2578 - val_loss: 2.0855 - val_accuracy: 0.2503\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 42s 529ms/step - loss: 2.0197 - accuracy: 0.2612 - val_loss: 2.0156 - val_accuracy: 0.2709\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 2.0189 - accuracy: 0.2663 - val_loss: 2.0875 - val_accuracy: 0.2531\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 42s 528ms/step - loss: 2.0179 - accuracy: 0.2637 - val_loss: 2.0251 - val_accuracy: 0.2663\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 43s 538ms/step - loss: 2.0049 - accuracy: 0.2732 - val_loss: 2.0674 - val_accuracy: 0.2570\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 42s 528ms/step - loss: 1.9927 - accuracy: 0.2786 - val_loss: 1.9707 - val_accuracy: 0.2925\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 1.9851 - accuracy: 0.2788 - val_loss: 2.0858 - val_accuracy: 0.2503\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 1.9838 - accuracy: 0.2785 - val_loss: 2.0009 - val_accuracy: 0.2711\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.9747 - accuracy: 0.2815 - val_loss: 1.9598 - val_accuracy: 0.2919\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 42s 529ms/step - loss: 1.9791 - accuracy: 0.2844 - val_loss: 1.9997 - val_accuracy: 0.2786\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 1.9621 - accuracy: 0.2889 - val_loss: 2.0116 - val_accuracy: 0.2772\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 1.9611 - accuracy: 0.2876 - val_loss: 1.9783 - val_accuracy: 0.2865\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 42s 536ms/step - loss: 1.9465 - accuracy: 0.2963 - val_loss: 1.9592 - val_accuracy: 0.2915\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 1.9471 - accuracy: 0.2963 - val_loss: 1.9669 - val_accuracy: 0.2928\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 42s 537ms/step - loss: 1.9340 - accuracy: 0.3004 - val_loss: 1.9482 - val_accuracy: 0.3007\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.9199 - accuracy: 0.3081 - val_loss: 1.9297 - val_accuracy: 0.3095\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.9098 - accuracy: 0.3105 - val_loss: 1.9441 - val_accuracy: 0.3042\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 42s 528ms/step - loss: 1.9129 - accuracy: 0.3098 - val_loss: 1.9544 - val_accuracy: 0.2930\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 42s 532ms/step - loss: 1.9008 - accuracy: 0.3144 - val_loss: 1.8878 - val_accuracy: 0.3209\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 41s 513ms/step - loss: 1.8898 - accuracy: 0.3189 - val_loss: 1.8602 - val_accuracy: 0.3306\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.8832 - accuracy: 0.3247 - val_loss: 1.8650 - val_accuracy: 0.3239\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.8722 - accuracy: 0.3273 - val_loss: 1.8435 - val_accuracy: 0.3400\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.8549 - accuracy: 0.3321 - val_loss: 1.8432 - val_accuracy: 0.3308\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 1.8400 - accuracy: 0.3417 - val_loss: 1.8703 - val_accuracy: 0.3303\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.8517 - accuracy: 0.3326 - val_loss: 1.8336 - val_accuracy: 0.3427\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.8236 - accuracy: 0.3431 - val_loss: 1.8304 - val_accuracy: 0.3454\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 1.8241 - accuracy: 0.3460 - val_loss: 1.7783 - val_accuracy: 0.3618\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.8126 - accuracy: 0.3489 - val_loss: 1.8439 - val_accuracy: 0.3392\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 41s 513ms/step - loss: 1.8016 - accuracy: 0.3554 - val_loss: 1.8841 - val_accuracy: 0.3240\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 1.7934 - accuracy: 0.3576 - val_loss: 1.7478 - val_accuracy: 0.3746\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 39s 500ms/step - loss: 1.7774 - accuracy: 0.3627 - val_loss: 1.7966 - val_accuracy: 0.3545\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.7782 - accuracy: 0.3622 - val_loss: 1.7934 - val_accuracy: 0.3588\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.7715 - accuracy: 0.3657 - val_loss: 1.7768 - val_accuracy: 0.3676\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 39s 500ms/step - loss: 1.7533 - accuracy: 0.3737 - val_loss: 1.7958 - val_accuracy: 0.3564\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.7378 - accuracy: 0.3790 - val_loss: 1.7416 - val_accuracy: 0.3799\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.7405 - accuracy: 0.3783 - val_loss: 1.6990 - val_accuracy: 0.3970\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 40s 500ms/step - loss: 1.7402 - accuracy: 0.3793 - val_loss: 1.7655 - val_accuracy: 0.3756\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.7251 - accuracy: 0.3803 - val_loss: 1.7313 - val_accuracy: 0.3845\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 1.7232 - accuracy: 0.3845 - val_loss: 1.7148 - val_accuracy: 0.3903\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.6953 - accuracy: 0.3931 - val_loss: 1.7000 - val_accuracy: 0.3935\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.7060 - accuracy: 0.3881 - val_loss: 1.6953 - val_accuracy: 0.4017\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.6918 - accuracy: 0.3945 - val_loss: 1.6802 - val_accuracy: 0.3991\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 1.6826 - accuracy: 0.3990 - val_loss: 1.6391 - val_accuracy: 0.4195\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.6907 - accuracy: 0.3941 - val_loss: 1.6814 - val_accuracy: 0.4018\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 1.6752 - accuracy: 0.4006 - val_loss: 1.6799 - val_accuracy: 0.4047\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.6583 - accuracy: 0.4083 - val_loss: 1.6610 - val_accuracy: 0.4123\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.6593 - accuracy: 0.4069 - val_loss: 1.6601 - val_accuracy: 0.4178\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.6560 - accuracy: 0.4090 - val_loss: 1.6535 - val_accuracy: 0.4169\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.6388 - accuracy: 0.4174 - val_loss: 1.6726 - val_accuracy: 0.4080\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.6351 - accuracy: 0.4175 - val_loss: 1.7195 - val_accuracy: 0.4028\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 39s 500ms/step - loss: 1.6458 - accuracy: 0.4143 - val_loss: 1.6076 - val_accuracy: 0.4308\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.6257 - accuracy: 0.4203 - val_loss: 1.6187 - val_accuracy: 0.4359\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.6178 - accuracy: 0.4238 - val_loss: 1.6939 - val_accuracy: 0.4115\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 1.6108 - accuracy: 0.4267 - val_loss: 1.6451 - val_accuracy: 0.4217\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.6035 - accuracy: 0.4282 - val_loss: 1.6210 - val_accuracy: 0.4306\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.6172 - accuracy: 0.4209 - val_loss: 1.5893 - val_accuracy: 0.4420\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.6089 - accuracy: 0.4272 - val_loss: 1.6488 - val_accuracy: 0.4183\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.5914 - accuracy: 0.4345 - val_loss: 1.6283 - val_accuracy: 0.4312\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 40s 506ms/step - loss: 1.5843 - accuracy: 0.4390 - val_loss: 1.6354 - val_accuracy: 0.4260\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 40s 506ms/step - loss: 1.5850 - accuracy: 0.4365 - val_loss: 1.5430 - val_accuracy: 0.4547\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 1.5910 - accuracy: 0.4369 - val_loss: 1.5696 - val_accuracy: 0.4485\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 40s 507ms/step - loss: 1.5725 - accuracy: 0.4420 - val_loss: 1.6108 - val_accuracy: 0.4323\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.5725 - accuracy: 0.4416 - val_loss: 1.5089 - val_accuracy: 0.4687\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.5687 - accuracy: 0.4415 - val_loss: 1.5704 - val_accuracy: 0.4496\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.5586 - accuracy: 0.4464 - val_loss: 1.5321 - val_accuracy: 0.4663\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.5651 - accuracy: 0.4445 - val_loss: 1.5538 - val_accuracy: 0.4601\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.5541 - accuracy: 0.4494 - val_loss: 1.5342 - val_accuracy: 0.4686\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.5476 - accuracy: 0.4487 - val_loss: 1.5375 - val_accuracy: 0.4636\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.5488 - accuracy: 0.4522 - val_loss: 1.5207 - val_accuracy: 0.4727\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.5401 - accuracy: 0.4518 - val_loss: 1.5522 - val_accuracy: 0.4558\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 40s 507ms/step - loss: 1.5348 - accuracy: 0.4555 - val_loss: 1.5488 - val_accuracy: 0.4543\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 1.5301 - accuracy: 0.4598 - val_loss: 1.5146 - val_accuracy: 0.4727\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.5197 - accuracy: 0.4598 - val_loss: 1.4906 - val_accuracy: 0.4856\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.5376 - accuracy: 0.4538 - val_loss: 1.5647 - val_accuracy: 0.4544\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 1.5295 - accuracy: 0.4584 - val_loss: 1.5357 - val_accuracy: 0.4583\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 39s 500ms/step - loss: 1.5230 - accuracy: 0.4600 - val_loss: 1.5074 - val_accuracy: 0.4729\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.5203 - accuracy: 0.4608 - val_loss: 1.5363 - val_accuracy: 0.4642\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.5164 - accuracy: 0.4615 - val_loss: 1.4930 - val_accuracy: 0.4755\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 40s 500ms/step - loss: 1.5092 - accuracy: 0.4676 - val_loss: 1.4950 - val_accuracy: 0.4784\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.5025 - accuracy: 0.4672 - val_loss: 1.4896 - val_accuracy: 0.4765\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.5138 - accuracy: 0.4624 - val_loss: 1.4716 - val_accuracy: 0.4909\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.5052 - accuracy: 0.4636 - val_loss: 1.5236 - val_accuracy: 0.4754\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.4921 - accuracy: 0.4722 - val_loss: 1.5083 - val_accuracy: 0.4803\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.4291 - accuracy: 0.4940\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4716 - accuracy: 0.4909\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4477 - accuracy: 0.4950\n",
      "Train accuracy: 0.49399998784065247\n",
      "Validation accuracy: 0.4909000098705292\n",
      "Test accuracy: 0.4950000047683716\n",
      "big_grid_model_43\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 13)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 13)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        3776      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,122,250\n",
      "Trainable params: 2,122,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 39s 500ms/step - loss: 11.9318 - accuracy: 0.1210 - val_loss: 2.2812 - val_accuracy: 0.1422\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 40s 508ms/step - loss: 2.2555 - accuracy: 0.1504 - val_loss: 2.2428 - val_accuracy: 0.1608\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 2.2216 - accuracy: 0.1714 - val_loss: 2.2263 - val_accuracy: 0.1722\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 2.2052 - accuracy: 0.1782 - val_loss: 2.1939 - val_accuracy: 0.1861\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 39s 500ms/step - loss: 2.1902 - accuracy: 0.1906 - val_loss: 2.1842 - val_accuracy: 0.1930\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 2.1786 - accuracy: 0.1948 - val_loss: 2.2088 - val_accuracy: 0.1957\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 2.1700 - accuracy: 0.2026 - val_loss: 2.1718 - val_accuracy: 0.2191\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 2.1509 - accuracy: 0.2106 - val_loss: 2.1502 - val_accuracy: 0.2281\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 2.1485 - accuracy: 0.2118 - val_loss: 2.1212 - val_accuracy: 0.2367\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 2.1252 - accuracy: 0.2221 - val_loss: 2.0827 - val_accuracy: 0.2425\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 2.1011 - accuracy: 0.2329 - val_loss: 2.1006 - val_accuracy: 0.2357\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 2.1018 - accuracy: 0.2302 - val_loss: 2.0652 - val_accuracy: 0.2592\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 2.0818 - accuracy: 0.2401 - val_loss: 2.0659 - val_accuracy: 0.2554\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 2.0590 - accuracy: 0.2471 - val_loss: 2.1742 - val_accuracy: 0.2258\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 2.0384 - accuracy: 0.2564 - val_loss: 2.0169 - val_accuracy: 0.2673\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 2.0264 - accuracy: 0.2600 - val_loss: 2.0289 - val_accuracy: 0.2610\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 2.0299 - accuracy: 0.2604 - val_loss: 2.0415 - val_accuracy: 0.2531\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 40s 500ms/step - loss: 2.0048 - accuracy: 0.2693 - val_loss: 1.9916 - val_accuracy: 0.2828\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 2.0028 - accuracy: 0.2752 - val_loss: 1.9771 - val_accuracy: 0.2837\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.9836 - accuracy: 0.2786 - val_loss: 1.9667 - val_accuracy: 0.2940\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.9956 - accuracy: 0.2779 - val_loss: 1.9593 - val_accuracy: 0.3049\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.9629 - accuracy: 0.2902 - val_loss: 1.9780 - val_accuracy: 0.2835\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.9559 - accuracy: 0.2909 - val_loss: 1.9233 - val_accuracy: 0.3054\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.9395 - accuracy: 0.3015 - val_loss: 1.9481 - val_accuracy: 0.2998\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 39s 491ms/step - loss: 1.9233 - accuracy: 0.3067 - val_loss: 1.9230 - val_accuracy: 0.3080\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 39s 500ms/step - loss: 1.9254 - accuracy: 0.3075 - val_loss: 2.0044 - val_accuracy: 0.2811\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 40s 500ms/step - loss: 1.9070 - accuracy: 0.3127 - val_loss: 1.8916 - val_accuracy: 0.3237\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.8752 - accuracy: 0.3263 - val_loss: 1.9229 - val_accuracy: 0.3159\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.8727 - accuracy: 0.3287 - val_loss: 1.8614 - val_accuracy: 0.3430\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.8530 - accuracy: 0.3331 - val_loss: 1.8714 - val_accuracy: 0.3362\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.8253 - accuracy: 0.3445 - val_loss: 1.9147 - val_accuracy: 0.3173\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.8224 - accuracy: 0.3471 - val_loss: 1.8283 - val_accuracy: 0.3602\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.8027 - accuracy: 0.3544 - val_loss: 1.8713 - val_accuracy: 0.3382\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 1.7829 - accuracy: 0.3634 - val_loss: 1.8042 - val_accuracy: 0.3646\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 40s 512ms/step - loss: 1.7847 - accuracy: 0.3622 - val_loss: 1.8442 - val_accuracy: 0.3432\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.7657 - accuracy: 0.3698 - val_loss: 1.8379 - val_accuracy: 0.3467\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.7533 - accuracy: 0.3731 - val_loss: 1.8502 - val_accuracy: 0.3460\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.7473 - accuracy: 0.3783 - val_loss: 1.7576 - val_accuracy: 0.3758\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.7362 - accuracy: 0.3805 - val_loss: 1.7817 - val_accuracy: 0.3650\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 1.7178 - accuracy: 0.3884 - val_loss: 1.7868 - val_accuracy: 0.3549\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.7172 - accuracy: 0.3930 - val_loss: 1.7672 - val_accuracy: 0.3790\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 1.7211 - accuracy: 0.3881 - val_loss: 1.7274 - val_accuracy: 0.3836\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.6964 - accuracy: 0.3941 - val_loss: 1.7403 - val_accuracy: 0.3759\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.6946 - accuracy: 0.3947 - val_loss: 1.7096 - val_accuracy: 0.3883\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.6879 - accuracy: 0.3957 - val_loss: 1.7218 - val_accuracy: 0.3865\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.6702 - accuracy: 0.4047 - val_loss: 1.8006 - val_accuracy: 0.3687\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.6793 - accuracy: 0.4008 - val_loss: 1.7037 - val_accuracy: 0.4011\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.6650 - accuracy: 0.4079 - val_loss: 1.7512 - val_accuracy: 0.3794\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 39s 500ms/step - loss: 1.6460 - accuracy: 0.4146 - val_loss: 1.6532 - val_accuracy: 0.4172\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 1.6543 - accuracy: 0.4141 - val_loss: 1.6468 - val_accuracy: 0.4254\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.6375 - accuracy: 0.4152 - val_loss: 1.6325 - val_accuracy: 0.4239\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.6433 - accuracy: 0.4170 - val_loss: 1.6331 - val_accuracy: 0.4152\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.6145 - accuracy: 0.4270 - val_loss: 1.5675 - val_accuracy: 0.4510\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.6152 - accuracy: 0.4261 - val_loss: 1.5997 - val_accuracy: 0.4363\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.6106 - accuracy: 0.4293 - val_loss: 1.6319 - val_accuracy: 0.4264\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.6080 - accuracy: 0.4258 - val_loss: 1.6667 - val_accuracy: 0.4046\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.5995 - accuracy: 0.4347 - val_loss: 1.5930 - val_accuracy: 0.4353\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.5967 - accuracy: 0.4349 - val_loss: 1.6801 - val_accuracy: 0.4026\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.5896 - accuracy: 0.4380 - val_loss: 1.5694 - val_accuracy: 0.4438\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 1.5870 - accuracy: 0.4374 - val_loss: 1.5693 - val_accuracy: 0.4410\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.5763 - accuracy: 0.4400 - val_loss: 1.5033 - val_accuracy: 0.4753\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.5889 - accuracy: 0.4370 - val_loss: 1.5300 - val_accuracy: 0.4596\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.5675 - accuracy: 0.4442 - val_loss: 1.6062 - val_accuracy: 0.4374\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.5603 - accuracy: 0.4473 - val_loss: 1.5733 - val_accuracy: 0.4489\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 1.5687 - accuracy: 0.4422 - val_loss: 1.5375 - val_accuracy: 0.4639\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.5548 - accuracy: 0.4475 - val_loss: 1.5009 - val_accuracy: 0.4662\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.5456 - accuracy: 0.4511 - val_loss: 1.5129 - val_accuracy: 0.4640\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 1.5400 - accuracy: 0.4543 - val_loss: 1.5736 - val_accuracy: 0.4512\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 1.5360 - accuracy: 0.4549 - val_loss: 1.5290 - val_accuracy: 0.4647\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 1.5397 - accuracy: 0.4527 - val_loss: 1.5659 - val_accuracy: 0.4498\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.5317 - accuracy: 0.4523 - val_loss: 1.5352 - val_accuracy: 0.4621\n",
      "Epoch 00071: early stopping\n",
      "   1/1250 [..............................] - ETA: 1s - loss: 1.5926 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0020s). Check your callbacks.\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.4618 - accuracy: 0.4807\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5033 - accuracy: 0.4753\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4724 - accuracy: 0.4803\n",
      "Train accuracy: 0.4807499945163727\n",
      "Validation accuracy: 0.47530001401901245\n",
      "Test accuracy: 0.48030000925064087\n",
      "big_grid_model_44\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 13)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 13)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        1888      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 532,234\n",
      "Trainable params: 532,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 7.1029 - accuracy: 0.1250 - val_loss: 2.2615 - val_accuracy: 0.1577\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 42s 529ms/step - loss: 2.2478 - accuracy: 0.1681 - val_loss: 2.2023 - val_accuracy: 0.1773\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 2.2065 - accuracy: 0.1789 - val_loss: 2.1703 - val_accuracy: 0.1875\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 2.1663 - accuracy: 0.1950 - val_loss: 2.1440 - val_accuracy: 0.2009\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 42s 529ms/step - loss: 2.1304 - accuracy: 0.2104 - val_loss: 2.1137 - val_accuracy: 0.2155\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 2.1108 - accuracy: 0.2206 - val_loss: 2.0935 - val_accuracy: 0.2197\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 2.0946 - accuracy: 0.2256 - val_loss: 2.0836 - val_accuracy: 0.2277\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 2.0793 - accuracy: 0.2305 - val_loss: 2.0876 - val_accuracy: 0.2278\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 2.0746 - accuracy: 0.2343 - val_loss: 2.0821 - val_accuracy: 0.2289\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 2.0721 - accuracy: 0.2351 - val_loss: 2.0884 - val_accuracy: 0.2287\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 2.0584 - accuracy: 0.2421 - val_loss: 2.0585 - val_accuracy: 0.2438\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 2.0550 - accuracy: 0.2438 - val_loss: 2.0518 - val_accuracy: 0.2429\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 2.0449 - accuracy: 0.2478 - val_loss: 2.0692 - val_accuracy: 0.2340\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 2.0417 - accuracy: 0.2494 - val_loss: 2.0707 - val_accuracy: 0.2429\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 2.0265 - accuracy: 0.2560 - val_loss: 2.0666 - val_accuracy: 0.2398\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 2.0245 - accuracy: 0.2603 - val_loss: 2.0460 - val_accuracy: 0.2423\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 2.0200 - accuracy: 0.2613 - val_loss: 2.0337 - val_accuracy: 0.2487\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 2.0125 - accuracy: 0.2652 - val_loss: 2.0261 - val_accuracy: 0.2597\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 2.0048 - accuracy: 0.2688 - val_loss: 2.0337 - val_accuracy: 0.2663\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 42s 529ms/step - loss: 2.0020 - accuracy: 0.2705 - val_loss: 2.0221 - val_accuracy: 0.2597\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.9939 - accuracy: 0.2745 - val_loss: 2.0141 - val_accuracy: 0.2657\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.9919 - accuracy: 0.2753 - val_loss: 2.0074 - val_accuracy: 0.2658\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.9808 - accuracy: 0.2839 - val_loss: 1.9948 - val_accuracy: 0.2735\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.9817 - accuracy: 0.2809 - val_loss: 1.9837 - val_accuracy: 0.2794\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.9715 - accuracy: 0.2892 - val_loss: 1.9822 - val_accuracy: 0.2831\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 42s 529ms/step - loss: 1.9699 - accuracy: 0.2873 - val_loss: 1.9934 - val_accuracy: 0.2746\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 41s 518ms/step - loss: 1.9666 - accuracy: 0.2895 - val_loss: 1.9840 - val_accuracy: 0.2859\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.9659 - accuracy: 0.2875 - val_loss: 1.9613 - val_accuracy: 0.2860\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.9509 - accuracy: 0.2924 - val_loss: 1.9751 - val_accuracy: 0.2826\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.9502 - accuracy: 0.2972 - val_loss: 1.9797 - val_accuracy: 0.2850\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.9478 - accuracy: 0.2967 - val_loss: 1.9908 - val_accuracy: 0.2755\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.9416 - accuracy: 0.2995 - val_loss: 1.9833 - val_accuracy: 0.2763\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 42s 528ms/step - loss: 1.9526 - accuracy: 0.2943 - val_loss: 1.9442 - val_accuracy: 0.2934\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 43s 539ms/step - loss: 1.9377 - accuracy: 0.3038 - val_loss: 1.9398 - val_accuracy: 0.2978\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 42s 528ms/step - loss: 1.9311 - accuracy: 0.3058 - val_loss: 1.9353 - val_accuracy: 0.3025\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.9286 - accuracy: 0.3067 - val_loss: 1.9669 - val_accuracy: 0.2905\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 42s 525ms/step - loss: 1.9280 - accuracy: 0.3054 - val_loss: 1.9365 - val_accuracy: 0.2967\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.9176 - accuracy: 0.3085 - val_loss: 1.9227 - val_accuracy: 0.3007\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.9275 - accuracy: 0.3049 - val_loss: 1.9463 - val_accuracy: 0.2890\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.9141 - accuracy: 0.3142 - val_loss: 1.9331 - val_accuracy: 0.3018\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 1.9131 - accuracy: 0.3101 - val_loss: 1.9276 - val_accuracy: 0.2991\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 42s 528ms/step - loss: 1.9046 - accuracy: 0.3134 - val_loss: 1.9145 - val_accuracy: 0.3047\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.8982 - accuracy: 0.3165 - val_loss: 1.9203 - val_accuracy: 0.3009\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 41s 518ms/step - loss: 1.8974 - accuracy: 0.3146 - val_loss: 1.9152 - val_accuracy: 0.2970\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.9103 - accuracy: 0.3121 - val_loss: 1.9110 - val_accuracy: 0.3102\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.8921 - accuracy: 0.3184 - val_loss: 1.9212 - val_accuracy: 0.3044\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 42s 529ms/step - loss: 1.8857 - accuracy: 0.3233 - val_loss: 1.9346 - val_accuracy: 0.2985\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 1.8787 - accuracy: 0.3223 - val_loss: 1.9022 - val_accuracy: 0.3118\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 42s 532ms/step - loss: 1.8837 - accuracy: 0.3238 - val_loss: 1.8825 - val_accuracy: 0.3189\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.8727 - accuracy: 0.3268 - val_loss: 1.8971 - val_accuracy: 0.3110\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.8708 - accuracy: 0.3271 - val_loss: 1.9026 - val_accuracy: 0.2972\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.8665 - accuracy: 0.3268 - val_loss: 1.8708 - val_accuracy: 0.3222\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.8672 - accuracy: 0.3272 - val_loss: 1.8749 - val_accuracy: 0.3214\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.8543 - accuracy: 0.3301 - val_loss: 1.8944 - val_accuracy: 0.3142\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 42s 525ms/step - loss: 1.8659 - accuracy: 0.3277 - val_loss: 1.8892 - val_accuracy: 0.3190\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.8575 - accuracy: 0.3338 - val_loss: 1.9065 - val_accuracy: 0.3097\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 1.8624 - accuracy: 0.3269 - val_loss: 1.8637 - val_accuracy: 0.3309\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.8427 - accuracy: 0.3383 - val_loss: 1.8985 - val_accuracy: 0.3205\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.8389 - accuracy: 0.3373 - val_loss: 1.8727 - val_accuracy: 0.3306\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.8378 - accuracy: 0.3399 - val_loss: 1.8429 - val_accuracy: 0.3385\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.8376 - accuracy: 0.3429 - val_loss: 1.8683 - val_accuracy: 0.3304\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 42s 533ms/step - loss: 1.8282 - accuracy: 0.3447 - val_loss: 1.8660 - val_accuracy: 0.3299\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.8317 - accuracy: 0.3420 - val_loss: 1.8770 - val_accuracy: 0.3328\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.8340 - accuracy: 0.3419 - val_loss: 1.8158 - val_accuracy: 0.3469\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 42s 532ms/step - loss: 1.8214 - accuracy: 0.3449 - val_loss: 1.8548 - val_accuracy: 0.3393\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.8113 - accuracy: 0.3516 - val_loss: 1.8727 - val_accuracy: 0.3331\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.8042 - accuracy: 0.3502 - val_loss: 1.8693 - val_accuracy: 0.3337\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.8121 - accuracy: 0.3519 - val_loss: 1.8733 - val_accuracy: 0.3307\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 1.7954 - accuracy: 0.3577 - val_loss: 1.8166 - val_accuracy: 0.3589\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.8043 - accuracy: 0.3507 - val_loss: 1.8607 - val_accuracy: 0.3335\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 1.8033 - accuracy: 0.3523 - val_loss: 1.8253 - val_accuracy: 0.3499\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.7803 - accuracy: 0.3628 - val_loss: 1.9140 - val_accuracy: 0.3215\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 42s 528ms/step - loss: 1.7861 - accuracy: 0.3579 - val_loss: 1.8482 - val_accuracy: 0.3428\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.7836 - accuracy: 0.3622 - val_loss: 1.8261 - val_accuracy: 0.3423\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.7777 - accuracy: 0.3625 - val_loss: 1.7759 - val_accuracy: 0.3697\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 1.7791 - accuracy: 0.3604 - val_loss: 1.7764 - val_accuracy: 0.3654\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 42s 529ms/step - loss: 1.7641 - accuracy: 0.3700 - val_loss: 1.8260 - val_accuracy: 0.3550\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.7548 - accuracy: 0.3703 - val_loss: 1.8329 - val_accuracy: 0.3504\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.7627 - accuracy: 0.3676 - val_loss: 1.7895 - val_accuracy: 0.3576\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.7582 - accuracy: 0.3692 - val_loss: 1.7387 - val_accuracy: 0.3794\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 42s 532ms/step - loss: 1.7510 - accuracy: 0.3733 - val_loss: 1.7438 - val_accuracy: 0.3777\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.7262 - accuracy: 0.3799 - val_loss: 1.7178 - val_accuracy: 0.3911\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.7414 - accuracy: 0.3758 - val_loss: 1.7592 - val_accuracy: 0.3740\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.7381 - accuracy: 0.3796 - val_loss: 1.7333 - val_accuracy: 0.3843\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 1.7236 - accuracy: 0.3833 - val_loss: 1.7238 - val_accuracy: 0.3976\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.7108 - accuracy: 0.3869 - val_loss: 1.7166 - val_accuracy: 0.3904\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.7013 - accuracy: 0.3889 - val_loss: 1.7899 - val_accuracy: 0.3611\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 1.6933 - accuracy: 0.3976 - val_loss: 1.7208 - val_accuracy: 0.3920\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.6939 - accuracy: 0.3945 - val_loss: 1.7396 - val_accuracy: 0.3855\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 40s 512ms/step - loss: 1.6942 - accuracy: 0.3916 - val_loss: 1.6410 - val_accuracy: 0.4174\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 40s 507ms/step - loss: 1.6939 - accuracy: 0.3952 - val_loss: 1.7182 - val_accuracy: 0.3930\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 40s 512ms/step - loss: 1.6841 - accuracy: 0.3960 - val_loss: 1.7467 - val_accuracy: 0.3790\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 41s 513ms/step - loss: 1.6856 - accuracy: 0.3984 - val_loss: 1.6811 - val_accuracy: 0.4063\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.6850 - accuracy: 0.3964 - val_loss: 1.6790 - val_accuracy: 0.4029\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 40s 507ms/step - loss: 1.6824 - accuracy: 0.3999 - val_loss: 1.7131 - val_accuracy: 0.3883\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 40s 512ms/step - loss: 1.6690 - accuracy: 0.4048 - val_loss: 1.6651 - val_accuracy: 0.4149\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 41s 514ms/step - loss: 1.6588 - accuracy: 0.4045 - val_loss: 1.7022 - val_accuracy: 0.3891\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 40s 512ms/step - loss: 1.6721 - accuracy: 0.4007 - val_loss: 1.6789 - val_accuracy: 0.4064\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.6667 - accuracy: 0.4030 - val_loss: 1.6855 - val_accuracy: 0.4053\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 40s 504ms/step - loss: 1.6641 - accuracy: 0.4035 - val_loss: 1.6558 - val_accuracy: 0.4112\n",
      "Epoch 00100: early stopping\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.6136 - accuracy: 0.4187\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6410 - accuracy: 0.4174\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6232 - accuracy: 0.4251\n",
      "Train accuracy: 0.4186750054359436\n",
      "Validation accuracy: 0.4174000024795532\n",
      "Test accuracy: 0.4250999987125397\n",
      "big_grid_model_45\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 13)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 13)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        1888      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,057,930\n",
      "Trainable params: 1,057,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 41s 515ms/step - loss: 7.4260 - accuracy: 0.1225 - val_loss: 2.2644 - val_accuracy: 0.1457\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 42s 529ms/step - loss: 2.2050 - accuracy: 0.1630 - val_loss: 2.2044 - val_accuracy: 0.1685\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 42s 532ms/step - loss: 2.1638 - accuracy: 0.1859 - val_loss: 2.1619 - val_accuracy: 0.1908\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 2.1423 - accuracy: 0.1985 - val_loss: 2.1586 - val_accuracy: 0.2048\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 43s 544ms/step - loss: 2.1157 - accuracy: 0.2169 - val_loss: 2.1326 - val_accuracy: 0.2082\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 44s 552ms/step - loss: 2.1019 - accuracy: 0.2201 - val_loss: 2.1074 - val_accuracy: 0.2239\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 43s 539ms/step - loss: 2.0813 - accuracy: 0.2345 - val_loss: 2.1130 - val_accuracy: 0.2152\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 43s 539ms/step - loss: 2.0692 - accuracy: 0.2381 - val_loss: 2.1175 - val_accuracy: 0.2145\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 44s 551ms/step - loss: 2.0547 - accuracy: 0.2430 - val_loss: 2.0899 - val_accuracy: 0.2274\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 47s 601ms/step - loss: 2.0448 - accuracy: 0.2504 - val_loss: 2.0567 - val_accuracy: 0.2518\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 46s 581ms/step - loss: 2.0340 - accuracy: 0.2561 - val_loss: 2.0410 - val_accuracy: 0.2455\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 43s 544ms/step - loss: 2.0309 - accuracy: 0.2558 - val_loss: 2.0892 - val_accuracy: 0.2197\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 43s 542ms/step - loss: 2.0268 - accuracy: 0.2611 - val_loss: 2.0521 - val_accuracy: 0.2498\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 43s 541ms/step - loss: 2.0171 - accuracy: 0.2623 - val_loss: 2.0385 - val_accuracy: 0.2558\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 43s 544ms/step - loss: 2.0119 - accuracy: 0.2668 - val_loss: 2.0180 - val_accuracy: 0.2683\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 43s 544ms/step - loss: 2.0023 - accuracy: 0.2731 - val_loss: 2.0354 - val_accuracy: 0.2585\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 42s 537ms/step - loss: 2.0001 - accuracy: 0.2741 - val_loss: 2.0413 - val_accuracy: 0.2557\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 43s 542ms/step - loss: 1.9864 - accuracy: 0.2774 - val_loss: 2.0298 - val_accuracy: 0.2641\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 43s 547ms/step - loss: 1.9951 - accuracy: 0.2758 - val_loss: 2.0102 - val_accuracy: 0.2672\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 43s 540ms/step - loss: 1.9815 - accuracy: 0.2832 - val_loss: 1.9911 - val_accuracy: 0.2739\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 42s 534ms/step - loss: 1.9780 - accuracy: 0.2830 - val_loss: 2.0377 - val_accuracy: 0.2553\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 42s 532ms/step - loss: 1.9772 - accuracy: 0.2837 - val_loss: 1.9823 - val_accuracy: 0.2866\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 43s 544ms/step - loss: 1.9689 - accuracy: 0.2871 - val_loss: 2.0202 - val_accuracy: 0.2583\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 43s 540ms/step - loss: 1.9601 - accuracy: 0.2921 - val_loss: 2.0332 - val_accuracy: 0.2624\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 43s 538ms/step - loss: 1.9581 - accuracy: 0.2919 - val_loss: 1.9714 - val_accuracy: 0.2896\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 43s 545ms/step - loss: 1.9473 - accuracy: 0.2969 - val_loss: 1.9695 - val_accuracy: 0.2825\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 43s 544ms/step - loss: 1.9432 - accuracy: 0.2998 - val_loss: 1.9585 - val_accuracy: 0.2896\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 43s 546ms/step - loss: 1.9341 - accuracy: 0.3043 - val_loss: 2.0618 - val_accuracy: 0.2617\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 44s 555ms/step - loss: 1.9329 - accuracy: 0.3035 - val_loss: 2.0052 - val_accuracy: 0.2767\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 44s 555ms/step - loss: 1.9358 - accuracy: 0.3026 - val_loss: 1.9854 - val_accuracy: 0.2869\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 42s 537ms/step - loss: 1.9168 - accuracy: 0.3113 - val_loss: 1.9242 - val_accuracy: 0.3110\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 43s 544ms/step - loss: 1.9084 - accuracy: 0.3175 - val_loss: 1.9334 - val_accuracy: 0.3131\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 42s 535ms/step - loss: 1.9028 - accuracy: 0.3169 - val_loss: 1.8994 - val_accuracy: 0.3193\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 43s 539ms/step - loss: 1.9038 - accuracy: 0.3164 - val_loss: 1.8949 - val_accuracy: 0.3229\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 42s 534ms/step - loss: 1.8983 - accuracy: 0.3194 - val_loss: 1.9138 - val_accuracy: 0.3168\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 42s 536ms/step - loss: 1.8951 - accuracy: 0.3228 - val_loss: 1.8890 - val_accuracy: 0.3300\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 1.8785 - accuracy: 0.3290 - val_loss: 1.8986 - val_accuracy: 0.3215\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 1.8746 - accuracy: 0.3295 - val_loss: 1.9140 - val_accuracy: 0.3236\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 1.8636 - accuracy: 0.3334 - val_loss: 1.8449 - val_accuracy: 0.3375\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 43s 549ms/step - loss: 1.8528 - accuracy: 0.3363 - val_loss: 1.8311 - val_accuracy: 0.3376\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 43s 551ms/step - loss: 1.8519 - accuracy: 0.3380 - val_loss: 1.8686 - val_accuracy: 0.3355\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 43s 544ms/step - loss: 1.8407 - accuracy: 0.3455 - val_loss: 1.8949 - val_accuracy: 0.3251\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 43s 542ms/step - loss: 1.8427 - accuracy: 0.3417 - val_loss: 1.8292 - val_accuracy: 0.3529\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 44s 558ms/step - loss: 1.8306 - accuracy: 0.3470 - val_loss: 1.8352 - val_accuracy: 0.3422\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 43s 538ms/step - loss: 1.8234 - accuracy: 0.3484 - val_loss: 1.7856 - val_accuracy: 0.3599\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 43s 547ms/step - loss: 1.8083 - accuracy: 0.3530 - val_loss: 1.7797 - val_accuracy: 0.3625\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 43s 542ms/step - loss: 1.8041 - accuracy: 0.3537 - val_loss: 1.7970 - val_accuracy: 0.3583\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 43s 542ms/step - loss: 1.7908 - accuracy: 0.3591 - val_loss: 1.7812 - val_accuracy: 0.3607\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 42s 538ms/step - loss: 1.7786 - accuracy: 0.3645 - val_loss: 1.8121 - val_accuracy: 0.3486\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 43s 545ms/step - loss: 1.7805 - accuracy: 0.3650 - val_loss: 1.7971 - val_accuracy: 0.3528\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 43s 548ms/step - loss: 1.7720 - accuracy: 0.3684 - val_loss: 1.8298 - val_accuracy: 0.3476\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 42s 537ms/step - loss: 1.7680 - accuracy: 0.3692 - val_loss: 1.7778 - val_accuracy: 0.3546\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 42s 533ms/step - loss: 1.7532 - accuracy: 0.3743 - val_loss: 1.7596 - val_accuracy: 0.3699\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 43s 539ms/step - loss: 1.7516 - accuracy: 0.3760 - val_loss: 1.7452 - val_accuracy: 0.3798\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 42s 532ms/step - loss: 1.7449 - accuracy: 0.3778 - val_loss: 1.7666 - val_accuracy: 0.3639\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 42s 533ms/step - loss: 1.7489 - accuracy: 0.3758 - val_loss: 1.7595 - val_accuracy: 0.3747\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 44s 562ms/step - loss: 1.7343 - accuracy: 0.3798 - val_loss: 1.8185 - val_accuracy: 0.3578\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 44s 554ms/step - loss: 1.7249 - accuracy: 0.3869 - val_loss: 1.7610 - val_accuracy: 0.3628\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 44s 558ms/step - loss: 1.7180 - accuracy: 0.3844 - val_loss: 1.7124 - val_accuracy: 0.3893\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 44s 561ms/step - loss: 1.7071 - accuracy: 0.3916 - val_loss: 1.7538 - val_accuracy: 0.3695\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 40s 509ms/step - loss: 1.7080 - accuracy: 0.3894 - val_loss: 1.7135 - val_accuracy: 0.3864\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 40s 510ms/step - loss: 1.7008 - accuracy: 0.3941 - val_loss: 1.7263 - val_accuracy: 0.3865\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 40s 504ms/step - loss: 1.7125 - accuracy: 0.3881 - val_loss: 1.7209 - val_accuracy: 0.3817\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 40s 506ms/step - loss: 1.6934 - accuracy: 0.3926 - val_loss: 1.6635 - val_accuracy: 0.4014\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.6866 - accuracy: 0.3954 - val_loss: 1.7409 - val_accuracy: 0.3808\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.6834 - accuracy: 0.3976 - val_loss: 1.6856 - val_accuracy: 0.4024\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 40s 504ms/step - loss: 1.6793 - accuracy: 0.4020 - val_loss: 1.6840 - val_accuracy: 0.4028\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 40s 508ms/step - loss: 1.6690 - accuracy: 0.4050 - val_loss: 1.6546 - val_accuracy: 0.4092\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 40s 507ms/step - loss: 1.6656 - accuracy: 0.4063 - val_loss: 1.7224 - val_accuracy: 0.3809\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.6731 - accuracy: 0.4021 - val_loss: 1.6442 - val_accuracy: 0.4156\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 40s 511ms/step - loss: 1.6650 - accuracy: 0.4052 - val_loss: 1.6686 - val_accuracy: 0.4067\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 40s 501ms/step - loss: 1.6598 - accuracy: 0.4092 - val_loss: 1.6524 - val_accuracy: 0.4124\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.6558 - accuracy: 0.4079 - val_loss: 1.6577 - val_accuracy: 0.4119\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 41s 516ms/step - loss: 1.6499 - accuracy: 0.4103 - val_loss: 1.7088 - val_accuracy: 0.3967\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 40s 509ms/step - loss: 1.6398 - accuracy: 0.4162 - val_loss: 1.6536 - val_accuracy: 0.4074\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 40s 506ms/step - loss: 1.6416 - accuracy: 0.4163 - val_loss: 1.6378 - val_accuracy: 0.4161\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.6381 - accuracy: 0.4157 - val_loss: 1.6667 - val_accuracy: 0.4063\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 40s 505ms/step - loss: 1.6309 - accuracy: 0.4203 - val_loss: 1.6154 - val_accuracy: 0.4254\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 40s 506ms/step - loss: 1.6286 - accuracy: 0.4205 - val_loss: 1.6324 - val_accuracy: 0.4165\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 40s 509ms/step - loss: 1.6290 - accuracy: 0.4199 - val_loss: 1.6156 - val_accuracy: 0.4263\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 1.6194 - accuracy: 0.4225 - val_loss: 1.6387 - val_accuracy: 0.4244\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 41s 516ms/step - loss: 1.6122 - accuracy: 0.4261 - val_loss: 1.6116 - val_accuracy: 0.4299\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 40s 512ms/step - loss: 1.6132 - accuracy: 0.4272 - val_loss: 1.6349 - val_accuracy: 0.4220\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 41s 516ms/step - loss: 1.6174 - accuracy: 0.4229 - val_loss: 1.6461 - val_accuracy: 0.4145\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 1.6086 - accuracy: 0.4280 - val_loss: 1.6356 - val_accuracy: 0.4215\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 1.6011 - accuracy: 0.4284 - val_loss: 1.6078 - val_accuracy: 0.4255\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 40s 509ms/step - loss: 1.5933 - accuracy: 0.4343 - val_loss: 1.6562 - val_accuracy: 0.4162\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 41s 514ms/step - loss: 1.5862 - accuracy: 0.4359 - val_loss: 1.6713 - val_accuracy: 0.4004\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 41s 516ms/step - loss: 1.5969 - accuracy: 0.4299 - val_loss: 1.6134 - val_accuracy: 0.4311\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 41s 514ms/step - loss: 1.5966 - accuracy: 0.4336 - val_loss: 1.6189 - val_accuracy: 0.4259\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 40s 511ms/step - loss: 1.5928 - accuracy: 0.4371 - val_loss: 1.5910 - val_accuracy: 0.4380\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 40s 512ms/step - loss: 1.5797 - accuracy: 0.4387 - val_loss: 1.6104 - val_accuracy: 0.4311\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 40s 510ms/step - loss: 1.5838 - accuracy: 0.4365 - val_loss: 1.6491 - val_accuracy: 0.4106\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 41s 513ms/step - loss: 1.5941 - accuracy: 0.4364 - val_loss: 1.5938 - val_accuracy: 0.4367\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 40s 506ms/step - loss: 1.5720 - accuracy: 0.4431 - val_loss: 1.6003 - val_accuracy: 0.4354\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 40s 506ms/step - loss: 1.5656 - accuracy: 0.4467 - val_loss: 1.6578 - val_accuracy: 0.4127\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 1.5759 - accuracy: 0.4394 - val_loss: 1.5833 - val_accuracy: 0.4426\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 40s 509ms/step - loss: 1.5649 - accuracy: 0.4461 - val_loss: 1.5998 - val_accuracy: 0.4359\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 39s 499ms/step - loss: 1.5730 - accuracy: 0.4405 - val_loss: 1.6417 - val_accuracy: 0.4271\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 39s 496ms/step - loss: 1.5652 - accuracy: 0.4428 - val_loss: 1.5619 - val_accuracy: 0.4433\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.5267 - accuracy: 0.4574\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5619 - accuracy: 0.4433\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5484 - accuracy: 0.4568\n",
      "Train accuracy: 0.4573749899864197\n",
      "Validation accuracy: 0.4433000087738037\n",
      "Test accuracy: 0.45680001378059387\n",
      "big_grid_model_46\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 13)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 13)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        3776      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,072,266\n",
      "Trainable params: 1,072,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 39s 498ms/step - loss: 7.5339 - accuracy: 0.1636 - val_loss: 2.2172 - val_accuracy: 0.1752\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 2.1224 - accuracy: 0.2166 - val_loss: 2.0910 - val_accuracy: 0.2342\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 2.0571 - accuracy: 0.2439 - val_loss: 2.0584 - val_accuracy: 0.2394\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 40s 511ms/step - loss: 2.0366 - accuracy: 0.2572 - val_loss: 2.0045 - val_accuracy: 0.2813\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 40s 502ms/step - loss: 2.0085 - accuracy: 0.2668 - val_loss: 2.0204 - val_accuracy: 0.2710\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 2.0086 - accuracy: 0.2709 - val_loss: 1.9572 - val_accuracy: 0.3040\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 40s 507ms/step - loss: 1.9991 - accuracy: 0.2772 - val_loss: 2.1111 - val_accuracy: 0.2203\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 2.0064 - accuracy: 0.2705 - val_loss: 1.9800 - val_accuracy: 0.2874\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 40s 511ms/step - loss: 1.9649 - accuracy: 0.2914 - val_loss: 1.9574 - val_accuracy: 0.2923\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 40s 503ms/step - loss: 1.9527 - accuracy: 0.2956 - val_loss: 1.9333 - val_accuracy: 0.3065\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 40s 506ms/step - loss: 1.9377 - accuracy: 0.3009 - val_loss: 1.9240 - val_accuracy: 0.3149\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 1.9226 - accuracy: 0.3073 - val_loss: 1.9112 - val_accuracy: 0.3100\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 43s 541ms/step - loss: 1.9112 - accuracy: 0.3108 - val_loss: 1.9263 - val_accuracy: 0.3136\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 42s 533ms/step - loss: 1.9070 - accuracy: 0.3136 - val_loss: 1.8962 - val_accuracy: 0.3186\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 42s 538ms/step - loss: 1.8951 - accuracy: 0.3176 - val_loss: 1.9036 - val_accuracy: 0.3181\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 42s 536ms/step - loss: 1.8765 - accuracy: 0.3290 - val_loss: 1.8604 - val_accuracy: 0.3406\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 42s 533ms/step - loss: 1.8719 - accuracy: 0.3309 - val_loss: 1.8640 - val_accuracy: 0.3441\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 43s 539ms/step - loss: 1.8585 - accuracy: 0.3311 - val_loss: 1.8413 - val_accuracy: 0.3431\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 43s 543ms/step - loss: 1.8387 - accuracy: 0.3421 - val_loss: 1.8355 - val_accuracy: 0.3526\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 42s 536ms/step - loss: 1.8278 - accuracy: 0.3484 - val_loss: 1.8243 - val_accuracy: 0.3592\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 42s 535ms/step - loss: 1.8236 - accuracy: 0.3498 - val_loss: 1.7784 - val_accuracy: 0.3823\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 42s 536ms/step - loss: 1.8225 - accuracy: 0.3494 - val_loss: 1.8270 - val_accuracy: 0.3532\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 43s 540ms/step - loss: 1.8141 - accuracy: 0.3530 - val_loss: 1.8604 - val_accuracy: 0.3522\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 42s 534ms/step - loss: 1.8060 - accuracy: 0.3546 - val_loss: 1.7532 - val_accuracy: 0.3826\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 42s 534ms/step - loss: 1.7813 - accuracy: 0.3615 - val_loss: 1.7163 - val_accuracy: 0.3957\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 42s 536ms/step - loss: 1.7846 - accuracy: 0.3608 - val_loss: 1.7495 - val_accuracy: 0.3813\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 42s 535ms/step - loss: 1.7727 - accuracy: 0.3650 - val_loss: 1.7354 - val_accuracy: 0.3876\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 42s 533ms/step - loss: 1.7738 - accuracy: 0.3661 - val_loss: 1.7396 - val_accuracy: 0.3867\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 42s 535ms/step - loss: 1.7600 - accuracy: 0.3685 - val_loss: 1.7507 - val_accuracy: 0.3754\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 42s 533ms/step - loss: 1.7666 - accuracy: 0.3695 - val_loss: 1.7899 - val_accuracy: 0.3625\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 42s 535ms/step - loss: 1.7522 - accuracy: 0.3717 - val_loss: 1.7190 - val_accuracy: 0.3957\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 42s 534ms/step - loss: 1.7523 - accuracy: 0.3754 - val_loss: 1.7173 - val_accuracy: 0.3965\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 42s 536ms/step - loss: 1.7356 - accuracy: 0.3803 - val_loss: 1.7464 - val_accuracy: 0.3881\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 43s 539ms/step - loss: 1.7307 - accuracy: 0.3815 - val_loss: 1.6798 - val_accuracy: 0.4072\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 43s 538ms/step - loss: 1.7269 - accuracy: 0.3820 - val_loss: 1.6670 - val_accuracy: 0.4146\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 43s 541ms/step - loss: 1.7201 - accuracy: 0.3824 - val_loss: 1.6898 - val_accuracy: 0.4031\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 42s 537ms/step - loss: 1.7105 - accuracy: 0.3862 - val_loss: 1.6550 - val_accuracy: 0.4137\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 42s 537ms/step - loss: 1.7038 - accuracy: 0.3927 - val_loss: 1.7190 - val_accuracy: 0.3881\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 42s 532ms/step - loss: 1.6963 - accuracy: 0.3944 - val_loss: 1.6822 - val_accuracy: 0.4096\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 42s 535ms/step - loss: 1.6912 - accuracy: 0.3913 - val_loss: 1.6536 - val_accuracy: 0.4207\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 43s 539ms/step - loss: 1.6904 - accuracy: 0.3942 - val_loss: 1.6829 - val_accuracy: 0.4069\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 42s 534ms/step - loss: 1.6778 - accuracy: 0.3981 - val_loss: 1.6438 - val_accuracy: 0.4217\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 42s 536ms/step - loss: 1.6767 - accuracy: 0.4005 - val_loss: 1.6147 - val_accuracy: 0.4346\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 43s 541ms/step - loss: 1.6657 - accuracy: 0.4058 - val_loss: 1.7338 - val_accuracy: 0.3865\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 42s 534ms/step - loss: 1.6683 - accuracy: 0.4043 - val_loss: 1.7023 - val_accuracy: 0.4016\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 42s 535ms/step - loss: 1.6653 - accuracy: 0.4092 - val_loss: 1.6298 - val_accuracy: 0.4247\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 42s 537ms/step - loss: 1.6440 - accuracy: 0.4098 - val_loss: 1.6361 - val_accuracy: 0.4258\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 43s 539ms/step - loss: 1.6428 - accuracy: 0.4121 - val_loss: 1.6490 - val_accuracy: 0.4267\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 42s 535ms/step - loss: 1.6459 - accuracy: 0.4142 - val_loss: 1.6233 - val_accuracy: 0.4301\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 42s 536ms/step - loss: 1.6214 - accuracy: 0.4205 - val_loss: 1.6322 - val_accuracy: 0.4358\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 1.6400 - accuracy: 0.4133 - val_loss: 1.5884 - val_accuracy: 0.4428\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 42s 534ms/step - loss: 1.6236 - accuracy: 0.4207 - val_loss: 1.6189 - val_accuracy: 0.4375\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 43s 539ms/step - loss: 1.6352 - accuracy: 0.4147 - val_loss: 1.5760 - val_accuracy: 0.4473\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 1.6094 - accuracy: 0.4278 - val_loss: 1.6231 - val_accuracy: 0.4287\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.6157 - accuracy: 0.4243 - val_loss: 1.6072 - val_accuracy: 0.4331\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.6072 - accuracy: 0.4277 - val_loss: 1.5689 - val_accuracy: 0.4503\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5943 - accuracy: 0.4327 - val_loss: 1.5947 - val_accuracy: 0.4371\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.6016 - accuracy: 0.4303 - val_loss: 1.5951 - val_accuracy: 0.4385\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 42s 529ms/step - loss: 1.5862 - accuracy: 0.4363 - val_loss: 1.5716 - val_accuracy: 0.4508\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.5862 - accuracy: 0.4334 - val_loss: 1.5323 - val_accuracy: 0.4616\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.6057 - accuracy: 0.4290 - val_loss: 1.5506 - val_accuracy: 0.4513\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5922 - accuracy: 0.4335 - val_loss: 1.5674 - val_accuracy: 0.4485\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.5878 - accuracy: 0.4323 - val_loss: 1.5256 - val_accuracy: 0.4635\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.5783 - accuracy: 0.4343 - val_loss: 1.5589 - val_accuracy: 0.4511\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5590 - accuracy: 0.4458 - val_loss: 1.5789 - val_accuracy: 0.4502\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.5639 - accuracy: 0.4459 - val_loss: 1.5445 - val_accuracy: 0.4568\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.5639 - accuracy: 0.4447 - val_loss: 1.5143 - val_accuracy: 0.4706\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.5611 - accuracy: 0.4441 - val_loss: 1.5054 - val_accuracy: 0.4695\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5633 - accuracy: 0.4445 - val_loss: 1.5129 - val_accuracy: 0.4685\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.5651 - accuracy: 0.4433 - val_loss: 1.5431 - val_accuracy: 0.4562\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.5522 - accuracy: 0.4496 - val_loss: 1.5367 - val_accuracy: 0.4602\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.5528 - accuracy: 0.4495 - val_loss: 1.5161 - val_accuracy: 0.4691\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5415 - accuracy: 0.4537 - val_loss: 1.6226 - val_accuracy: 0.4327\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 1.5462 - accuracy: 0.4487 - val_loss: 1.5355 - val_accuracy: 0.4619\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.5475 - accuracy: 0.4496 - val_loss: 1.5113 - val_accuracy: 0.4677\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.5357 - accuracy: 0.4534 - val_loss: 1.5111 - val_accuracy: 0.4715\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.5464 - accuracy: 0.4491 - val_loss: 1.5669 - val_accuracy: 0.4546\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.5377 - accuracy: 0.4540 - val_loss: 1.5233 - val_accuracy: 0.4628\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.5339 - accuracy: 0.4559 - val_loss: 1.5039 - val_accuracy: 0.4753\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.5354 - accuracy: 0.4541 - val_loss: 1.5449 - val_accuracy: 0.4597\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.5362 - accuracy: 0.4567 - val_loss: 1.4636 - val_accuracy: 0.4885\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.5236 - accuracy: 0.4601 - val_loss: 1.4929 - val_accuracy: 0.4729\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.5280 - accuracy: 0.4608 - val_loss: 1.5081 - val_accuracy: 0.4698\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.5285 - accuracy: 0.4575 - val_loss: 1.5196 - val_accuracy: 0.4708\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.5143 - accuracy: 0.4640 - val_loss: 1.4732 - val_accuracy: 0.4817\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5096 - accuracy: 0.4643 - val_loss: 1.5193 - val_accuracy: 0.4693\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.5147 - accuracy: 0.4654 - val_loss: 1.5082 - val_accuracy: 0.4712\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.5075 - accuracy: 0.4674 - val_loss: 1.4920 - val_accuracy: 0.4776\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5112 - accuracy: 0.4657 - val_loss: 1.4996 - val_accuracy: 0.4770\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.5130 - accuracy: 0.4636 - val_loss: 1.4800 - val_accuracy: 0.4857\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.4960 - accuracy: 0.4676 - val_loss: 1.4649 - val_accuracy: 0.4879\n",
      "Epoch 00091: early stopping\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.4252 - accuracy: 0.4910\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4636 - accuracy: 0.4885\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4439 - accuracy: 0.4945\n",
      "Train accuracy: 0.49102500081062317\n",
      "Validation accuracy: 0.4884999990463257\n",
      "Test accuracy: 0.4945000112056732\n",
      "big_grid_model_47\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "1.test. Convert RGB to greyscale\n",
      "2.test. Morphological operations\n",
      "3.test. Expand first dim\n",
      "4.test. Crop images\n",
      "5.train. Convert list to numpy array\n",
      "(40000, 32, 32, 13)\n",
      "(40000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "(10000, 32, 32, 13)\n",
      "(10000, 10)\n",
      "Build data generators\n",
      "Model: \"big_grid_model_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 13)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        3776      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,122,250\n",
      "Trainable params: 2,122,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Augmentation mode on\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 8.9447 - accuracy: 0.1363 - val_loss: 2.2574 - val_accuracy: 0.1423\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 2.2116 - accuracy: 0.1634 - val_loss: 2.2288 - val_accuracy: 0.1668\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 2.1728 - accuracy: 0.1850 - val_loss: 2.1618 - val_accuracy: 0.1958\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 2.1319 - accuracy: 0.2074 - val_loss: 2.1208 - val_accuracy: 0.2194\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 42s 528ms/step - loss: 2.0960 - accuracy: 0.2272 - val_loss: 2.1091 - val_accuracy: 0.2346\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 2.0870 - accuracy: 0.2333 - val_loss: 2.0664 - val_accuracy: 0.2413\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 2.0601 - accuracy: 0.2466 - val_loss: 2.0743 - val_accuracy: 0.2530\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 2.0452 - accuracy: 0.2539 - val_loss: 2.1107 - val_accuracy: 0.2370\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 2.0381 - accuracy: 0.2589 - val_loss: 2.0934 - val_accuracy: 0.2330\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 2.0203 - accuracy: 0.2666 - val_loss: 2.0192 - val_accuracy: 0.2777\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 2.0097 - accuracy: 0.2746 - val_loss: 2.0011 - val_accuracy: 0.2803\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.9918 - accuracy: 0.2772 - val_loss: 2.0058 - val_accuracy: 0.2802\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.9879 - accuracy: 0.2811 - val_loss: 2.0183 - val_accuracy: 0.2735\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.9747 - accuracy: 0.2874 - val_loss: 2.0434 - val_accuracy: 0.2665\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.9655 - accuracy: 0.2933 - val_loss: 1.9965 - val_accuracy: 0.2921\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.9554 - accuracy: 0.2964 - val_loss: 1.9844 - val_accuracy: 0.2978\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.9412 - accuracy: 0.3032 - val_loss: 2.0376 - val_accuracy: 0.2670\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.9302 - accuracy: 0.3087 - val_loss: 2.0128 - val_accuracy: 0.2857\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.9270 - accuracy: 0.3097 - val_loss: 1.9619 - val_accuracy: 0.3043\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 1.9134 - accuracy: 0.3125 - val_loss: 1.9696 - val_accuracy: 0.2946\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.8983 - accuracy: 0.3205 - val_loss: 1.9195 - val_accuracy: 0.3228\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.8825 - accuracy: 0.3258 - val_loss: 1.9285 - val_accuracy: 0.3092\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.8781 - accuracy: 0.3286 - val_loss: 1.9823 - val_accuracy: 0.2940\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.8692 - accuracy: 0.3318 - val_loss: 1.9719 - val_accuracy: 0.2931\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 1.8502 - accuracy: 0.3363 - val_loss: 1.8871 - val_accuracy: 0.3327\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.8432 - accuracy: 0.3415 - val_loss: 1.9294 - val_accuracy: 0.3190\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.8302 - accuracy: 0.3474 - val_loss: 1.8874 - val_accuracy: 0.3317\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.8159 - accuracy: 0.3507 - val_loss: 1.9118 - val_accuracy: 0.3276\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 41s 518ms/step - loss: 1.8012 - accuracy: 0.3554 - val_loss: 1.8478 - val_accuracy: 0.3493\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.7998 - accuracy: 0.3553 - val_loss: 1.8371 - val_accuracy: 0.3545\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.7703 - accuracy: 0.3672 - val_loss: 1.8055 - val_accuracy: 0.3683\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.7633 - accuracy: 0.3715 - val_loss: 1.8029 - val_accuracy: 0.3657\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.7517 - accuracy: 0.3717 - val_loss: 1.7550 - val_accuracy: 0.3830\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.7319 - accuracy: 0.3821 - val_loss: 1.7389 - val_accuracy: 0.3855\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.7404 - accuracy: 0.3823 - val_loss: 1.8140 - val_accuracy: 0.3533\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.7260 - accuracy: 0.3854 - val_loss: 1.7636 - val_accuracy: 0.3851\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.7026 - accuracy: 0.3922 - val_loss: 1.6699 - val_accuracy: 0.4034\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.6966 - accuracy: 0.3920 - val_loss: 1.6593 - val_accuracy: 0.4121\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.6863 - accuracy: 0.3985 - val_loss: 1.7202 - val_accuracy: 0.3854\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.6758 - accuracy: 0.3997 - val_loss: 1.6471 - val_accuracy: 0.4127\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 1.6661 - accuracy: 0.4058 - val_loss: 1.6623 - val_accuracy: 0.4071\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.6583 - accuracy: 0.4085 - val_loss: 1.6576 - val_accuracy: 0.4172\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.6436 - accuracy: 0.4137 - val_loss: 1.6020 - val_accuracy: 0.4338\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 42s 528ms/step - loss: 1.6406 - accuracy: 0.4135 - val_loss: 1.5980 - val_accuracy: 0.4288\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.6343 - accuracy: 0.4174 - val_loss: 1.5959 - val_accuracy: 0.4291\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 1.6298 - accuracy: 0.4211 - val_loss: 1.5642 - val_accuracy: 0.4479\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.6291 - accuracy: 0.4193 - val_loss: 1.5605 - val_accuracy: 0.4430\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.6062 - accuracy: 0.4272 - val_loss: 1.6289 - val_accuracy: 0.4280\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.6070 - accuracy: 0.4284 - val_loss: 1.5796 - val_accuracy: 0.4395\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 1.5973 - accuracy: 0.4315 - val_loss: 1.5393 - val_accuracy: 0.4552\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.5877 - accuracy: 0.4371 - val_loss: 1.5698 - val_accuracy: 0.4411\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.5776 - accuracy: 0.4405 - val_loss: 1.5458 - val_accuracy: 0.4496\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5803 - accuracy: 0.4384 - val_loss: 1.5445 - val_accuracy: 0.4513\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.5650 - accuracy: 0.4442 - val_loss: 1.5457 - val_accuracy: 0.4526\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.5578 - accuracy: 0.4444 - val_loss: 1.5149 - val_accuracy: 0.4649\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.5579 - accuracy: 0.4471 - val_loss: 1.5311 - val_accuracy: 0.4574\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.5592 - accuracy: 0.4459 - val_loss: 1.5316 - val_accuracy: 0.4634\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5475 - accuracy: 0.4513 - val_loss: 1.5232 - val_accuracy: 0.4646\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5407 - accuracy: 0.4525 - val_loss: 1.5127 - val_accuracy: 0.4652\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.5399 - accuracy: 0.4564 - val_loss: 1.5850 - val_accuracy: 0.4485\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.5269 - accuracy: 0.4584 - val_loss: 1.4622 - val_accuracy: 0.4820\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.5274 - accuracy: 0.4592 - val_loss: 1.6293 - val_accuracy: 0.4266\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.5386 - accuracy: 0.4541 - val_loss: 1.5407 - val_accuracy: 0.4565\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.5228 - accuracy: 0.4588 - val_loss: 1.4986 - val_accuracy: 0.4738\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.5150 - accuracy: 0.4622 - val_loss: 1.4604 - val_accuracy: 0.4838\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.5090 - accuracy: 0.4640 - val_loss: 1.5467 - val_accuracy: 0.4538\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 42s 534ms/step - loss: 1.5112 - accuracy: 0.4621 - val_loss: 1.4555 - val_accuracy: 0.4904\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 41s 522ms/step - loss: 1.4988 - accuracy: 0.4677 - val_loss: 1.4754 - val_accuracy: 0.4831\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 41s 519ms/step - loss: 1.4932 - accuracy: 0.4732 - val_loss: 1.4405 - val_accuracy: 0.4932\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.5027 - accuracy: 0.4679 - val_loss: 1.4411 - val_accuracy: 0.4910\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.4949 - accuracy: 0.4713 - val_loss: 1.4433 - val_accuracy: 0.4937\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.4893 - accuracy: 0.4720 - val_loss: 1.4382 - val_accuracy: 0.4896\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.4846 - accuracy: 0.4733 - val_loss: 1.4375 - val_accuracy: 0.4967\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.4879 - accuracy: 0.4706 - val_loss: 1.4244 - val_accuracy: 0.4968\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 1.4777 - accuracy: 0.4761 - val_loss: 1.4312 - val_accuracy: 0.4932\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 41s 525ms/step - loss: 1.4748 - accuracy: 0.4764 - val_loss: 1.3961 - val_accuracy: 0.5050\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.4727 - accuracy: 0.4784 - val_loss: 1.4070 - val_accuracy: 0.5081\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 42s 526ms/step - loss: 1.4632 - accuracy: 0.4814 - val_loss: 1.4211 - val_accuracy: 0.4968\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 41s 523ms/step - loss: 1.4717 - accuracy: 0.4793 - val_loss: 1.4036 - val_accuracy: 0.5007\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 41s 524ms/step - loss: 1.4631 - accuracy: 0.4812 - val_loss: 1.4521 - val_accuracy: 0.4886\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 41s 521ms/step - loss: 1.4612 - accuracy: 0.4823 - val_loss: 1.4090 - val_accuracy: 0.5037\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 40s 505ms/step - loss: 1.4535 - accuracy: 0.4854 - val_loss: 1.4098 - val_accuracy: 0.5045\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 39s 489ms/step - loss: 1.4467 - accuracy: 0.4923 - val_loss: 1.3851 - val_accuracy: 0.5146\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.4523 - accuracy: 0.4873 - val_loss: 1.4753 - val_accuracy: 0.4886\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.4506 - accuracy: 0.4869 - val_loss: 1.3825 - val_accuracy: 0.5122\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.4432 - accuracy: 0.4879 - val_loss: 1.4480 - val_accuracy: 0.4912\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 39s 493ms/step - loss: 1.4389 - accuracy: 0.4947 - val_loss: 1.4145 - val_accuracy: 0.5077\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.4308 - accuracy: 0.4941 - val_loss: 1.3876 - val_accuracy: 0.5135\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.4276 - accuracy: 0.4948 - val_loss: 1.4099 - val_accuracy: 0.5061\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 39s 495ms/step - loss: 1.4340 - accuracy: 0.4917 - val_loss: 1.4044 - val_accuracy: 0.5086\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 39s 497ms/step - loss: 1.4402 - accuracy: 0.4883 - val_loss: 1.3999 - val_accuracy: 0.5113\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 39s 490ms/step - loss: 1.4356 - accuracy: 0.4943 - val_loss: 1.4294 - val_accuracy: 0.4931\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.4376 - accuracy: 0.4942 - val_loss: 1.3930 - val_accuracy: 0.5112\n",
      "Epoch 00093: early stopping\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.3417 - accuracy: 0.5242\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3851 - accuracy: 0.5146\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3827 - accuracy: 0.5127\n",
      "Train accuracy: 0.5242499709129333\n",
      "Validation accuracy: 0.5145999789237976\n",
      "Test accuracy: 0.5127000212669373\n",
      "big_grid_model_48\n",
      "1.train. Convert RGB to greyscale\n",
      "2.train. Morphological operations\n",
      "3.train. Expand first dim\n",
      "4.train. Crop images\n",
      "5.train. Convert list to numpy array\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.72 GiB for an array with shape (50000, 1, 32, 32, 15) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f8a78906e484>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                 \u001b[0mepochs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                                 \u001b[0mbatch_size_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                                 augmentation_ = True)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-26893fa85bda>\u001b[0m in \u001b[0;36mmorphological_test_cifar_10\u001b[1;34m(results_directory_, model_name_, structuring_elements_depth_, transormation_type_, structuring_elements_type_, structuring_elements_initsize_, structuring_elements_step_, addborder_, morphological_transformation_mode_, start_neurons_, dense_neurons_, epochs_, batch_size_, augmentation_)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"5.train. Convert list to numpy array\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mx_train_5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mx_train_4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.72 GiB for an array with shape (50000, 1, 32, 32, 15) and data type float64"
     ]
    }
   ],
   "source": [
    "for i in np.arange(27, grid_big.shape[0]):\n",
    "    \n",
    "    model_name_ = \"big_grid_model_\" + str(i)\n",
    "    print(model_name_)\n",
    "    \n",
    "    morphological_test_cifar_10(results_directory_ = \"Results_5_\",\n",
    "                                model_name_ = model_name_,\n",
    "                                structuring_elements_depth_ = grid_big[\"structuring_elements_depth_hp\"][i],\n",
    "                                transormation_type_ = grid_big[\"transormation_type_hp\"][i],\n",
    "                                structuring_elements_type_ = grid_big[\"structuring_elements_type_hp\"][i],\n",
    "                                structuring_elements_initsize_ = 1,\n",
    "                                structuring_elements_step_ = grid_big[\"structuring_elements_step_hp\"][i],\n",
    "                                addborder_ = True,\n",
    "                                morphological_transformation_mode_ = True,\n",
    "                                start_neurons_ = grid_big[\"start_neurons_hp\"][i],\n",
    "                                dense_neurons_ = grid_big[\"dense_neurons_hp\"][i],\n",
    "                                epochs_ = 100,\n",
    "                                batch_size_ = 512,\n",
    "                                augmentation_ = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_ML_TF",
   "language": "python",
   "name": "gpu_ml_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
